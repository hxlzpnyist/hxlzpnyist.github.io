{"meta":{"title":"断风雨","subtitle":"耐得住寂寞,才能守得住繁华","description":null,"author":"hxlzpnyist","url":"https://www.hxlzpnyist.site"},"pages":[{"title":"关于","date":"2019-02-22T06:12:19.000Z","updated":"2019-02-22T09:49:55.730Z","comments":true,"path":"about/index.html","permalink":"https://www.hxlzpnyist.site/about/index.html","excerpt":"","text":""}],"posts":[{"title":"zookeeper-数据同步源码分析","slug":"zookeeper-数据同步源码分析","date":"2019-05-09T10:09:01.000Z","updated":"2019-06-21T06:48:41.001Z","comments":true,"path":"2019/05/09/zookeeper-数据同步源码分析/","link":"","permalink":"https://www.hxlzpnyist.site/2019/05/09/zookeeper-数据同步源码分析/","excerpt":"","text":"在上一篇对 zookeeper 选举实现分析之后，我们知道 zookeeper 集群在选举结束之后，leader 节点将进入 LEADING 状态，follower 节点将进入 FOLLOWING 状态；此时集群中节点将进行数据同步操作，以保证数据一致。 只有数据同步完成之后 zookeeper 集群才具备对外提供服务的能力。 LEADING当节点在选举后角色确认为 leader 后将会进入 LEADING 状态，源码如下： public void run() { try { /* * Main loop */ while (running) { switch (getPeerState()) { case LEADING: LOG.info(&quot;LEADING&quot;); try { setLeader(makeLeader(logFactory)); leader.lead(); setLeader(null); } catch (Exception e) { LOG.warn(&quot;Unexpected exception&quot;,e); } finally { if (leader != null) { leader.shutdown(&quot;Forcing shutdown&quot;); setLeader(null); } setPeerState(ServerState.LOOKING); } break; } } } finally { } } QuorumPeer 在节点状态变更为 LEADING 之后会创建 leader 实例，并触发 lead 过程。 void lead() throws IOException, InterruptedException { try { // 省略 /** * 开启线程用于接收 follower 的连接请求 */ cnxAcceptor = new LearnerCnxAcceptor(); cnxAcceptor.start(); readyToStart = true; /** * 阻塞等待计算新的 epoch 值，并设置 zxid */ long epoch = getEpochToPropose(self.getId(), self.getAcceptedEpoch()); zk.setZxid(ZxidUtils.makeZxid(epoch, 0)); /** * 阻塞等待接收过半的 follower 节点发送的 ACKEPOCH 信息； 此时说明已经确定了本轮选举后 epoch 值 */ waitForEpochAck(self.getId(), leaderStateSummary); self.setCurrentEpoch(epoch); try { /** * 阻塞等待 超过半数的节点 follower 发送了 NEWLEADER ACK 信息；此时说明过半的 follower 节点已经完成数据同步 */ waitForNewLeaderAck(self.getId(), zk.getZxid(), LearnerType.PARTICIPANT); } catch (InterruptedException e) { // 省略 } /** * 启动 zk server，此时集群可以对外正式提供服务 */ startZkServer(); // 省略 } 从 lead 方法的实现可得知，leader 与 follower 在数据同步过程中会执行如下过程： 接收 follower 连接 计算新的 epoch 值 通知统一 epoch 值 数据同步 启动 zk server 对外提供服务 FOLLOWING下面在看下 follower 节点进入 FOLLOWING 状态后的操作： public void run() { try { /* * Main loop */ while (running) { switch (getPeerState()) { case LOOKING: // 省略 case OBSERVING: // 省略 case FOLLOWING: try { LOG.info(&quot;FOLLOWING&quot;); setFollower(makeFollower(logFactory)); follower.followLeader(); } catch (Exception e) { LOG.warn(&quot;Unexpected exception&quot;,e); } finally { follower.shutdown(); setFollower(null); setPeerState(ServerState.LOOKING); } break; } } } finally { } } QuorumPeer 在节点状态变更为 FOLLOWING 之后会创建 follower 实例，并触发 followLeader 过程。 void followLeader() throws InterruptedException { // 省略 try { QuorumServer leaderServer = findLeader(); try { /** * follower 与 leader 建立连接 */ connectToLeader(leaderServer.addr, leaderServer.hostname); /** * follower 向 leader 提交节点信息用于计算新的 epoch 值 */ long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); /** * follower 与 leader 数据同步 */ syncWithLeader(newEpochZxid); // 省略 } catch (Exception e) { // 省略 } } finally { // 省略 } } 从 followLeader 方法的实现可得知，follower 与 leader 在数据同步过程中会执行如下过程： 请求连接 leader 提交节点信息计算新的 epoch 值 数据同步 下面我们看下在各个环节的实现细节； Leader Follower 建立通信follower 请求连接protected QuorumServer findLeader() { QuorumServer leaderServer = null; // Find the leader by id Vote current = self.getCurrentVote(); for (QuorumServer s : self.getView().values()) { if (s.id == current.getId()) { // Ensure we have the leader&#39;s correct IP address before // attempting to connect. s.recreateSocketAddresses(); leaderServer = s; break; } } if (leaderServer == null) { LOG.warn(&quot;Couldn&#39;t find the leader with id = &quot; + current.getId()); } return leaderServer; } protected void connectToLeader(InetSocketAddress addr, String hostname) throws IOException, ConnectException, InterruptedException { sock = new Socket(); sock.setSoTimeout(self.tickTime * self.initLimit); for (int tries = 0; tries &lt; 5; tries++) { try { sock.connect(addr, self.tickTime * self.syncLimit); sock.setTcpNoDelay(nodelay); break; } catch (IOException e) { if (tries == 4) { LOG.error(&quot;Unexpected exception&quot;,e); throw e; } else { LOG.warn(&quot;Unexpected exception, tries=&quot;+tries+ &quot;, connecting to &quot; + addr,e); sock = new Socket(); sock.setSoTimeout(self.tickTime * self.initLimit); } } Thread.sleep(1000); } self.authLearner.authenticate(sock, hostname); leaderIs = BinaryInputArchive.getArchive(new BufferedInputStream( sock.getInputStream())); bufferedOutput = new BufferedOutputStream(sock.getOutputStream()); leaderOs = BinaryOutputArchive.getArchive(bufferedOutput); } follower 会通过选举后的投票信息确认 leader 节点地址，并发起连接（总共有 5 次尝试连接的机会，若连接不通则重新进入选举过程） leader 接收连接class LearnerCnxAcceptor extends ZooKeeperThread{ private volatile boolean stop = false; public LearnerCnxAcceptor() { super(&quot;LearnerCnxAcceptor-&quot; + ss.getLocalSocketAddress()); } @Override public void run() { try { while (!stop) { try{ /** * 接收 follower 的连接，并开启 LearnerHandler 线程用于处理二者之间的通信 */ Socket s = ss.accept(); s.setSoTimeout(self.tickTime * self.initLimit); s.setTcpNoDelay(nodelay); BufferedInputStream is = new BufferedInputStream( s.getInputStream()); LearnerHandler fh = new LearnerHandler(s, is, Leader.this); fh.start(); } catch (SocketException e) { // 省略 } catch (SaslException e){ LOG.error(&quot;Exception while connecting to quorum learner&quot;, e); } } } catch (Exception e) { LOG.warn(&quot;Exception while accepting follower&quot;, e); } } } 从 LearnerCnxAcceptor 实现可以看出 leader 节点在为每个 follower 节点连接建立之后都会为之分配一个 LearnerHandler 线程用于处理二者之间的通信。 计算新的 epoch 值 follower 在与 leader 建立连接之后，会发出 FOLLOWERINFO 信息 long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); protected long registerWithLeader(int pktType) throws IOException{ /** * 发送 follower info 信息，包括 last zxid 和 sid */ long lastLoggedZxid = self.getLastLoggedZxid(); QuorumPacket qp = new QuorumPacket(); qp.setType(pktType); qp.setZxid(ZxidUtils.makeZxid(self.getAcceptedEpoch(), 0)); /* * Add sid to payload */ LearnerInfo li = new LearnerInfo(self.getId(), 0x10000); ByteArrayOutputStream bsid = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(bsid); boa.writeRecord(li, &quot;LearnerInfo&quot;); qp.setData(bsid.toByteArray()); /** * follower 向 leader 发送 FOLLOWERINFO 信息，包括 zxid，sid，protocol version */ writePacket(qp, true); // 省略 } 接下来我们看下 leader 在接收到 FOLLOWERINFO 信息之后做什么(参考 LearnerHandler) public void run() { try { // 省略 /** * leader 接收 follower 发送的 FOLLOWERINFO 信息，包括 follower 节点的 zxid，sid，protocol version * @see Learner.registerWithleader() */ QuorumPacket qp = new QuorumPacket(); ia.readRecord(qp, &quot;packet&quot;); byte learnerInfoData[] = qp.getData(); if (learnerInfoData != null) { if (learnerInfoData.length == 8) { // 省略 } else { /** * 高版本的 learnerInfoData 包括 long 类型的 sid, int 类型的 protocol version 占用 12 字节 */ LearnerInfo li = new LearnerInfo(); ByteBufferInputStream.byteBuffer2Record(ByteBuffer.wrap(learnerInfoData), li); this.sid = li.getServerid(); this.version = li.getProtocolVersion(); } } /** * 通过 follower 发送的 zxid，解析出 foloower 节点的 epoch 值 */ long lastAcceptedEpoch = ZxidUtils.getEpochFromZxid(qp.getZxid()); long peerLastZxid; StateSummary ss = null; long zxid = qp.getZxid(); /** * 阻塞等待计算新的 epoch 值 */ long newEpoch = leader.getEpochToPropose(this.getSid(), lastAcceptedEpoch); // 省略 } 从上述代码可知，leader 在接收到 follower 发送的 FOLLOWERINFO 信息之后，会解析出 follower 节点的 acceptedEpoch 值并参与到新的 epoch 值计算中。 （具体计算逻辑参考方法 getEpochToPropose） public long getEpochToPropose(long sid, long lastAcceptedEpoch) throws InterruptedException, IOException { synchronized(connectingFollowers) { if (!waitingForNewEpoch) { return epoch; } // epoch 用来记录计算后的选举周期值 // follower 或 leader 的 acceptedEpoch 值与 epoch 比较；若前者大则将其加一 if (lastAcceptedEpoch &gt;= epoch) { epoch = lastAcceptedEpoch+1; } // connectingFollowers 用来记录与 leader 已连接的 follower connectingFollowers.add(sid); QuorumVerifier verifier = self.getQuorumVerifier(); // 判断是否已计算出新的 epoch 值的条件是 leader 已经参与了 epoch 值计算，以及超过一半的节点参与了计算 if (connectingFollowers.contains(self.getId()) &amp;&amp; verifier.containsQuorum(connectingFollowers)) { // 将 waitingForNewEpoch 设置为 false 说明不需要等待计算新的 epoch 值了 waitingForNewEpoch = false; // 设置 leader 的 acceptedEpoch 值 self.setAcceptedEpoch(epoch); // 唤醒 connectingFollowers wait 的线程 connectingFollowers.notifyAll(); } else { long start = Time.currentElapsedTime(); long cur = start; long end = start + self.getInitLimit()*self.getTickTime(); while(waitingForNewEpoch &amp;&amp; cur &lt; end) { // 若未完成新的 epoch 值计算则阻塞等待 connectingFollowers.wait(end - cur); cur = Time.currentElapsedTime(); } if (waitingForNewEpoch) { throw new InterruptedException(&quot;Timeout while waiting for epoch from quorum&quot;); } } return epoch; } } 从方法 getEpochToPropose 可知 leader 会收集集群中过半的 follower acceptedEpoch 信息后，选出一个最大值然后加 1 就是 newEpoch 值； 在此过程中 leader 会进入阻塞状态直到过半的 follower 参与到计算才会进入下一阶段。 通知新的 epoch 值leader 在计算出新的 newEpoch 值后，会进入下一阶段发送 LEADERINFO 信息 （同样参考 LearnerHandler） public void run() { try { // 省略 /** * 阻塞等待计算新的 epoch 值 */ long newEpoch = leader.getEpochToPropose(this.getSid(), lastAcceptedEpoch); if (this.getVersion() &lt; 0x10000) { // we are going to have to extrapolate the epoch information long epoch = ZxidUtils.getEpochFromZxid(zxid); ss = new StateSummary(epoch, zxid); // fake the message leader.waitForEpochAck(this.getSid(), ss); } else { byte ver[] = new byte[4]; ByteBuffer.wrap(ver).putInt(0x10000); /** * 计算出新的 epoch 值后，leader 向 follower 发送 LEADERINFO 信息；包括新的 newEpoch */ QuorumPacket newEpochPacket = new QuorumPacket(Leader.LEADERINFO, ZxidUtils.makeZxid(newEpoch, 0), ver, null); oa.writeRecord(newEpochPacket, &quot;packet&quot;); bufferedOutput.flush(); // 省略 } } // 省略 } protected long registerWithLeader(int pktType) throws IOException{ // 省略 /** * follower 向 leader 发送 FOLLOWERINFO 信息，包括 zxid，sid，protocol version */ writePacket(qp, true); /** * follower 接收 leader 发送的 LEADERINFO 信息 */ readPacket(qp); /** * 解析 leader 发送的 new epoch 值 */ final long newEpoch = ZxidUtils.getEpochFromZxid(qp.getZxid()); if (qp.getType() == Leader.LEADERINFO) { // we are connected to a 1.0 server so accept the new epoch and read the next packet leaderProtocolVersion = ByteBuffer.wrap(qp.getData()).getInt(); byte epochBytes[] = new byte[4]; final ByteBuffer wrappedEpochBytes = ByteBuffer.wrap(epochBytes); /** * new epoch &gt; current accepted epoch 则更新 acceptedEpoch 值 */ if (newEpoch &gt; self.getAcceptedEpoch()) { wrappedEpochBytes.putInt((int)self.getCurrentEpoch()); self.setAcceptedEpoch(newEpoch); } else if (newEpoch == self.getAcceptedEpoch()) { wrappedEpochBytes.putInt(-1); } else { throw new IOException(&quot;Leaders epoch, &quot; + newEpoch + &quot; is less than accepted epoch, &quot; + self.getAcceptedEpoch()); } /** * follower 向 leader 发送 ACKEPOCH 信息，包括 last zxid */ QuorumPacket ackNewEpoch = new QuorumPacket(Leader.ACKEPOCH, lastLoggedZxid, epochBytes, null); writePacket(ackNewEpoch, true); return ZxidUtils.makeZxid(newEpoch, 0); } } 从上述代码可以看出在完成 newEpoch 值计算后的 leader 与 follower 的交互过程： leader 向 follower 发送 LEADERINFO 信息，告知 follower 新的 epoch 值 follower 接收解析 LEADERINFO 信息，若 new epoch 值大于 current accepted epoch 值则更新 acceptedEpoch follower 向 leader 发送 ACKEPOCH 信息，反馈 leader 已收到新的 epoch 值，并附带 follower 节点的 last zxid 数据同步 LearnerHandler 中 leader 在收到过半的 ACKEPOCH 信息之后将进入数据同步阶段 public void run() { try { // 省略 // peerLastZxid 为 follower 的 last zxid peerLastZxid = ss.getLastZxid(); /* the default to send to the follower */ int packetToSend = Leader.SNAP; long zxidToSend = 0; long leaderLastZxid = 0; /** the packets that the follower needs to get updates from **/ long updates = peerLastZxid; ReentrantReadWriteLock lock = leader.zk.getZKDatabase().getLogLock(); ReadLock rl = lock.readLock(); try { rl.lock(); final long maxCommittedLog = leader.zk.getZKDatabase().getmaxCommittedLog(); final long minCommittedLog = leader.zk.getZKDatabase().getminCommittedLog(); LinkedList&lt;Proposal&gt; proposals = leader.zk.getZKDatabase().getCommittedLog(); if (peerLastZxid == leader.zk.getZKDatabase().getDataTreeLastProcessedZxid()) { /** * follower 与 leader 的 zxid 相同说明 二者数据一致；同步方式为差量同步 DIFF，同步的zxid 为 peerLastZxid， 也就是不需要同步 */ packetToSend = Leader.DIFF; zxidToSend = peerLastZxid; } else if (proposals.size() != 0) { // peerLastZxid 介于 minCommittedLog ，maxCommittedLog 中间 if ((maxCommittedLog &gt;= peerLastZxid) &amp;&amp; (minCommittedLog &lt;= peerLastZxid)) { /** * 在遍历 proposals 时，用来记录上一个 proposal 的 zxid */ long prevProposalZxid = minCommittedLog; boolean firstPacket=true; packetToSend = Leader.DIFF; zxidToSend = maxCommittedLog; for (Proposal propose: proposals) { // 跳过 follower 已经存在的提案 if (propose.packet.getZxid() &lt;= peerLastZxid) { prevProposalZxid = propose.packet.getZxid(); continue; } else { if (firstPacket) { firstPacket = false; if (prevProposalZxid &lt; peerLastZxid) { /** * 此时说明有部分 proposals 提案在 leader 节点上不存在，则需告诉 follower 丢弃这部分 proposals * 也就是告诉 follower 先执行回滚 TRUNC ，需要回滚到 prevProposalZxid 处，也就是 follower 需要丢弃 prevProposalZxid ~ peerLastZxid 范围内的数据 * 剩余的 proposals 则通过 DIFF 进行同步 */ packetToSend = Leader.TRUNC; zxidToSend = prevProposalZxid; updates = zxidToSend; } } /** * 将剩余待 DIFF 同步的提案放入到队列中，等待发送 */ queuePacket(propose.packet); /** * 每个提案后对应一个 COMMIT 报文 */ QuorumPacket qcommit = new QuorumPacket(Leader.COMMIT, propose.packet.getZxid(), null, null); queuePacket(qcommit); } } } else if (peerLastZxid &gt; maxCommittedLog) { /** * follower 的 zxid 比 leader 大 ，则告诉 follower 执行 TRUNC 回滚 */ packetToSend = Leader.TRUNC; zxidToSend = maxCommittedLog; updates = zxidToSend; } else { } } } finally { rl.unlock(); } QuorumPacket newLeaderQP = new QuorumPacket(Leader.NEWLEADER, ZxidUtils.makeZxid(newEpoch, 0), null, null); if (getVersion() &lt; 0x10000) { oa.writeRecord(newLeaderQP, &quot;packet&quot;); } else { // 数据同步完成之后会发送 NEWLEADER 信息 queuedPackets.add(newLeaderQP); } bufferedOutput.flush(); //Need to set the zxidToSend to the latest zxid if (packetToSend == Leader.SNAP) { zxidToSend = leader.zk.getZKDatabase().getDataTreeLastProcessedZxid(); } /** * 发送数据同步方式信息，告诉 follower 按什么方式进行数据同步 */ oa.writeRecord(new QuorumPacket(packetToSend, zxidToSend, null, null), &quot;packet&quot;); bufferedOutput.flush(); /* if we are not truncating or sending a diff just send a snapshot */ if (packetToSend == Leader.SNAP) { /** * 如果是全量同步的话，则将 leader 本地数据序列化写入 follower 的输出流 */ leader.zk.getZKDatabase().serializeSnapshot(oa); oa.writeString(&quot;BenWasHere&quot;, &quot;signature&quot;); } bufferedOutput.flush(); /** * 开启个线程执行 packet 发送 */ sendPackets(); /** * 接收 follower ack 响应 */ qp = new QuorumPacket(); ia.readRecord(qp, &quot;packet&quot;); /** * 阻塞等待过半的 follower ack */ leader.waitForNewLeaderAck(getSid(), qp.getZxid(), getLearnerType()); /** * leader 向 follower 发送 UPTODATE，告知其可对外提供服务 */ queuedPackets.add(new QuorumPacket(Leader.UPTODATE, -1, null, null)); // 省略 } } 从上述代码可以看出 leader 和 follower 在进行数据同步时会通过 peerLastZxid 与 maxCommittedLog， minCommittedLog 两个值比较最终决定数据同步方式。 DIFF(差异化同步) follower 的 peerLastZxid 等于 leader 的 peerLastZxid 此时说明 follower 与 leader 数据一致，采用 DIFF 方式同步，也即是无需同步 follower 的 peerLastZxid 介于 maxCommittedLog， minCommittedLog 两者之间 此时说明 follower 与 leader 数据存在差异，需对差异的部分进行同步；首先 leader 会向 follower 发送 DIFF 报文告知其同步方式，随后会发送差异的提案及提案提交报文 交互流程如下： Leader Follower | DIFF | | --------------------&gt; | | PROPOSAL | | --------------------&gt; | | COMMIT | | --------------------&gt; | | PROPOSAL | | --------------------&gt; | | COMMIT | | --------------------&gt; | 示例： 假设 leader 节点的提案缓存队列对应的 zxid 依次是： 0x500000001, 0x500000002, 0x500000003, 0x500000004, 0x500000005 而 follower 节点的 peerLastZxid 为 0x500000003，则需要将 0x500000004， 0x500000005 两个提案进行同步；那么数据包发送过程如下表： 报文类型 ZXID DIFF 0x500000005 PROPOSAL 0x500000004 COMMIT 0x500000004 PROPOSAL 0x500000005 COMMIT 0x500000005 TRUNC+DIFF(先回滚再差异化同步) 在上文 DIFF 差异化同步时会存在一个特殊场景就是 虽然 follower 的 peerLastZxid 介于 maxCommittedLog， minCommittedLog 两者之间，但是 follower 的 peerLastZxid 在 leader 节点中不存在； 此时 leader 需告知 follower 先回滚到 peerLastZxid 的前一个 zxid, 回滚后再进行差异化同步。 交互流程如下： Leader Follower | TRUNC | | --------------------&gt; | | PROPOSAL | | --------------------&gt; | | COMMIT | | --------------------&gt; | | PROPOSAL | | --------------------&gt; | | COMMIT | | --------------------&gt; | 示例： 假设集群中三台节点 A, B, C 某一时刻 A 为 Leader 选举周期为 5, zxid 包括： (0x500000004, 0x500000005, 0x500000006); 假设某一时刻 leader A 节点在处理完事务为 0x500000007 的请求进行广播时 leader A 节点服务器宕机导致 0x500000007 该事物没有被同步出去；在集群进行下一轮选举之后 B 节点成为新的 leader，选举周期为 6 对外提供服务处理了新的事务请求包括 0x600000001， 0x600000002； 集群节点 ZXID 列表 A 0x500000004, 0x500000005, 0x500000006, 0x500000007 B 0x500000004, 0x500000005, 0x500000006, 0x600000001， 0x600000002 C 0x500000004, 0x500000005, 0x500000006, 0x600000001， 0x600000002 此时节点 A 在重启加入集群后，在与 leader B 节点进行数据同步时会发现事务 0x500000007 在 leader 节点中并不存在，此时 leader 告知 A 需先回滚事务到 0x500000006，在差异同步事务 0x600000001，0x600000002；那么数据包发送过程如下表： 报文类型 ZXID TRUNC 0x500000006 PROPOSAL 0x600000001 COMMIT 0x600000001 PROPOSAL 0x600000002 COMMIT 0x600000002 TRUNC(回滚同步) 若 follower 的 peerLastZxid 大于 leader 的 maxCommittedLog，则告知 follower 回滚至 maxCommittedLog； 该场景可以认为是 TRUNC+DIFF 的简化模式 交互流程如下： Leader Follower | TRUNC | | --------------------&gt; | SNAP(全量同步) 若 follower 的 peerLastZxid 小于 leader 的 minCommittedLog 或者 leader 节点上不存在提案缓存队列时，将采用 SNAP 全量同步方式。 该模式下 leader 首先会向 follower 发送 SNAP 报文，随后从内存数据库中获取全量数据序列化传输给 follower， follower 在接收全量数据后会进行反序列化加载到内存数据库中。 交互流程如下： Leader Follower | SNAP | | --------------------&gt; | | DATA | | --------------------&gt; | leader 在完成数据同步之后，会向 follower 发送 NEWLEADER 报文，在收到过半的 follower 响应的 ACK 之后此时说明过半的节点完成了数据同步，接下来 leader 会向 follower 发送 UPTODATE 报文告知 follower 节点可以对外提供服务了，此时 leader 会启动 zk server 开始对外提供服务。 FOLLOWER 数据同步 下面我们在看下数据同步阶段 FOLLOWER 是如何处理的，参考 Learner.syncWithLeader protected void syncWithLeader(long newLeaderZxid) throws IOException, InterruptedException{ QuorumPacket ack = new QuorumPacket(Leader.ACK, 0, null, null); QuorumPacket qp = new QuorumPacket(); long newEpoch = ZxidUtils.getEpochFromZxid(newLeaderZxid); /** * 接收 leader 发送的数据同步方式报文 */ readPacket(qp); synchronized (zk) { if (qp.getType() == Leader.DIFF) { } else if (qp.getType() == Leader.SNAP) { // 执行加载全量数据 } else if (qp.getType() == Leader.TRUNC) { // 执行回滚 } else { } outerLoop: while (self.isRunning()) { readPacket(qp); switch(qp.getType()) { case Leader.PROPOSAL: // 处理提案 break; case Leader.COMMIT: // commit proposal break; case Leader.INFORM: // 忽略 break; case Leader.UPTODATE: // 设置 zk server self.cnxnFactory.setZooKeeperServer(zk); // 退出循环 break outerLoop; case Leader.NEWLEADER: // Getting NEWLEADER here instead of in discovery /** * follower 响应 NEWLEADER ACK */ writePacket(new QuorumPacket(Leader.ACK, newLeaderZxid, null, null), true); break; } } } ack.setZxid(ZxidUtils.makeZxid(newEpoch, 0)); writePacket(ack, true); // 启动 zk server zk.startup(); } 从上述代码中可以看出 follower 在数据同步阶段的处理流程如下： follower 接收 leader 发送的数据同步方式（DIFF/TRUNC/SANP）报文并进行相应处理 当 follower 收到 leader 发送的 NEWLEADER 报文后，会向 leader 响应 ACK (leader 在收到过半的 ACK 消息之后会发送 UPTODATE) 当 follower 收到 leader 发送的 UPTODATE 报文后，说明此时可以对外提供服务，此时将启动 zk server 小结最后用一张图总结下 zk 在完成选举后数据同步的过程如下图所示：","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.hxlzpnyist.site/tags/zookeeper/"}],"keywords":[]},{"title":"zookeeper-选举源码分析","slug":"zookeeper-选举源码分析","date":"2019-04-20T01:47:05.000Z","updated":"2019-06-21T06:48:44.040Z","comments":true,"path":"2019/04/20/zookeeper-选举源码分析/","link":"","permalink":"https://www.hxlzpnyist.site/2019/04/20/zookeeper-选举源码分析/","excerpt":"","text":"在 zookeeper 集群中发生选举的场景有以下三种： 集群启动时 Leader 节点重启时 Follower 节点重启时 本文主要针对集群启动时发生的选举实现进行分析。 ZK 集群中节点在启动时会调用QuorumPeer.start方法 public synchronized void start() { /** * 加载数据文件，获取 lastProcessedZxid, currentEpoch，acceptedEpoch */ loadDataBase(); /** * 启动主线程 用于处理客户端连接请求 */ cnxnFactory.start(); /** * 开始 leader 选举; 会相继创建选举算法的实现，创建当前节点与集群中其他节点选举通信的网络IO，并启动相应工作线程 */ startLeaderElection(); /** * 启动 QuorumPeer 线程，监听当前节点服务状态 */ super.start(); } 加载数据文件在 loadDataBase 方法中，ZK 会通过加载数据文件获取 lastProcessedZxid , 并通过读取 currentEpoch , acceptedEpoch 文件来获取相对应的值；若上述两文件不存在，则以 lastProcessedZxid 的高 32 位作为 currentEpoch , acceptedEpoch 值并写入对应文件中。 初始选举环境synchronized public void startLeaderElection() { try { // 创建投票 currentVote = new Vote(myid, getLastLoggedZxid(), getCurrentEpoch()); } catch(IOException e) { } // 从集群中节点列表，查找当前节点与其他进行信息同步的地址 for (QuorumServer p : getView().values()) { if (p.id == myid) { myQuorumAddr = p.addr; break; } } if (myQuorumAddr == null) { throw new RuntimeException(&quot;My id &quot; + myid + &quot; not in the peer list&quot;); } // electionType == 3 this.electionAlg = createElectionAlgorithm(electionType); } protected Election createElectionAlgorithm(int electionAlgorithm){ Election le=null; //TODO: use a factory rather than a switch switch (electionAlgorithm) { // 忽略其他算法的实现 case 3: /** * 创建 QuorumCnxManager 实例，并启动 QuorumCnxManager.Listener 线程用于与集群中其他节点进行选举通信; */ qcm = createCnxnManager(); QuorumCnxManager.Listener listener = qcm.listener; if(listener != null){ listener.start(); /** * 创建选举算法 FastLeaderElection 实例 */ le = new FastLeaderElection(this, qcm); } else { LOG.error(&quot;Null listener when initializing cnx manager&quot;); } break; default: assert false; } return le; } 初始节点的相关实例之后，执行 super.start() 方法，因 QuorumPeer 类继承 ZooKeeperThread 故会启动 QuorumPeer 线程 public void run() { // 代码省略 try { /* * Main loop */ while (running) { switch (getPeerState()) { case LOOKING: LOG.info(&quot;LOOKING&quot;); if (Boolean.getBoolean(&quot;readonlymode.enabled&quot;)) { // 只读模式下代码省略 } else { try { setBCVote(null); setCurrentVote(makeLEStrategy().lookForLeader()); } catch (Exception e) { LOG.warn(&quot;Unexpected exception&quot;, e); setPeerState(ServerState.LOOKING); } } break; // 忽略其他状态下的处理逻辑 } } } finally { } } 选举从上述代码可以看出 QuorumPeer 线程在运行过程中轮询监听当前节点的状态并进行相应的逻辑处理，集群启动时节点状态为 LOOKING (也就是选举 Leader 过程)，此时会调用 FastLeaderElection.lookForLeader 方法 （也是投票选举算法的核心）简化后源码如下： public Vote lookForLeader() throws InterruptedException { // 忽略 try { HashMap&lt;Long, Vote&gt; recvset = new HashMap&lt;Long, Vote&gt;(); HashMap&lt;Long, Vote&gt; outofelection = new HashMap&lt;Long, Vote&gt;(); int notTimeout = finalizeWait; synchronized(this){ // logicalclock 逻辑时钟加一 logicalclock.incrementAndGet(); /** * 更新提案信息，用于后续投票；集群启动节点默认选举自身为 Leader */ updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); } /** * 发送选举投票提案 */ sendNotifications(); /* * Loop in which we exchange notifications until we find a leader */ while ((self.getPeerState() == ServerState.LOOKING) &amp;&amp; (!stop)){ /* * Remove next notification from queue, times out after 2 times * the termination time */ /** * 从 recvqueue 队列中获取外部节点的选举投票信息 */ Notification n = recvqueue.poll(notTimeout, TimeUnit.MILLISECONDS); /* * Sends more notifications if haven&#39;t received enough. * Otherwise processes new notification. */ if(n == null){ /** * 检查上一次发送的选举投票信息是否全部发送； * 若已发送则重新在发送一遍，反之说明当前节点与集群中其他节点未连接，则执行 connectAll() 建立连接 */ if(manager.haveDelivered()){ sendNotifications(); } else { manager.connectAll(); } /* * Exponential backoff */ int tmpTimeOut = notTimeout*2; notTimeout = (tmpTimeOut &lt; maxNotificationInterval? tmpTimeOut : maxNotificationInterval); LOG.info(&quot;Notification time out: &quot; + notTimeout); } else if(self.getVotingView().containsKey(n.sid)) { /** * 只处理同一集群中节点的投票请求 */ switch (n.state) { case LOOKING: // If notification &gt; current, replace and send messages out if (n.electionEpoch &gt; logicalclock.get()) { /** * 外部投票选举周期大于当前节点选举周期 * * step1 : 更新选举周期值 * step2 : 清空已收到的选举投票数据 * step3 : 选举投票 PK，选举规则参见 totalOrderPredicate 方法 * step4 : 变更选举投票并发送 */ logicalclock.set(n.electionEpoch); recvset.clear(); if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) { updateProposal(n.leader, n.zxid, n.peerEpoch); } else { updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch()); } sendNotifications(); } else if (n.electionEpoch &lt; logicalclock.get()) { // 丢弃小于当前选举周期的投票 break; } else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch, proposedLeader, proposedZxid, proposedEpoch)) { /** * 同一选举周期 * * step1 : 选举投票 PK，选举规则参见 totalOrderPredicate 方法 * step2 : 变更选举投票并发送 */ updateProposal(n.leader, n.zxid, n.peerEpoch); sendNotifications(); } /** * 记录外部选举投票信息 */ recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch)); /** * 统计选举投票结果，判断是否可以结束此轮选举 */ if (termPredicate(recvset, new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch))) { // ...... if (n == null) { /** * 选举结束判断当前节点状态; 若提案的 leader == myid 则 state = LEADING, 反之为 FOLLOWING */ self.setPeerState((proposedLeader == self.getId()) ? ServerState.LEADING: learningState()); // 变更当前投票信息 Vote endVote = new Vote(proposedLeader, proposedZxid, logicalclock.get(), proposedEpoch); leaveInstance(endVote); return endVote; } } break; case OBSERVING: LOG.debug(&quot;Notification from observer: &quot; + n.sid); break; case FOLLOWING: case LEADING: // ...... break; default: LOG.warn(&quot;Notification state unrecognized: {} (n.state), {} (n.sid)&quot;, n.state, n.sid); break; } } else { LOG.warn(&quot;Ignoring notification from non-cluster member &quot; + n.sid); } } return null; } finally { // ...... } } 从 lookForLeader 方法的实现可以看出，选举流程如下： 发送内部投票 内部投票发送逻辑参考后续小节 接收外部投票 接收外部投票逻辑参考后续小节 选举投票 PK 当接收到外部节点投票信息后会与内部投票信息进行 PK 已确定投票优先权；PK 规则参见 totalOrderPredicate 方法如下 protected boolean totalOrderPredicate(long newId, long newZxid, long newEpoch, long curId, long curZxid, long curEpoch) { if(self.getQuorumVerifier().getWeight(newId) == 0){ return false; } /* * We return true if one of the following three cases hold: * 1- New epoch is higher * 2- New epoch is the same as current epoch, but new zxid is higher * 3- New epoch is the same as current epoch, new zxid is the same * as current zxid, but server id is higher. */ return ((newEpoch &gt; curEpoch) || ((newEpoch == curEpoch) &amp;&amp; ((newZxid &gt; curZxid) || ((newZxid == curZxid) &amp;&amp; (newId &gt; curId))))); } 从其实现可以看出选举投票 PK 规则如下： * 比较外部投票与内部投票的选举周期值，选举周期大的值优先 * 若选举周期值一致，则比较事务 ID； 事务 ID 最新的优先 * 若选举周期值一致且事务 ID 值相同，则比较投票节点的 server id; server id 最大的优先 统计选举投票 当接收到外部投票之后，都会统计下此轮选举的投票情况并判断是否可结束选举; 参考 termPredicate 方法 protected boolean termPredicate( HashMap&lt;Long, Vote&gt; votes, Vote vote) { HashSet&lt;Long&gt; set = new HashSet&lt;Long&gt;(); /** * 统计接收的投票中与当前节点所推举 leader 投票一致的个数 */ for (Map.Entry&lt;Long,Vote&gt; entry : votes.entrySet()) { if (vote.equals(entry.getValue())){ set.add(entry.getKey()); } } /** * 如果超过一半的投票一致 则说明可以终止本次选举 */ return self.getQuorumVerifier().containsQuorum(set); } 确认节点角色 当此轮选举结束之后，通过判断所推举的 leader server id 是否与当前节点 server id 相等； 若相等则说明当前节点为 leader, 反之为 follower。 发送接收投票 上文中主要聊了下 ZK 选举算法的核心部分，下面接着看下集群节点在选举过程中是如何发送自己的投票和接收外部的投票及相关处理逻辑。 首先通过 FastLeaderElection.sendNotifications 方法看下发送投票逻辑： private void sendNotifications() { for (QuorumServer server : self.getVotingView().values()) { long sid = server.id; /** * 发送投票通知信息 * * leader : 被推举的服务器 myid * zxid : 被推举的服务器 zxid * electionEpoch : 当前节点选举周期 * ServerState state : 当前节点状态 * sid : 消息接收方 myid * peerEpoch : 被推举的服务器 epoch */ ToSend notmsg = new ToSend(ToSend.mType.notification, proposedLeader, proposedZxid, logicalclock.get(), QuorumPeer.ServerState.LOOKING, sid, proposedEpoch); /** * 将消息添加到队列 sendqueue 中; * * @see Messenger.WorkerSender sendqueue 队列会被 WorkerSender 消费 */ sendqueue.offer(notmsg); } } 从实现可以看出节点在启动阶段会将自身信息封装为 ToSend 实例（也就是选举自身为 leader）并添加到队列 FastLeaderElection.sendqueue 中；那么此时我们会问到 FastLeaderElection.sendqueue 队列中的消息被谁消费处理呢 ？ 让我们回过头看下节点在启动初始化选举环境时创建 QuorumCnxManager, FastLeaderElection 实例的过程。 PS : FastLeaderElection.sendqueue 队列中消息被谁消费 ？ QuorumCnxManagerpublic QuorumCnxManager(final long mySid, Map&lt;Long,QuorumPeer.QuorumServer&gt; view, QuorumAuthServer authServer, QuorumAuthLearner authLearner, int socketTimeout, boolean listenOnAllIPs, int quorumCnxnThreadsSize, boolean quorumSaslAuthEnabled, ConcurrentHashMap&lt;Long, SendWorker&gt; senderWorkerMap) { this.senderWorkerMap = senderWorkerMap; this.recvQueue = new ArrayBlockingQueue&lt;Message&gt;(RECV_CAPACITY); this.queueSendMap = new ConcurrentHashMap&lt;Long, ArrayBlockingQueue&lt;ByteBuffer&gt;&gt;(); this.lastMessageSent = new ConcurrentHashMap&lt;Long, ByteBuffer&gt;(); String cnxToValue = System.getProperty(&quot;zookeeper.cnxTimeout&quot;); if(cnxToValue != null){ this.cnxTO = Integer.parseInt(cnxToValue); } this.mySid = mySid; this.socketTimeout = socketTimeout; this.view = view; this.listenOnAllIPs = listenOnAllIPs; initializeAuth(mySid, authServer, authLearner, quorumCnxnThreadsSize, quorumSaslAuthEnabled); listener = new Listener(); } 在 QuorumCnxManager 实例化后，会启动一个 QuorumCnxManager.Listener 线程；同时在 QuorumCnxManager 实例中存在三个重要的集合容器变量： senderWorkerMap : 发送器集合，Map 类型按 server id 分组；为集群中的每个节点分配一个 SendWorker 负责消息的发送 recvQueue ： 消息接收队列，用于存放从外部节点接收到的投票消息 queueSendMap ： 消息发送队列，Map 类型按 server id 分组；为集群中的每个节点分配一个阻塞队列存放待发送的消息，从而保证各个节点之间的消息发送互不影响 下面我们再看下 QuorumCnxManager.Listener 线程启动后，主要做了什么: public void run() { int numRetries = 0; InetSocketAddress addr; while((!shutdown) &amp;&amp; (numRetries &lt; 3)){ try { ss = new ServerSocket(); ss.setReuseAddress(true); /** * 获取当前节点的选举地址并 bind 监听等待外部节点连接 */ addr = view.get(QuorumCnxManager.this.mySid).electionAddr; ss.bind(addr); while (!shutdown) { /** * 接收外部节点连接并处理 */ Socket client = ss.accept(); setSockOpts(client); receiveConnection(client); numRetries = 0; } } catch (IOException e) { LOG.error(&quot;Exception while listening&quot;, e); numRetries++; ss.close(); Thread.sleep(1000); } } } 跟踪代码发现 receiveConnection 方法最终会调用方法 handleConnection 如下 private void handleConnection(Socket sock, DataInputStream din) throws IOException { /** * 读取外部节点的 server id * ps : 此时的 server id 是什么时候发送的呢 ？ */ Long sid = din.readLong(); if (sid &lt; this.mySid) { /** * 若外部节点的 server id 小于当前节点的 server id，则关闭此连接，改为由当前节点发起连接 * ps ： 该限制说明选举过程中，zk 只允许 server id 较大的一方去主动发起连接避免重复连接 */ SendWorker sw = senderWorkerMap.get(sid); if (sw != null) { sw.finish(); } closeSocket(sock); connectOne(sid); } else { SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if(vsw != null) vsw.finish(); /** * 按 server id 分组，为外部节点分配 SendWorker, RecvWorker 和一个消息发送队列 */ senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY)); /** * 启动外部节点对应的 SendWorker， RecvWorker 线程 */ sw.start(); rw.start(); return; } } 至此会发现 QuorumCnxManager.Listener 线程处理逻辑如下： 监听当前节点的 election address 等待接收外部节点连接 读取外部节点的 server id 并与当前节点的 server id 比较；若前者小则关闭连接，改由当前节点发起连接 反之为外部节点分配 SendWorker，RecvWorker 线程及消息发送队列 PS ： 此处我们会有个疑问外部节点的 server id 是什么时候发送过来的呢 ？ 下面我们在看下为每个外部节点开启了 SendWorker， RecvWorker 线程后做了什么： SendWorker public void run() { // 省略 try { while (running &amp;&amp; !shutdown &amp;&amp; sock != null) { ByteBuffer b = null; try { /** * 通过 server id 获取待发送给集群中节点的消息队列 */ ArrayBlockingQueue&lt;ByteBuffer&gt; bq = queueSendMap .get(sid); if (bq != null) { /** * 从队列中获取待发送的消息 */ b = pollSendQueue(bq, 1000, TimeUnit.MILLISECONDS); } else { LOG.error(&quot;No queue of incoming messages for &quot; + &quot;server &quot; + sid); break; } if(b != null){ lastMessageSent.put(sid, b); /** * 写入 socket 的输出流完成消息的发送 */ send(b); } } catch (InterruptedException e) { } } } catch (Exception e) { } } synchronized void send(ByteBuffer b) throws IOException { byte[] msgBytes = new byte[b.capacity()]; try { b.position(0); b.get(msgBytes); } catch (BufferUnderflowException be) { LOG.error(&quot;BufferUnderflowException &quot;, be); return; } /** * 发送的报文包括：消息体正文长度和消息体正文 */ dout.writeInt(b.capacity()); dout.write(b.array()); dout.flush(); } 通过代码实现我们知道 SendWorker 的职责就是从 queueSendMap 队列中获取待发送给远程节点的消息并执行发送。 PS : 此处我们会有个疑问 QuorumCnxManager.queueSendMap 中节点对应队列中待发送的消息是谁生产的呢 ？ RecvWorker public void run() { threadCnt.incrementAndGet(); try { while (running &amp;&amp; !shutdown &amp;&amp; sock != null) { /** * 读取外部节点发送的消息 * 由 SendWorker 可知前 4 字节为消息载体有效长度 */ int length = din.readInt(); if (length &lt;= 0 || length &gt; PACKETMAXSIZE) { throw new IOException( &quot;Received packet with invalid packet: &quot; + length); } /** * 读取消息体正文 */ byte[] msgArray = new byte[length]; din.readFully(msgArray, 0, length); ByteBuffer message = ByteBuffer.wrap(msgArray); /** * 将读取的消息包装为 Message 对象添加到队列 recvQueue 中 */ addToRecvQueue(new Message(message.duplicate(), sid)); } } catch (Exception e) { LOG.warn(&quot;Connection broken for id &quot; + sid + &quot;, my id = &quot; + QuorumCnxManager.this.mySid + &quot;, error = &quot; , e); } finally { LOG.warn(&quot;Interrupting SendWorker&quot;); sw.finish(); if (sock != null) { closeSocket(sock); } } } public void addToRecvQueue(Message msg) { synchronized(recvQLock) { // 省略 try { recvQueue.add(msg); } catch (IllegalStateException ie) { // This should never happen LOG.error(&quot;Unable to insert element in the recvQueue &quot; + ie); } } } 从上面可以看出 RecvWorker 线程在运行期间会接收 server id 对应的外部节点发送的消息，并将其放入 QuorumCnxManager.recvQueue 队列中。到目前为止我们基本完成对 QuorumCnxManager 核心功能的分析，发现其功能主要是负责集群中当前节点与外部节点进行选举通讯的网络 IO 操作，譬如接收外部节点选举投票和向外部节点发送内部投票。 FastLeaderElection下面我们在接着回头看下 FastLeaderElection 类实例的过程： public FastLeaderElection(QuorumPeer self, QuorumCnxManager manager){ this.stop = false; this.manager = manager; starter(self, manager); } private void starter(QuorumPeer self, QuorumCnxManager manager) { this.self = self; proposedLeader = -1; proposedZxid = -1; sendqueue = new LinkedBlockingQueue&lt;ToSend&gt;(); recvqueue = new LinkedBlockingQueue&lt;Notification&gt;(); this.messenger = new Messenger(manager); } Messenger(QuorumCnxManager manager) { /** * 启动 WorkerSender 线程用于发送消息 */ this.ws = new WorkerSender(manager); Thread t = new Thread(this.ws, &quot;WorkerSender[myid=&quot; + self.getId() + &quot;]&quot;); t.setDaemon(true); t.start(); /** * 启动 WorkerReceiver 线程用于接收消息 */ this.wr = new WorkerReceiver(manager); t = new Thread(this.wr, &quot;WorkerReceiver[myid=&quot; + self.getId() + &quot;]&quot;); t.setDaemon(true); t.start(); } 从 FastLeaderElection 实例化过程我们知道，其内部分别启动了线程 WorkerSender，WorkerReceiver ；那么接下来看下这两个线程具体做什么吧。 WorkerSenderpublic void run() { while (!stop) { try { /** * 从 sendqueue 队列中获取 ToSend 待发送的消息 */ ToSend m = sendqueue.poll(3000, TimeUnit.MILLISECONDS); if(m == null) continue; process(m); } catch (InterruptedException e) { break; } } LOG.info(&quot;WorkerSender is down&quot;); } void process(ToSend m) { // 将 ToSend 转换为 40字节 ByteBuffer ByteBuffer requestBuffer = buildMsg(m.state.ordinal(), m.leader, m.zxid, m.electionEpoch, m.peerEpoch); // 交由 QuorumCnxManager 执行发送 manager.toSend(m.sid, requestBuffer); } 看了 WorkerSender 的实现是不是明白了什么？ 还记得上文中 FastLeaderElection.sendNotifications 方法执行发送通知的时候的疑惑吗 ？ FastLeaderElection.sendqueue 队列产生的消息就是被 WorkerSender 线程所消费处理, WorkerSender 会将消息转发至 QuorumCnxManager 处理 public void toSend(Long sid, ByteBuffer b) { /* * If sending message to myself, then simply enqueue it (loopback). * 如果是发给自己的投票，则将其添加到接收队列中等待处理 */ if (this.mySid == sid) { b.position(0); addToRecvQueue(new Message(b.duplicate(), sid)); /* * Otherwise send to the corresponding thread to send. */ } else { /* * Start a new connection if doesn&#39;t have one already. */ ArrayBlockingQueue&lt;ByteBuffer&gt; bq = new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY); ArrayBlockingQueue&lt;ByteBuffer&gt; bqExisting = queueSendMap.putIfAbsent(sid, bq); // 将发送的消息放入对应的队列中，若队列满了则将队列头部元素移除 if (bqExisting != null) { addToSendQueue(bqExisting, b); } else { addToSendQueue(bq, b); } connectOne(sid); } } private void addToSendQueue(ArrayBlockingQueue&lt;ByteBuffer&gt; queue, ByteBuffer buffer) { // 省略 try { // 将消息插入节点对应的队列中 queue.add(buffer); } catch (IllegalStateException ie) { } } QuorumCnxManager 在收到 FastLeaderElection.WorkerSender 转发的消息时，会判断当前消息是否发给自己的投票，若是则将消息添加到接收队列中，反之会将消息添加到 queueSendMap 对应 server id 的队列中；看到这里的时候是不是就明白了在 QuorumCnxManager.SendWorker 分析时候的疑惑呢 。 这个时候投票消息未必能够发送出去，因为当前节点与外部节点的通道是否已建立还未知，所以继续执行 connectOne synchronized public void connectOne(long sid){ /** * 判断当前服务节点是否与 sid 外部服务节点建立连接;有可能对方先发起连接 * 若已连接则等待后续处理，反之发起连接 */ if (!connectedToPeer(sid)){ InetSocketAddress electionAddr; if (view.containsKey(sid)) { electionAddr = view.get(sid).electionAddr; } else { LOG.warn(&quot;Invalid server id: &quot; + sid); return; } try { LOG.debug(&quot;Opening channel to server &quot; + sid); Socket sock = new Socket(); setSockOpts(sock); sock.connect(view.get(sid).electionAddr, cnxTO); LOG.debug(&quot;Connected to server &quot; + sid); initiateConnection(sock, sid); } catch (UnresolvedAddressException e) { } catch (IOException e) { } } else { LOG.debug(&quot;There is a connection already for server &quot; + sid); } } public boolean connectedToPeer(long peerSid) { return senderWorkerMap.get(peerSid) != null; } private boolean startConnection(Socket sock, Long sid) throws IOException { DataOutputStream dout = null; DataInputStream din = null; try { /** * 发送当前节点的 server id，需告知对方我是哪台节点 */ dout = new DataOutputStream(sock.getOutputStream()); dout.writeLong(this.mySid); dout.flush(); din = new DataInputStream( new BufferedInputStream(sock.getInputStream())); } catch (IOException e) { LOG.warn(&quot;Ignoring exception reading or writing challenge: &quot;, e); closeSocket(sock); return false; } // 只允许 sid 值大的服务器去主动和其他服务器连接，否则断开连接 if (sid &gt; this.mySid) { LOG.info(&quot;Have smaller server identifier, so dropping the &quot; + &quot;connection: (&quot; + sid + &quot;, &quot; + this.mySid + &quot;)&quot;); closeSocket(sock); // Otherwise proceed with the connection } else { SendWorker sw = new SendWorker(sock, sid); RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if(vsw != null) vsw.finish(); senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY)); sw.start(); rw.start(); return true; } return false; } 从上述代码可以看出节点在与外部节点连接后会先发送 myid 报文告知对方我是哪个节点（这也是为什么 QuorumCnxManager.Listener 线程在接收到一个连接请求时会先执行 getLong 获取 server id 了）；同样在连接建立的时候也遵循一个原则（只允许 server id 较大的一方发起连接）。 WorkerReceiverpublic void run() { Message response; while (!stop) { // Sleeps on receive try{ /** * 从 QuorumCnxManager.recvQueue 队列中获取接收的外部投票 */ response = manager.pollRecvQueue(3000, TimeUnit.MILLISECONDS); if(response == null) continue; if(!self.getVotingView().containsKey(response.sid)){ // 忽略对方是观察者的处理 } else { // Instantiate Notification and set its attributes Notification n = new Notification(); // 将 message 转成 notification 对象 if(self.getPeerState() == QuorumPeer.ServerState.LOOKING){ // 当前节点状态为 looking，则将外部节点投票添加到 recvqueue 队列中 recvqueue.offer(n); if((ackstate == QuorumPeer.ServerState.LOOKING) &amp;&amp; (n.electionEpoch &lt; logicalclock.get())){ // 若外部节点选举周期小于当前节点选举周期则发送内部投票 Vote v = getVote(); ToSend notmsg = new ToSend(ToSend.mType.notification, v.getId(), v.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, v.getPeerEpoch()); sendqueue.offer(notmsg); } } else { // 忽略其他状态时的处理 } } } catch (InterruptedException e) { } } LOG.info(&quot;WorkerReceiver is down&quot;); } 此时我们明白 WorkerReceiver 线程在运行期间会一直从 QuorumCnxManager.recvQueue 的队列中拉取接收到的外部投票信息，若当前节点为 LOOKING 状态，则将外部投票信息添加到 FastLeaderElection.recvqueue 队列中，等待 FastLeaderElection.lookForLeader 选举算法处理投票信息。 到此我们基本明白了 ZK 集群节点发送和接收投票的处理流程，但是这个时候您是不是又有一种懵的状态呢 笑哭，我们会发现选举过程中依赖了多个线程 WorkerSender, SendWorker, WorkerReceiver, RecvWorker ，多个阻塞队列 sendqueue, recvqueue,queueSendMap,recvQueue 而且名字起的很类似，更让人懵 ； 不过莫慌，我们来通过下面的图来缕下思路 小结看了这么长时间的代码，也够累的；最后我们就来个小结吧 ： QuorumCnxManager 类主要职能是负责集群中节点与外部节点进行通信及投票信息的中转 FastLeaderElection 类是选举投票的核心实现 选举投票规则 比较外部投票与内部投票的选举周期值，选举周期大的值优先 若选举周期值一致，则比较事务 ID； 事务 ID 最新的优先 若选举周期值一致且事务 ID 值相同，则比较投票节点的 server id; server id 最大的优先 集群中节点通信时为了避免重复建立连接，遵守一个原则：连接总是由 server id 较大的一方发起","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.hxlzpnyist.site/tags/zookeeper/"}],"keywords":[]},{"title":"声网sdk体验-直播","slug":"声网sdk体验-直播","date":"2019-04-14T05:46:47.000Z","updated":"2019-06-21T06:49:10.278Z","comments":true,"path":"2019/04/14/声网sdk体验-直播/","link":"","permalink":"https://www.hxlzpnyist.site/2019/04/14/声网sdk体验-直播/","excerpt":"","text":"概述直播如何实现的？ 下面是基于声网 sdk 快速开发简单直播demo的实现。 功能设计 如上图所示为直播 Demo 实现的基本功能展示，包括： 主播端： 创建直播间 发布、取消发布视频 下播 浏览发送弹幕 访客端： 浏览直播间 观看直播 退出直播间 浏览发送弹幕 下面看下本次实现的简易架构图： 实现在实现之前我们需要创建 Agora 账号并获取 App ID（参见声网的开发者中心）。 主播端创建直播间 本次实现对于直播间的创建只是简单记录下直播间的名称 存储直播间名称protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 获取直播间名称 String room = req.getParameter(&quot;room&quot;); // 新增直播间 RoomListHolder.addRoom(room); resp.setCharacterEncoding(&quot;UTF-8&quot;); resp.setContentType(&quot;application/json&quot;); resp.getWriter().write(&quot;true&quot;); } Agora SDK 集成 // 创建 Agora Client var client = AgoraRTC.createClient({mode: &#39;interop&#39;}); // 初始化 client，并在初始化成功后执行加入直播间频道 client.init(&#39;APP ID&#39;, function () { // 加入直播间频道 client.join(null, room, null, function (uid) { console.log(&quot;用户 &quot; + uid + &quot;创建了直播间 &quot; + room); // 执行本地视频发布 }); }); 发布视频 主播在完成直播间的创建之后，基于 Agora SDK 实现本地视频的发布，这样当有订阅该直播间频道的用户将会获取视频流。 获取本地音频设备在发布视频前，需要获取本地的音频设备，也即是麦克风，摄像头。 AgoraRTC.getDevices(function (devices) { for (var i = 0; i !== devices.length; ++i) { var device = devices[i]; if (device.kind === &#39;audioinput&#39;) { // 获取麦克风设备 media.audio = device.deviceId; } else if (device.kind === &#39;videoinput&#39;) { // 获取摄像头设备 media.video = device.deviceId; } } }); 发布视频 // 创建本地音视频流 var localStream = AgoraRTC.createStream({ streamID: uid, // Agora 分配的 uid audio: true, cameraId: camera, microphoneId: microphone, video: true, screen: false }); // 初始化音视频流 localStream.init(function () { // 指定元素 ID 播放音视频流 localStream.play(&#39;video&#39;); // 发布音视频流 client.publish(localStream, function (err) { console.log(&quot;音视频发布失败: &quot; + err); }); // 监听音视频发布事件 client.on(&#39;stream-published&#39;, function (evt) { console.log(&quot;音视频发布成功!&quot;); }); }, function (err) { console.log(&quot;&quot;, err); }); 下播 下播对于 Agora SDK 来说即是离开频道，同时从直播间列表中移除当前直播间。 client.leave(function () { // 主播执行时 会触发访客端事件 peer-leave // 访客执行时 不会触发 console.log(&quot;下播成功&quot;); // 将 room 从直播间列表中移除 $.post(&quot;/removeRoom?room=&quot; + room, {}, function(data, textStatus, jqXHR) { // do nothing }, &#39;json&#39;); }, function (err) { console.log(&quot;下播失败&quot;); }); protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 获取待移除的直播间 String room = req.getParameter(&quot;room&quot;); // 移除直播间 RoomListHolder.removeRoom(room); } 访客端 访客通过浏览直播间列表，选择自己感兴趣的主播观看。 浏览直播间// 获取直播间列表数据 $.get(&quot;/getRooms&quot;, function (data, status) { var roomHtml = &#39;&#39;; if (data == null) { roomHtml = &#39;当前没有直播间&#39;; } else { $.each(data, function (i, room) { roomHtml += &#39;&lt;div class=&quot;layui-col-md6&quot;&gt;\\n&#39; + &#39; &lt;div class=&quot;layui-card&quot;&gt;\\n&#39; + &#39; &lt;div class=&quot;layui-card-header&quot;&gt;&#39;+ room +&#39;&lt;/div&gt;\\n&#39; + &#39; &lt;div class=&quot;layui-card-body&quot;&gt;\\n&#39; + &#39; &lt;button channel=&quot;&#39;+ room +&#39;&quot; class=&quot;layui-btn layui-btn-radius layui-btn-warm view&quot;&gt;\\n&#39; + &#39; &lt;i class=&quot;layui-icon&quot;&gt;&amp;#xe652;&lt;/i&gt; 观看\\n&#39; + &#39; &lt;/button&gt;\\n&#39; + &#39; &lt;/div&gt;\\n&#39; + &#39; &lt;/div&gt;\\n&#39; + &#39; &lt;/div&gt;\\n&#39; + &#39; &#39;; }); } // 渲染 $(&#39;#roomList&#39;).html(roomHtml); }); 观看直播 访客观看直播，对于 Agora SDK 来说也就是加入直播间频道，并订阅频道视频流。 client.join(null, room, null, function (uid) { console.log(&quot;用户 &quot; + uid + &quot; 来到直播间 &quot; + room); }, function (err) { console.log(&quot;加入直播间失败&quot;) }); client.on(&#39;stream-added&#39;, function (evt) { // 主播发布视频时会触发 stream-added 事件 var stream = evt.stream; // 访客订阅 stream 流 client.subscribe(stream, function (err) { console.log(&quot;视频流订阅失败&quot;, err); }); }); client.on(&#39;stream-subscribed&#39;, function (evt) { // 主播端视频流订阅成功后触发 stram-subscribed 事件 var stream = evt.stream; // 按指定元素 ID 播放视频流 stream.play(&#39;video_remote&#39;); }); client.on(&#39;stream-removed&#39;, function (evt) { // 主播端执行 unpublish 时会触发该事件 var stream = evt.stream; // 停止视频播放 stream.stop(); }); client.on(&#39;peer-leave&#39;, function (evt) { // 主播端执行 leave 下播操作时会触发该事件 var stream = evt.stream; if (stream) { // 停止视频流播放 stream.stop(); } }); 弹幕本次只是对直播的简单实现，弹幕的功能暂时忽略吧，o(╯□╰)o 效果性能小结Agora SDK 使用体验征文大赛 | 掘金技术征文，征文活动正在进行中","categories":[],"tags":[],"keywords":[]},{"title":"重拾-Mybatis-Mapper文件解析","slug":"重拾-Mybatis-Mapper文件解析","date":"2019-03-15T03:02:41.000Z","updated":"2019-03-15T07:14:59.488Z","comments":true,"path":"2019/03/15/重拾-Mybatis-Mapper文件解析/","link":"","permalink":"https://www.hxlzpnyist.site/2019/03/15/重拾-Mybatis-Mapper文件解析/","excerpt":"","text":"前言配置示例 使用相对于类路径的资源引用 &lt;mappers&gt; &lt;mapper resource=&quot;org/mybatis/builder/AuthorMapper.xml&quot;/&gt; &lt;mapper resource=&quot;org/mybatis/builder/BlogMapper.xml&quot;/&gt; &lt;mapper resource=&quot;org/mybatis/builder/PostMapper.xml&quot;/&gt; &lt;/mappers&gt; 使用完全限定资源定位符（URL） &lt;mappers&gt; &lt;mapper url=&quot;file:///var/mappers/AuthorMapper.xml&quot;/&gt; &lt;mapper url=&quot;file:///var/mappers/BlogMapper.xml&quot;/&gt; &lt;mapper url=&quot;file:///var/mappers/PostMapper.xml&quot;/&gt; &lt;/mappers&gt; 使用映射器接口实现类的完全限定类名 &lt;mappers&gt; &lt;mapper class=&quot;org.mybatis.builder.AuthorMapper&quot;/&gt; &lt;mapper class=&quot;org.mybatis.builder.BlogMapper&quot;/&gt; &lt;mapper class=&quot;org.mybatis.builder.PostMapper&quot;/&gt; &lt;/mappers&gt; 将包内的映射器接口实现全部注册为映射器 &lt;mappers&gt; &lt;package name=&quot;org.mybatis.builder&quot;/&gt; &lt;/mappers&gt; mapper 文件解析private void mapperElement(XNode parent) throws Exception { if (parent != null) { for (XNode child : parent.getChildren()) { if (&quot;package&quot;.equals(child.getName())) { // 将包内的映射器接口实现全部注册为映射器 String mapperPackage = child.getStringAttribute(&quot;name&quot;); configuration.addMappers(mapperPackage); } else { String resource = child.getStringAttribute(&quot;resource&quot;); String url = child.getStringAttribute(&quot;url&quot;); String mapperClass = child.getStringAttribute(&quot;class&quot;); if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) { ErrorContext.instance().resource(resource); // 使用相对于类路径的资源引用 InputStream inputStream = Resources.getResourceAsStream(resource); XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); } else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) { ErrorContext.instance().resource(url); // 使用完全限定资源定位符（URL） InputStream inputStream = Resources.getUrlAsStream(url); XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments()); mapperParser.parse(); } else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) { // 使用映射器接口实现类的完全限定类名 Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); } else { throw new BuilderException(&quot;A mapper element may only specify a url, resource or class, but not more than one.&quot;); } } } } } 按 XML 映射文件解析XMLMapperBuilder 的 parse 方法执行 mapper 接口映射文件的解析 public void parse() { // 判断 resource 文件是否加载过 if (!configuration.isResourceLoaded(resource)) { // 解析 mapper 文件 configurationElement(parser.evalNode(&quot;/mapper&quot;)); // 将 resource 文件标记为已加载 configuration.addLoadedResource(resource); bindMapperForNamespace(); } parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements(); } private void configurationElement(XNode context) { try { // 获取 mapper 的命名空间 String namespace = context.getStringAttribute(&quot;namespace&quot;); if (namespace == null || namespace.equals(&quot;&quot;)) { throw new BuilderException(&quot;Mapper&#39;s namespace cannot be empty&quot;); } builderAssistant.setCurrentNamespace(namespace); // 解析 cache-ref // 从 configuration 中通过参照的缓存的命名空间获取缓存并复制到当前 mapper cacheRefElement(context.evalNode(&quot;cache-ref&quot;)); // 解析 cache // 创建 cache 实例并注册到 configuration 的 caches 容器中 cacheElement(context.evalNode(&quot;cache&quot;)); parameterMapElement(context.evalNodes(&quot;/mapper/parameterMap&quot;)); // 解析 resultMap 标签 resultMapElements(context.evalNodes(&quot;/mapper/resultMap&quot;)); sqlElement(context.evalNodes(&quot;/mapper/sql&quot;)); // 解析 sql 语句标签 buildStatementFromContext(context.evalNodes(&quot;select|insert|update|delete&quot;)); } catch (Exception e) { throw new BuilderException(&quot;Error parsing Mapper XML. The XML location is &#39;&quot; + resource + &quot;&#39;. Cause: &quot; + e, e); } } cache-ref 解析 通过配置 cache-ref 引用其他命名空间的缓存配置实例 private void cacheRefElement(XNode context) { if (context != null) { // 将当前 mapper 命名空间和参照缓存的命名空间进行绑定, 注册到 configuration 的 cacheRefMap configuration.addCacheRef(builderAssistant.getCurrentNamespace(), context.getStringAttribute(&quot;namespace&quot;)); CacheRefResolver cacheRefResolver = new CacheRefResolver(builderAssistant, context.getStringAttribute(&quot;namespace&quot;)); try { // 获取参照缓存 并绑定到当前 mapper cacheRefResolver.resolveCacheRef(); } catch (IncompleteElementException e) { configuration.addIncompleteCacheRef(cacheRefResolver); } } } Configuration 的 addCacheRef 方法如下： public void addCacheRef(String namespace, String referencedNamespace) { cacheRefMap.put(namespace, referencedNamespace); } 从上述代码发现，解析 cache-ref 标签之后会将当前命名空间和缓存参照的命名空间进行绑定注册到 cacheRefMap 容器中。 public Cache resolveCacheRef() { // 从参照的命名空间获取 cache 并复制到当前 mapper return assistant.useCacheRef(cacheRefNamespace); } public Cache useCacheRef(String namespace) { if (namespace == null) { throw new BuilderException(&quot;cache-ref element requires a namespace attribute.&quot;); } try { unresolvedCacheRef = true; // 获取参照的缓存实例 Cache cache = configuration.getCache(namespace); if (cache == null) { // 若参照的缓存实例不存在则抛出异常 throw new IncompleteElementException(&quot;No cache for namespace &#39;&quot; + namespace + &quot;&#39; could be found.&quot;); } // 将参照的缓存复制到当前缓存实例 currentCache = cache; unresolvedCacheRef = false; return cache; } catch (IllegalArgumentException e) { throw new IncompleteElementException(&quot;No cache for namespace &#39;&quot; + namespace + &quot;&#39; could be found.&quot;, e); } } 从 resolveCacheRef 的操作来看，在解析参照缓存的命名空间之后，会从 configuration 的 caches 缓存容器中获取参照缓存实例，若存在参照缓存则将其复制到当前命名空间下，反之抛出异常。 cache 解析private void cacheElement(XNode context) { if (context != null) { // 获取缓存的实现类，默认为 PERPETUAL，也就是 PerpetualCache 类 String type = context.getStringAttribute(&quot;type&quot;, &quot;PERPETUAL&quot;); Class&lt;? extends Cache&gt; typeClass = typeAliasRegistry.resolveAlias(type); // 获取缓存的回收策略，默认为 LRU 策略，也就是 LruCache String eviction = context.getStringAttribute(&quot;eviction&quot;, &quot;LRU&quot;); Class&lt;? extends Cache&gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); // 获取缓存刷新时间间隔 Long flushInterval = context.getLongAttribute(&quot;flushInterval&quot;); Integer size = context.getIntAttribute(&quot;size&quot;); boolean readWrite = !context.getBooleanAttribute(&quot;readOnly&quot;, false); boolean blocking = context.getBooleanAttribute(&quot;blocking&quot;, false); Properties props = context.getChildrenAsProperties(); // 创建缓存对象 builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); } } public Cache useNewCache(Class&lt;? extends Cache&gt; typeClass, Class&lt;? extends Cache&gt; evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) { // 设置缓存命名空间,也就是 cache 的 id // 设置缓存的实现类, 默认为 PerpetualCache // 设置缓存的回收策略，默认为 LruCache Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); // 将 cache 添加到 configuration.addCache(cache); currentCache = cache; return cache; } 解析 cache 的流程很简单，其过程如下： 获取缓存的实现类 type 属性，默认为 PerpetualCache 获取缓存的回收策略 eviction 属性， 默认为 LRU 策略 获取缓存刷新时间，size 等熟悉 通过 builderAssistant (mapper 构造助手) 创建 cache 实例 将 cache 实例注册到 configuration 的 caches 容器中 resultMap 解析 private ResultMap resultMapElement(XNode resultMapNode, List&lt;ResultMapping&gt; additionalResultMappings, Class&lt;?&gt; enclosingType) throws Exception { ErrorContext.instance().activity(&quot;processing &quot; + resultMapNode.getValueBasedIdentifier()); // 获取映射的类 String type = resultMapNode.getStringAttribute(&quot;type&quot;, resultMapNode.getStringAttribute(&quot;ofType&quot;, resultMapNode.getStringAttribute(&quot;resultType&quot;, resultMapNode.getStringAttribute(&quot;javaType&quot;)))); Class&lt;?&gt; typeClass = resolveClass(type); if (typeClass == null) { typeClass = inheritEnclosingType(resultMapNode, enclosingType); } Discriminator discriminator = null; List&lt;ResultMapping&gt; resultMappings = new ArrayList&lt;&gt;(); // 遍历 resultMap 标签下的子标签 常用的为 id, result 标签 resultMappings.addAll(additionalResultMappings); List&lt;XNode&gt; resultChildren = resultMapNode.getChildren(); for (XNode resultChild : resultChildren) { if (&quot;constructor&quot;.equals(resultChild.getName())) { processConstructorElement(resultChild, typeClass, resultMappings); } else if (&quot;discriminator&quot;.equals(resultChild.getName())) { discriminator = processDiscriminatorElement(resultChild, typeClass, resultMappings); } else { List&lt;ResultFlag&gt; flags = new ArrayList&lt;&gt;(); if (&quot;id&quot;.equals(resultChild.getName())) { flags.add(ResultFlag.ID); } // ResultMapping 存储的是 标签 result 的内容 包括java bean 属性与 db 列的映射关系 resultMappings.add(buildResultMappingFromContext(resultChild, typeClass, flags)); } } // 获取 resultMap 的 id String id = resultMapNode.getStringAttribute(&quot;id&quot;, resultMapNode.getValueBasedIdentifier()); String extend = resultMapNode.getStringAttribute(&quot;extends&quot;); Boolean autoMapping = resultMapNode.getBooleanAttribute(&quot;autoMapping&quot;); // ResultMap 存储的是 标签 resultMap 的内容 // 其包括了 ResultMapping 集合，二者一对多的关系 ResultMapResolver resultMapResolver = new ResultMapResolver(builderAssistant, id, typeClass, extend, discriminator, resultMappings, autoMapping); try { return resultMapResolver.resolve(); } catch (IncompleteElementException e) { configuration.addIncompleteResultMap(resultMapResolver); throw e; } } 按 mapper 接口解析","categories":[],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.hxlzpnyist.site/tags/Mybatis/"}],"keywords":[]},{"title":"重拾-MyBatis-配置文件解析","slug":"重拾-Mybatis-配置文件解析","date":"2019-03-14T05:44:42.000Z","updated":"2019-06-21T06:49:34.596Z","comments":true,"path":"2019/03/14/重拾-Mybatis-配置文件解析/","link":"","permalink":"https://www.hxlzpnyist.site/2019/03/14/重拾-Mybatis-配置文件解析/","excerpt":"","text":"前言我们知道在使用 Mybatis 时，我们需要通过 SqlSessionFactoryBuild 去创建 SqlSessionFactory 实例，譬如： // resource 为 mybatis 的配置文件 InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 那么我们看下 build 方法的具体实现 public SqlSessionFactory build(Reader reader, String environment, Properties properties) { try { // 创建 XMLConfigBuilder 实例并执行解析 XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties); return build(parser.parse()); } catch (Exception e) { throw ExceptionFactory.wrapException(&quot;Error building SqlSession.&quot;, e); } finally { ErrorContext.instance().reset(); try { reader.close(); } catch (IOException e) { } } } public Configuration parse() { if (parsed) { throw new BuilderException(&quot;Each XMLConfigBuilder can only be used once.&quot;); } parsed = true; parseConfiguration(parser.evalNode(&quot;/configuration&quot;)); return configuration; } Mybatis 主要通过 XMLConfigBuilder 执行对配置文件的解析，具体实现如下文： 配置文件解析private void parseConfiguration(XNode root) { try { //issue #117 read properties first // 解析 properties 标签 propertiesElement(root.evalNode(&quot;properties&quot;)); // 解析 settings 标签 Properties settings = settingsAsProperties(root.evalNode(&quot;settings&quot;)); loadCustomVfs(settings); loadCustomLogImpl(settings); // 解析 typeAliases 别名标签 typeAliasesElement(root.evalNode(&quot;typeAliases&quot;)); // 解析 plugins 插件标签 pluginElement(root.evalNode(&quot;plugins&quot;)); objectFactoryElement(root.evalNode(&quot;objectFactory&quot;)); objectWrapperFactoryElement(root.evalNode(&quot;objectWrapperFactory&quot;)); reflectorFactoryElement(root.evalNode(&quot;reflectorFactory&quot;)); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 // 解析 environments 标签 environmentsElement(root.evalNode(&quot;environments&quot;)); databaseIdProviderElement(root.evalNode(&quot;databaseIdProvider&quot;)); // 解析 typeHandlers 标签 typeHandlerElement(root.evalNode(&quot;typeHandlers&quot;)); // 解析 mappers 标签 mapperElement(root.evalNode(&quot;mappers&quot;)); } catch (Exception e) { throw new BuilderException(&quot;Error parsing SQL Mapper Configuration. Cause: &quot; + e, e); } } 从 XMLConfigBuilder 的方法 parseConfiguration 实现我们知道，MyBatis 会依次解析配置文件中的相应标签，本文将针对开发中常用的配置进行分析；主要包括 properties, typeAliases, enviroments, typeHandlers, mappers 。 properties 解析配置示例&lt;configuration&gt; &lt;!-- 可以指定 resource 属性，也可以指定 url 属性 --&gt; &lt;properties resource=&quot;org/mybatis/example/config.properties&quot;&gt; &lt;property name=&quot;username&quot; value=&quot;dev_user&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;F2Fa3!33TYyg&quot;/&gt; &lt;/properties&gt; &lt;/configuration&gt; 从配置示例可以看出 properties 属性变量的来源可以是外部的配置文件，也可以是配置文件中自定义的，也可以是 SqlSessionFactoryBuilder 的 build 方法传参譬如： public SqlSessionFactory build(InputStream inputStream, Properties properties) { return build(inputStream, null, properties); } 那么当存在同名的属性时，将采用哪种方式的属性值呢？ 解析private void propertiesElement(XNode context) throws Exception { if (context != null) { // 获取 properties 标签下的所有 property 子标签 Properties defaults = context.getChildrenAsProperties(); // 获取 resource，url 属性 String resource = context.getStringAttribute(&quot;resource&quot;); String url = context.getStringAttribute(&quot;url&quot;); // resource url 两个属性不能同时存在 if (resource != null &amp;&amp; url != null) { throw new BuilderException(&quot;The properties element cannot specify both a URL and a resource based property file reference. Please specify one or the other.&quot;); } if (resource != null) { // 加载 resource 指定的配置文件 defaults.putAll(Resources.getResourceAsProperties(resource)); } else if (url != null) { // 加载 url 指定的配置文件 defaults.putAll(Resources.getUrlAsProperties(url)); } /** * 获取传参的 properties * 构建 sqlSessionFactory 时可以传参 properties * * @see SqlSessionFactoryBuilder.build(InputStream inputStream, Properties properties) */ Properties vars = configuration.getVariables(); if (vars != null) { defaults.putAll(vars); } parser.setVariables(defaults); // 将 properties 赋值 configuration 中的 variables 变量 configuration.setVariables(defaults); } } public Properties getChildrenAsProperties() { Properties properties = new Properties(); // 遍历 properties 标签下的 propertry 子标签 for (XNode child : getChildren()) { // 获取 propertry 的 name value 属性 String name = child.getStringAttribute(&quot;name&quot;); String value = child.getStringAttribute(&quot;value&quot;); if (name != null &amp;&amp; value != null) { properties.setProperty(name, value); } } return properties; } 从 properties 标签解析的实现来看，MyBatis 加载 properties 属性的过程如下： 首先加载 properties 标签内所有子标签的 property 其次加载 properties 标签属性 resource 或 url 指定的外部属性配置 最后加载 SqlSessionFactoryBuilder 的方法 build 传参的属性配置 因此，通过方法参数传递的 properties 具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的是 properties 标签内的子标签 property 指定的属性。 typeAliases 解析 类型别名是为 Java 类型设置一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余 配置示例&lt;typeAliases&gt; &lt;typeAlias alias=&quot;Author&quot; type=&quot;domain.blog.Author&quot;/&gt; &lt;typeAlias alias=&quot;Blog&quot; type=&quot;domain.blog.Blog&quot;/&gt; &lt;typeAlias alias=&quot;Comment&quot; type=&quot;domain.blog.Comment&quot;/&gt; &lt;/typeAliases&gt; 也可以指定一个包名，MyBatis 会在包名下面搜索需要的 Java Bean，比如: &lt;typeAliases&gt; &lt;package name=&quot;domain.blog&quot;/&gt; &lt;/typeAliases&gt; 解析private void typeAliasesElement(XNode parent) { if (parent != null) { for (XNode child : parent.getChildren()) { // 如果是 package 标签，对整个包下的 java bean 进行别名处理 // 若 java bean 没有配置注解的话，使用 bean 的首字母小写类名作为别名 // 若 java bean 配置了注解，使用注解值作为别名 if (&quot;package&quot;.equals(child.getName())) { // 获取指定的包名 String typeAliasPackage = child.getStringAttribute(&quot;name&quot;); configuration.getTypeAliasRegistry().registerAliases(typeAliasPackage); } else { // 别名 String alias = child.getStringAttribute(&quot;alias&quot;); // 别名对应的类 String type = child.getStringAttribute(&quot;type&quot;); try { Class&lt;?&gt; clazz = Resources.classForName(type); if (alias == null) { // 默认别名为类名，若配置了别名注解则取注解值映射类 typeAliasRegistry.registerAlias(clazz); } else { // 通过指定的别名映射类 typeAliasRegistry.registerAlias(alias, clazz); } } catch (ClassNotFoundException e) { throw new BuilderException(&quot;Error registering typeAlias for &#39;&quot; + alias + &quot;&#39;. Cause: &quot; + e, e); } } } } } typeAliasesElement 在对 typeAliases 标签解析时，针对采用 package 和 typeAlias 两种配置方式进行了不同的解析。 下面我们先看下通过包名的配置方式 通过包名解析public void registerAliases(String packageName) { registerAliases(packageName, Object.class); } public void registerAliases(String packageName, Class&lt;?&gt; superType) { // 获取包下所有的类 ResolverUtil&lt;Class&lt;?&gt;&gt; resolverUtil = new ResolverUtil&lt;&gt;(); resolverUtil.find(new ResolverUtil.IsA(superType), packageName); Set&lt;Class&lt;? extends Class&lt;?&gt;&gt;&gt; typeSet = resolverUtil.getClasses(); for (Class&lt;?&gt; type : typeSet) { // Ignore inner classes and interfaces (including package-info.java) // Skip also inner classes. See issue #6 // 忽略内部类 接口 if (!type.isAnonymousClass() &amp;&amp; !type.isInterface() &amp;&amp; !type.isMemberClass()) { registerAlias(type); } } } public void registerAlias(Class&lt;?&gt; type) { // 别名为类名 String alias = type.getSimpleName(); // 是否配置了别名注解，若配置了则别名取注解值 Alias aliasAnnotation = type.getAnnotation(Alias.class); if (aliasAnnotation != null) { alias = aliasAnnotation.value(); } registerAlias(alias, type); } 当通过 package 指定包名时，MyBatis 会扫描包下所有的类（忽略内部类，接口），若类没有采用 @Alias 注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名, 比如 domain.blog.Author 的别名为 author；若有注解，则别名为其注解值。 public void registerAlias(String alias, Class&lt;?&gt; value) { if (alias == null) { throw new TypeException(&quot;The parameter alias cannot be null&quot;); } // issue #748 // 别名小写处理 String key = alias.toLowerCase(Locale.ENGLISH); if (typeAliases.containsKey(key) &amp;&amp; typeAliases.get(key) != null &amp;&amp; !typeAliases.get(key).equals(value)) { throw new TypeException(&quot;The alias &#39;&quot; + alias + &quot;&#39; is already mapped to the value &#39;&quot; + typeAliases.get(key).getName() + &quot;&#39;.&quot;); } // 别名与类映射 typeAliases.put(key, value); } 在完成别名的解析之后会将其注册到 typeAliasRegistry 的变量 typeAliases Map 集合中。 配置环境 environments 解析 environments 用于事务管理器及数据源相关配置 配置示例&lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;&gt; &lt;property name=&quot;...&quot; value=&quot;...&quot;/&gt; &lt;/transactionManager&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;${driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;environment id=&quot;test&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;&gt; &lt;property name=&quot;...&quot; value=&quot;...&quot;/&gt; &lt;/transactionManager&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;${driver}&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;${url}&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;${username}&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;${password}&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; 从 environments 的配置来看 MyBatis 是支持多数据源的，但每个 SqlSessionFactory 实例只能选择其中一个； 若需要连接多个数据库，就得需要创建多个 SqlSessinFactory 实例。 解析private void environmentsElement(XNode context) throws Exception { if (context != null) { if (environment == null) { /** * @see org.apache.ibatis.session.SqlSessionFactoryBuilder.build 时未指定 enviorment, 则取默认的 */ environment = context.getStringAttribute(&quot;default&quot;); } for (XNode child : context.getChildren()) { String id = child.getStringAttribute(&quot;id&quot;); // 查找与 environment 匹配的配置环境 if (isSpecifiedEnvironment(id)) { // 解析事务管理 TransactionFactory txFactory = transactionManagerElement(child.evalNode(&quot;transactionManager&quot;)); // 解析数据源 DataSourceFactory dsFactory = dataSourceElement(child.evalNode(&quot;dataSource&quot;)); // 获取数据源实例 DataSource dataSource = dsFactory.getDataSource(); Environment.Builder environmentBuilder = new Environment.Builder(id) .transactionFactory(txFactory) .dataSource(dataSource); // 设置配置环境 configuration.setEnvironment(environmentBuilder.build()); } } } } private boolean isSpecifiedEnvironment(String id) { if (environment == null) { // 若 environment 为空说明未指定当前 SqlSessionFactory 实例所需的配置环境；同时 environments 标签未配置 default 属性 throw new BuilderException(&quot;No environment specified.&quot;); } else if (id == null) { // environment 标签需要配置 id 属性 throw new BuilderException(&quot;Environment requires an id attribute.&quot;); } else if (environment.equals(id)) { // environment == id 说明当前匹配配置环境 return true; } return false; } 因 environments 支持多数据源的配置，所以在解析时会先查找匹配当前 SqlSessionFactory 的 environment; 然后在解析当前配置环境所需的事务管理器和数据源。 事务管理器解析private TransactionFactory transactionManagerElement(XNode context) throws Exception { if (context != null) { // 获取配置事务管理器的类别，也就是别名 String type = context.getStringAttribute(&quot;type&quot;); // 获取事务属性配置 Properties props = context.getChildrenAsProperties(); // 通过别名查找对应的事务管理器类并实例化 TransactionFactory factory = (TransactionFactory) resolveClass(type).newInstance(); factory.setProperties(props); return factory; } throw new BuilderException(&quot;Environment declaration requires a TransactionFactory.&quot;); } 事务管理器解析时会通过配置中指定的 type 别名去查找对应的 TransactionFactory 并实例化。 那么 MyBatis 内部内置了哪些事务管理器呢？ public Configuration() { typeAliasRegistry.registerAlias(&quot;JDBC&quot;, JdbcTransactionFactory.class); typeAliasRegistry.registerAlias(&quot;MANAGED&quot;, ManagedTransactionFactory.class); // 省略 } 从 Configuration 的构造可以看出，其构造时会通过 typeAliasRegistry 注册了别名为 JDBC,MANAGED 的两种事务管理器。 数据源解析private DataSourceFactory dataSourceElement(XNode context) throws Exception { if (context != null) { // 获取配置数据源的类别，也就是别名 String type = context.getStringAttribute(&quot;type&quot;); // 获取数据源属性配置 Properties props = context.getChildrenAsProperties(); // 通过别名查找数据源并实例化 DataSourceFactory factory = (DataSourceFactory) resolveClass(type).newInstance(); factory.setProperties(props); return factory; } throw new BuilderException(&quot;Environment declaration requires a DataSourceFactory.&quot;); } 同事务管理器一样，数据源解析时也会通过指定的别名查找对应的数据源实现类同样其在 Configuration 构造时向 typeAliasRegistry 注册了三种数据源 public Configuration() { // 省略 typeAliasRegistry.registerAlias(&quot;JNDI&quot;, JndiDataSourceFactory.class); typeAliasRegistry.registerAlias(&quot;POOLED&quot;, PooledDataSourceFactory.class); typeAliasRegistry.registerAlias(&quot;UNPOOLED&quot;, UnpooledDataSourceFactory.class); // 省略 } 类型转换器 typeHandlers 解析配置示例&lt;typeHandlers&gt; &lt;typeHandler handler=&quot;org.mybatis.example.ExampleTypeHandler&quot;/&gt; &lt;/typeHandlers&gt; &lt;typeHandlers&gt; &lt;package name=&quot;org.mybatis.example&quot;/&gt; &lt;/typeHandlers&gt; 解析private void typeHandlerElement(XNode parent) { if (parent != null) { for (XNode child : parent.getChildren()) { if (&quot;package&quot;.equals(child.getName())) { String typeHandlerPackage = child.getStringAttribute(&quot;name&quot;); typeHandlerRegistry.register(typeHandlerPackage); } else { // 映射 java 对象类型 String javaTypeName = child.getStringAttribute(&quot;javaType&quot;); // 映射 jdbc 类型 String jdbcTypeName = child.getStringAttribute(&quot;jdbcType&quot;); // 类型转换器类名 String handlerTypeName = child.getStringAttribute(&quot;handler&quot;); Class&lt;?&gt; javaTypeClass = resolveClass(javaTypeName); JdbcType jdbcType = resolveJdbcType(jdbcTypeName); Class&lt;?&gt; typeHandlerClass = resolveClass(handlerTypeName); if (javaTypeClass != null) { if (jdbcType == null) { // 指定了 java type，未指定 jdbc type typeHandlerRegistry.register(javaTypeClass, typeHandlerClass); } else { // 指定了 java type，指定了 jdbc type typeHandlerRegistry.register(javaTypeClass, jdbcType, typeHandlerClass); } } else { // 未指定 java type 按 typeHandlerClass 注册 typeHandlerRegistry.register(typeHandlerClass); } } } } } typeHandler 解析指定 javaType 和 jdbcTypepublic void register(Class&lt;?&gt; javaTypeClass, JdbcType jdbcType, Class&lt;?&gt; typeHandlerClass) { register(javaTypeClass, jdbcType, getInstance(javaTypeClass, typeHandlerClass)); } private void register(Type javaType, JdbcType jdbcType, TypeHandler&lt;?&gt; handler) { if (javaType != null) { // 一个 java type 可能会映射多个 jdbc type Map&lt;JdbcType, TypeHandler&lt;?&gt;&gt; map = typeHandlerMap.get(javaType); if (map == null || map == NULL_TYPE_HANDLER_MAP) { map = new HashMap&lt;&gt;(); typeHandlerMap.put(javaType, map); } map.put(jdbcType, handler); } // 存储 typeHandler allTypeHandlersMap.put(handler.getClass(), handler); } 当指定了 javaType 和 jdbcType 最终会将二者及 typeHandler 映射并注册到 typeHandlerMap 中，从 typeHandlerMap 的数据结构来看，javaType 可能会与多个 jdbcType 映射。 譬如 String -&gt; CHAR,VARCHAR 。 指定 javaType 未指定 jdbcTypepublic void register(Class&lt;?&gt; javaTypeClass, Class&lt;?&gt; typeHandlerClass) { // 将 type handler 实例化 register(javaTypeClass, getInstance(javaTypeClass, typeHandlerClass)); } private &lt;T&gt; void register(Type javaType, TypeHandler&lt;? extends T&gt; typeHandler) { // 获取 MappedJdbcTypes 注解 // 该注解用于设置类型转换器匹配的 jdbcType MappedJdbcTypes mappedJdbcTypes = typeHandler.getClass().getAnnotation(MappedJdbcTypes.class); if (mappedJdbcTypes != null) { // 遍历匹配的 jdbcType 并注册 for (JdbcType handledJdbcType : mappedJdbcTypes.value()) { register(javaType, handledJdbcType, typeHandler); } if (mappedJdbcTypes.includeNullJdbcType()) { register(javaType, null, typeHandler); } } else { // 未指定 jdbcType 时按 null 处理 register(javaType, null, typeHandler); } } 当类型转换器配置了 javaType 未配置 jdbcType 时，会判断类型转换器是否配置了 @MappedJdbcTypes 注解； 若配置了则使用注解值作为 jdbcType 并注册，若未配置则按 null 注册。 未指定 javaType 和 jdbcTypepublic void register(Class&lt;?&gt; typeHandlerClass) { boolean mappedTypeFound = false; // 获取 MappedTypes 注解 // 该注解用于设置类型转换器匹配的 javaType MappedTypes mappedTypes = typeHandlerClass.getAnnotation(MappedTypes.class); if (mappedTypes != null) { for (Class&lt;?&gt; javaTypeClass : mappedTypes.value()) { // 执行注册 register(javaTypeClass, typeHandlerClass); mappedTypeFound = true; } } if (!mappedTypeFound) { register(getInstance(null, typeHandlerClass)); } } 当 javaType,jdbcType 均为指定时，会判断类型转换器是否配置了 @MappedTypes 注解； 若配置了则使用注解值作为 javaType 并注册。 package 解析public void register(String packageName) { // 扫描指定包下的所有类 ResolverUtil&lt;Class&lt;?&gt;&gt; resolverUtil = new ResolverUtil&lt;&gt;(); resolverUtil.find(new ResolverUtil.IsA(TypeHandler.class), packageName); Set&lt;Class&lt;? extends Class&lt;?&gt;&gt;&gt; handlerSet = resolverUtil.getClasses(); for (Class&lt;?&gt; type : handlerSet) { //Ignore inner classes and interfaces (including package-info.java) and abstract classes // 忽略内部类 接口 抽象类 if (!type.isAnonymousClass() &amp;&amp; !type.isInterface() &amp;&amp; !Modifier.isAbstract(type.getModifiers())) { // 执行注册 register(type); } } } 当按指定包名解析时，会扫描包下的所有类（忽略内部类，接口，抽象类）并执行注册 小结本文我们主要分析了 Mybatis 配置文件中标签 properties,typeAliases,enviroments,typeHandlers 的解析过程，由于 mappers 的解析比较复杂后续在进行分析；通过本文的分析我们了解到 Configuration 实例中包括以下内容： variables : Properties 类型，存储属性变量 typeAliasRegistry : 别名注册中心，通过一个 Map 集合变量 typeAliases 存储别名与类的映射关系 environment : 配置环境，绑定事务管理器和当前数据源 typeHandlerRegistry : 类型转换器注册中心，存储 javaType 与 jdbcType,typeHandler 的映射关系，内置 jdbcType 与 typeHandler 的映射关系","categories":[],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.hxlzpnyist.site/tags/Mybatis/"}],"keywords":[]},{"title":"重拾-Spring Transaction","slug":"重拾-Spring-Transaction","date":"2019-03-05T15:07:11.000Z","updated":"2019-06-21T06:49:53.142Z","comments":true,"path":"2019/03/05/重拾-Spring-Transaction/","link":"","permalink":"https://www.hxlzpnyist.site/2019/03/05/重拾-Spring-Transaction/","excerpt":"","text":"问题面试中是不是有时经常会被问到 “Spring 事务如何管理的了解吗？” ，“Spring 事务的传播性有哪些，能聊聊它们的使用场景吗？”， “事务回滚的时候是所有异常下都会回滚吗？”； 下面我们就带着这些问题来看看 Spring 事务是如何实现的吧。 实现分析首先我们还是先通过一个使用示例，先看下 Spring 事务是如何工作的。 使用示例 本文我们先采用 TransactionProxyFactoryBean 配置的方式来看下， Spring 事务如何实现 &lt;beans&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; &gt; &lt;property name=&quot;driverClassName&quot;&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;url&quot;&gt; &lt;value&gt;url&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;username&quot;&gt; &lt;value&gt;username&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;password&quot;&gt; &lt;value&gt;password&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置事务管理 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot;&gt; &lt;ref bean=&quot;dataSource&quot;&gt;&lt;/ref&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置 jdbcTemplate --&gt; &lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot;&gt; &lt;ref bean=&quot;dataSource&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;userServiceTarget&quot; class=&quot;org.springframework.transaction.UserServiceImpl&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot;&gt; &lt;ref bean=&quot;jdbcTemplate&quot;&gt;&lt;/ref&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- TransactionProxyFactoryBean 实现了接口 InitializingBean，在初始化过程中会调用 afterPropertiesSet 1 : 创建事务拦截器 2 : 创建事务 advisor （事务的拦截切面） 3 : 创建代理 --&gt; &lt;bean id=&quot;userService&quot; class=&quot;org.springframework.transaction.interceptor.TransactionProxyFactoryBean&quot;&gt; &lt;property name=&quot;transactionManager&quot;&gt; &lt;ref bean=&quot;transactionManager&quot; /&gt; &lt;/property&gt; &lt;property name=&quot;target&quot;&gt; &lt;ref bean=&quot;userServiceTarget&quot;&gt;&lt;/ref&gt; &lt;/property&gt; &lt;property name=&quot;proxyInterfaces&quot;&gt; &lt;value&gt;org.springframework.transaction.UserService&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置事务属性 传播行为, 事务隔离级别, 是否只读, 回滚规则（哪些异常下执行回滚），key 为配置需要事务管理的方法名； 在代理目标执行的时候会通过该属性判断方法是否需要事务管理 --&gt; &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;*&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 在 TransactionProxyFactoryBean 的属性配置中如果您对 transactionAttributes 属性不熟悉的话，是不是会感觉一头雾水呢？ 这个玩意怎么配置的？ 配置格式又是什么样的呢？ 配置值有哪些呢 ？； 下面将会通过对 TransactionProxyFactoryBean 的源码分析来一一解答。 源码分析类结构 从 TransactionProxyFactoryBean 类结构我们知道，其实现了接口 InitializingBean 和 FactoryBean; 那么也就是在 TransactionProxyFactoryBean 实例化后会调用方法 afterPropertiesSet, 在获取目标对象实例时会调用方法 getObject; 下面将主要看下这两个方法的实现。 afterPropertiesSet-创建目标代理对象public void afterPropertiesSet() throws AopConfigException { // 校验 Target 目标对象 if (this.target == null) { throw new AopConfigException(&quot;Target must be set&quot;); } // 校验事务属性定义，从抛出的异常信息可以看出 Spring 在此做了强校验； // 也就是说如果没有需要 Spring 事务管理的方法，就不要采用 TransactionProxyFactoryBean 了 // 那么 transactionAttributeSource 是怎么来的呢？ 见下文分析 if (this.transactionAttributeSource == null) { throw new AopConfigException(&quot;Either &#39;transactionAttributeSource&#39; or &#39;transactionAttributes&#39; is required: &quot; + &quot;If there are no transactional methods, don&#39;t use a transactional proxy.&quot;); } // 创建事务拦截器 transactionInterceptor TransactionInterceptor transactionInterceptor = new TransactionInterceptor(); transactionInterceptor.setTransactionManager(this.transactionManager); transactionInterceptor.setTransactionAttributeSource(this.transactionAttributeSource); transactionInterceptor.afterPropertiesSet(); ProxyFactory proxyFactory = new ProxyFactory(); // 是否配置了前置拦截 if (this.preInterceptors != null) { for (int i = 0; i &lt; this.preInterceptors.length; i++) { proxyFactory.addAdvisor(GlobalAdvisorAdapterRegistry.getInstance().wrap(this.preInterceptors[i])); } } if (this.pointcut != null) { // 如果配置了 pointcut 切入点，则按配置的 pointcut 创建 advisor Advisor advice = new DefaultPointcutAdvisor(this.pointcut, transactionInterceptor); proxyFactory.addAdvisor(advice); } else { // rely on default pointcut // 创建事务拦截切面 advisor proxyFactory.addAdvisor(new TransactionAttributeSourceAdvisor(transactionInterceptor)); // could just do the following, but it&#39;s usually less efficient because of AOP advice chain caching // proxyFactory.addInterceptor(transactionInterceptor); } // 是否配置了后置拦截 if (this.postInterceptors != null) { for (int i = 0; i &lt; this.postInterceptors.length; i++) { proxyFactory.addAdvisor(GlobalAdvisorAdapterRegistry.getInstance().wrap(this.postInterceptors[i])); } } proxyFactory.copyFrom(this); proxyFactory.setTargetSource(createTargetSource(this.target)); // 设置代理的接口 if (this.proxyInterfaces != null) { proxyFactory.setInterfaces(this.proxyInterfaces); } else if (!getProxyTargetClass()) { // rely on AOP infrastructure to tell us what interfaces to proxy proxyFactory.setInterfaces(AopUtils.getAllInterfaces(this.target)); } // 创建目标对象的代理对象 this.proxy = proxyFactory.getProxy(); } 从源码中我们知道 afterPropertiesSet 主要做以下几件事： 参数有效性校验; 校验目标对象，事务属性定义 设置代理的 advisor chain, 包括用户自定义的前置拦截, 内置的事务拦截器，用户自定义的后置拦截 创建目标代理对象 在 afterPropertiesSet 的实现中有个针对 transactionAttributeSource 的非空校验，那么这个变量是何时赋值的呢 ? 还记得使用示例中的关于事务属性的定义 transactionAttributes 吗 ? setTransactionAttributes-设置事务属性定义public void setTransactionAttributes(Properties transactionAttributes) { NameMatchTransactionAttributeSource tas = new NameMatchTransactionAttributeSource(); tas.setProperties(transactionAttributes); this.transactionAttributeSource = tas; } public void setProperties(Properties transactionAttributes) { TransactionAttributeEditor tae = new TransactionAttributeEditor(); // 遍历 properties for (Iterator it = transactionAttributes.keySet().iterator(); it.hasNext(); ) { // key 为匹配的方法名 String methodName = (String) it.next(); String value = transactionAttributes.getProperty(methodName); // 解析 value tae.setAsText(value); TransactionAttribute attr = (TransactionAttribute) tae.getValue(); // 将方法名与事务属性定义匹配关联 addTransactionalMethod(methodName, attr); } } 下面我们就看下 setAsText 方法是如何解析事务属性的配置 /** * Format is PROPAGATION_NAME,ISOLATION_NAME,readOnly,+Exception1,-Exception2. * Null or the empty string means that the method is non transactional. * @see java.beans.PropertyEditor#setAsText(java.lang.String) */ public void setAsText(String s) throws IllegalArgumentException { if (s == null || &quot;&quot;.equals(s)) { setValue(null); } else { // tokenize it with &quot;,&quot; // 按 , 分割配置信息 String[] tokens = StringUtils.commaDelimitedListToStringArray(s); RuleBasedTransactionAttribute attr = new RuleBasedTransactionAttribute(); for (int i = 0; i &lt; tokens.length; i++) { String token = tokens[i]; // 以 PROPAGATION 开头，则配置事务传播性 if (token.startsWith(TransactionDefinition.PROPAGATION_CONSTANT_PREFIX)) { attr.setPropagationBehaviorName(tokens[i]); } // 以 ISOLATION 开头，则配置事务隔离级别 else if (token.startsWith(TransactionDefinition.ISOLATION_CONSTANT_PREFIX)) { attr.setIsolationLevelName(tokens[i]); } // 以 timeout_ 开头，则设置事务超时时间 else if (token.startsWith(DefaultTransactionAttribute.TIMEOUT_PREFIX)) { String value = token.substring(DefaultTransactionAttribute.TIMEOUT_PREFIX.length()); attr.setTimeout(Integer.parseInt(value)); } // 若等于 readOnly 则配置事务只读 else if (token.equals(DefaultTransactionAttribute.READ_ONLY_MARKER)) { attr.setReadOnly(true); } // 以 + 开头，则配置哪些异常下不回滚 else if (token.startsWith(DefaultTransactionAttribute.COMMIT_RULE_PREFIX)) { attr.getRollbackRules().add(new NoRollbackRuleAttribute(token.substring(1))); } // 以 - 开头，则配置哪些异常下回滚 else if (token.startsWith(DefaultTransactionAttribute.ROLLBACK_RULE_PREFIX)) { attr.getRollbackRules().add(new RollbackRuleAttribute(token.substring(1))); } else { throw new IllegalArgumentException(&quot;Illegal transaction token: &quot; + token); } } setValue(attr); } } 从 setAsText 方法的实现我们就可以搞明白在配置文件中 transactionAttributes 如何配置了，譬如： &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;*&quot;&gt;PROPAGATION_REQUIRED, ISOLATION_DEFAULT, readOnly&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 也可以这样配置： &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;*&quot;&gt;readOnly, ISOLATION_DEFAULT, PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; 也就是说 transactionAttributes 的配置只要保证 token 格式正确即可，顺序无关；但是从规范来讲建议还是保持 PROPAGATION_NAME,ISOLATION_NAME,readOnly,+Exception1,-Exception2. 的格式。 getObject-获取代理对象public Object getObject() { // proxy 对象在 afterPropertiesSet 方法执行时产生 return this.proxy; } 代理执行是否支持事务在 重拾-Spring AOP 中我们知道，当代理对象在执行的时候会先获取当前方法所匹配的 advisor (参见类 JdkDynamicAopProxy); 而 TransactionProxyFactoryBean 在创建代理对象的时候会将 TransactionInterceptor 绑定到 TransactionAttributeSourceAdvisor 上，那么我就看下 TransactionAttributeSourceAdvisor 是如何匹配方法的。 public class TransactionAttributeSourceAdvisor extends StaticMethodMatcherPointcutAdvisor { private TransactionAttributeSource transactionAttributeSource; public TransactionAttributeSourceAdvisor(TransactionInterceptor ti) { super(ti); if (ti.getTransactionAttributeSource() == null) { throw new AopConfigException(&quot;Cannot construct a TransactionAttributeSourceAdvisor using a &quot; + &quot;TransactionInterceptor that has no TransactionAttributeSource configured&quot;); } this.transactionAttributeSource = ti.getTransactionAttributeSource(); } public boolean matches(Method m, Class targetClass) { return (this.transactionAttributeSource.getTransactionAttribute(m, targetClass) != null); } } TransactionAttributeSourceAdvisor 判断方法是否匹配时，实际是由 NameMatchTransactionAttributeSource 的方法 getTransactionAttribute 来处理。 public TransactionAttribute getTransactionAttribute(Method method, Class targetClass) { // 获取目标方法名 String methodName = method.getName(); // 获取目标方法匹配的事务属性定义 TransactionAttribute attr = (TransactionAttribute) this.nameMap.get(methodName); // 如果 attr 不为空说明当前方法配置了事务属性定义，也就是当前方法需要事务管理 if (attr != null) { return attr; } else { // look up most specific name match String bestNameMatch = null; for (Iterator it = this.nameMap.keySet().iterator(); it.hasNext();) { // 判断当前方法是否匹配通配符的方式 String mappedName = (String) it.next(); if (isMatch(methodName, mappedName) &amp;&amp; (bestNameMatch == null || bestNameMatch.length() &lt;= mappedName.length())) { attr = (TransactionAttribute) this.nameMap.get(mappedName); bestNameMatch = mappedName; } } return attr; } } protected boolean isMatch(String methodName, String mappedName) { return (mappedName.endsWith(&quot;*&quot;) &amp;&amp; methodName.startsWith(mappedName.substring(0, mappedName.length() - 1))) || (mappedName.startsWith(&quot;*&quot;) &amp;&amp; methodName.endsWith(mappedName.substring(1, mappedName.length()))); } TransactionInterceptor-事务拦截在完成判断当前方法是否需要事务管理后，如果需要事务管理最终会调用 TransactionInterceptor 执行事务拦截的处理。 public final Object invoke(MethodInvocation invocation) throws Throwable { Class targetClass = (invocation.getThis() != null) ? invocation.getThis().getClass() : null; // if the transaction attribute is null, the method is non-transactional // 获取当前方法所支持的事务配置属性，若不存在则说明当前方法不需要事务管理 TransactionAttribute transAtt = this.transactionAttributeSource.getTransactionAttribute(invocation.getMethod(), targetClass); TransactionStatus status = null; TransactionStatus oldTransactionStatus = null; // create transaction if necessary if (transAtt != null) { // the transaction manager will flag an error if an incompatible tx already exists // 通过事务管理获取事务，该事务可能是新创建的也可能是当前上下文已存在的事务 // 返回事务状态 status = this.transactionManager.getTransaction(transAtt); // make the TransactionStatus available to callees oldTransactionStatus = (TransactionStatus) currentTransactionStatus.get(); currentTransactionStatus.set(status); } else { // it isn&#39;t a transactional method } Object retVal = null; try { // 目标方法执行 retVal = invocation.proceed(); } catch (Throwable ex) { // target invocation exception if (status != null) { // 异常处理 可能会执行事务的回滚 onThrowable(invocation, transAtt, status, ex); } throw ex; } finally { if (transAtt != null) { // use stack to restore old transaction status if one was set currentTransactionStatus.set(oldTransactionStatus); } } if (status != null) { // 通过事务管理执行事务提交 this.transactionManager.commit(status); } return retVal; } private void onThrowable(MethodInvocation invocation, TransactionAttribute txAtt, TransactionStatus status, Throwable ex) { // 判断异常是否需要回滚 if (txAtt.rollbackOn(ex)) { try { // 通过事务管理执行回滚 this.transactionManager.rollback(status); } catch (TransactionException tex) { logger.error(&quot;Application exception overridden by rollback exception&quot;, ex); throw tex; } } else { // Will still roll back if rollbackOnly is true // 异常不需要回滚的话 则提交事务 this.transactionManager.commit(status); } } 从 TransactionInterceptor 的处理逻辑来看，我们知道其主要做以下事情： 获取当前方法所定义的事务属性 通过事务管理器 Transaction Manager 来获取事务 目标方法执行 执行异常处理，如异常需要回滚则通过事务管理器执行事务 rollback，反之执行事务 commit 方法执行成功则执行事务 commit 也就是说 TransactionInterceptor (事务拦截器) 主要是将事务相关的动作委托给 TransactionManager （事务管理器）处理 TransactionManager-事务管理 本文是以 DataSourceTransactionManager 为例来分析事务的管理实现 getTransaction-获取事务public final TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException { // 获取事务 Object transaction = doGetTransaction(); if (definition == null) { // 若 definition == null 则采用默认的事务定义 definition = new DefaultTransactionDefinition(); } // 判断当前上下文是否开启过事务 if (isExistingTransaction(transaction)) { // 当前上下文开启过事务 // 如果当前方法匹配的事务传播性为 PROPAGATION_NEVER 说明不需要事务则抛出异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) { throw new IllegalTransactionStateException(&quot;Transaction propagation &#39;never&#39; but existing transaction found&quot;); } // 如果当前方法匹配的事务传播性为 PROPAGATION_NOT_SUPPORTED 说明该方法不应该运行在事务中，则将当前事务挂起 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) { // 将当前事务挂起 Object suspendedResources = suspend(transaction); boolean newSynchronization = (this.transactionSynchronization == SYNCHRONIZATION_ALWAYS); // 返回的事务状态为 不需要事务 return newTransactionStatus(null, false, newSynchronization, definition.isReadOnly(), debugEnabled, suspendedResources); } // 如果当前方法匹配的事务传播性为 PROPAGATION_REQUIRES_NEW 表示当前方法必须运行在它自己的事务中；将已存在的事务挂起，重新开启事务 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) { if (debugEnabled) { logger.debug(&quot;Creating new transaction, suspending current one&quot;); } // 挂起当前事务 Object suspendedResources = suspend(transaction); // 重新开启个事务 doBegin(transaction, definition); boolean newSynchronization = (this.transactionSynchronization != SYNCHRONIZATION_NEVER); // 返回的事务状态为 新建事务 return newTransactionStatus(transaction, true, newSynchronization, definition.isReadOnly(), debugEnabled, suspendedResources); } else { boolean newSynchronization = (this.transactionSynchronization != SYNCHRONIZATION_NEVER); // 其他的传播行为 表示在已存在的事务中执行 return newTransactionStatus(transaction, false, newSynchronization, definition.isReadOnly(), debugEnabled, null); } } if (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) { throw new InvalidTimeoutException(&quot;Invalid transaction timeout&quot;, definition.getTimeout()); } // 如果传播性为 PROPAGATION_MANDATORY 说明必须在事务中执行，若当前没有事务的话则抛出异常 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) { throw new IllegalTransactionStateException(&quot;Transaction propagation &#39;mandatory&#39; but no existing transaction found&quot;); } // 当前上下文不存在事务 // 若传播性为 PROPAGATION_REQUIRED 或 PROPAGATION_REQUIRES_NEW 则开启新的事务执行 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) { // 开启新的 connection 并取消自动提交，将 connection 绑定当前线程 doBegin(transaction, definition); boolean newSynchronization = (this.transactionSynchronization != SYNCHRONIZATION_NEVER); return newTransactionStatus(transaction, true, newSynchronization, definition.isReadOnly(), debugEnabled, null); } else { // &quot;empty&quot; (-&gt; no) transaction boolean newSynchronization = (this.transactionSynchronization == SYNCHRONIZATION_ALWAYS); // 返回事务状态为 不需要事务 return newTransactionStatus(null, false, newSynchronization, definition.isReadOnly(), debugEnabled, null); } } protected Object doGetTransaction() { // 判断当前线程是否开启过事务 if (TransactionSynchronizationManager.hasResource(this.dataSource)) { // 获取当前已存在的 connectoin holder ConnectionHolder holder = (ConnectionHolder) TransactionSynchronizationManager.getResource(this.dataSource); return new DataSourceTransactionObject(holder); } else { return new DataSourceTransactionObject(); } } 看到了这里，是不是突然明白 PROPAGATION (事务传播性) 是干什么的了； 简单来说, PROPAGATION 就是为了告诉 Spring 当前方法需不需要事务，是在已存在的事务中执行，还是新开启事务执行；也可以认为是继承上个方法栈的事务，还是拥有自己的事务。 TransactionManager 获取事务的过程实际就是通过当前方法定义的 PROPAGATION (事务传播性) 和当前上下文是否存在事务来判断是否需要事务，是否需要开启新的事务或者是使用当前已存在的事务。 下面看下如何开启新的事务 doBegin protected void doBegin(Object transaction, TransactionDefinition definition) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // cache to avoid repeated checks boolean debugEnabled = logger.isDebugEnabled(); // 判断 connection holder 是否为空 // 两种场景下可能为空： // 1. 上下文不存在事务的时候 // 2. 上下文已存在的事务被挂起的时候 if (txObject.getConnectionHolder() == null) { if (debugEnabled) { logger.debug(&quot;Opening new connection for JDBC transaction&quot;); } // 开启新的 connection Connection con = DataSourceUtils.getConnection(this.dataSource, false); txObject.setConnectionHolder(new ConnectionHolder(con)); } Connection con = txObject.getConnectionHolder().getConnection(); try { // apply read-only if (definition.isReadOnly()) { try { // 如果定义了只读，设置 connection 为只读 con.setReadOnly(true); } catch (Exception ex) { // SQLException or UnsupportedOperationException logger.warn(&quot;Could not set JDBC connection read-only&quot;, ex); } } // apply isolation level // 设置事务隔离级别 if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) { txObject.setPreviousIsolationLevel(new Integer(con.getTransactionIsolation())); con.setTransactionIsolation(definition.getIsolationLevel()); } // 若 connection 为自动提交则取消 if (con.getAutoCommit()) { txObject.setMustRestoreAutoCommit(true); con.setAutoCommit(false); } // 设置超时时间 if (definition.getTimeout() != TransactionDefinition.TIMEOUT_DEFAULT) { txObject.getConnectionHolder().setTimeoutInSeconds(definition.getTimeout()); } // 将当前 connection holder 绑定到当前上下文 TransactionSynchronizationManager.bindResource(this.dataSource, txObject.getConnectionHolder()); } catch (SQLException ex) { throw new CannotCreateTransactionException(&quot;Could not configure connection&quot;, ex); } } doBegin 执行开启事务的操作，在上下文不存在事务或者上下文事务被挂起的时候会新打开一个 connection, 并按照事务定义设置相关属性，譬如是否只读，取消自动提交，设置事务隔离级别，设置超时时间；最后会将 connection 绑定到当前上下文，也即当前线程。 doSuspend-事务挂起protected Object doSuspend(Object transaction) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // 将当前事务的 connection holder 置为空 txObject.setConnectionHolder(null); // 并将当前事务与上下文解绑 return TransactionSynchronizationManager.unbindResource(this.dataSource); } 事务挂起既是将当前事务的连接持有者清空并与当前上下文解绑，保证后续能够重新开启事务。 数据库操作 针对数据库的操作，本文以 Spring 提供的 jdbcTemplate 工具类进行分析。 public Object execute(final StatementCallback action) { // 若当前需要事务管理的话，那么此时获取的 connection 则是 transaction manager bind 的 connection // 这样就保证数据库操作的时候所获得的的 connection 与 事务管理的一致 Connection con = DataSourceUtils.getConnection(getDataSource()); Statement stmt = null; // 以下代码省略 此处重点关注如何获取 connection } public static Connection getConnection(DataSource ds, boolean allowSynchronization) throws CannotGetJdbcConnectionException { // 从当前上下文获取 connection holder ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(ds); if (conHolder != null) { return conHolder.getConnection(); } else { try { // 反之新打开一个 connection Connection con = ds.getConnection(); if (allowSynchronization &amp;&amp; TransactionSynchronizationManager.isSynchronizationActive()) { logger.debug(&quot;Registering transaction synchronization for JDBC connection&quot;); // use same Connection for further JDBC actions within the transaction // thread object will get removed by synchronization at transaction completion conHolder = new ConnectionHolder(con); TransactionSynchronizationManager.bindResource(ds, conHolder); TransactionSynchronizationManager.registerSynchronization(new ConnectionSynchronization(conHolder, ds)); } return con; } catch (SQLException ex) { throw new CannotGetJdbcConnectionException(&quot;Could not get JDBC connection&quot;, ex); } } } 从上述代码我们可以看到，当通过 jdbcTemplate 操作数据库时会先从当前上下文中获取 connection; 这样就保证了所获取的事务与事务拦截器的事务为同一个实例，也就是将事务交给了 Spring 来管理。 commit-事务提交public final void commit(TransactionStatus status) throws TransactionException { DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status; // 省略 else { try { try { triggerBeforeCommit(defStatus); triggerBeforeCompletion(defStatus); if (status.isNewTransaction()) { logger.info(&quot;Initiating transaction commit&quot;); // 执行事务提交 doCommit(defStatus); } } // 省略 } finally { cleanupAfterCompletion(defStatus); } } } doCommit 执行事务提交 protected void doCommit(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); if (status.isDebug()) { logger.debug(&quot;Committing JDBC transaction [&quot; + txObject.getConnectionHolder().getConnection() + &quot;]&quot;); } try { // 事务提交 txObject.getConnectionHolder().getConnection().commit(); } catch (SQLException ex) { throw new TransactionSystemException(&quot;Could not commit&quot;, ex); } } resume-事务恢复从上文的 commit 事务提交操作发现，在完成事务提交之后，还有个后置动作 cleanupAfterCompletion, 该方法会对挂起中的事务执行恢复操作。 private void cleanupAfterCompletion(DefaultTransactionStatus status) { if (status.isNewSynchronization()) { TransactionSynchronizationManager.clearSynchronization(); } if (status.isNewTransaction()) { doCleanupAfterCompletion(status.getTransaction()); } // 当存在挂起的事务时，执行恢复挂起的事务 if (status.getSuspendedResources() != null) { if (status.isDebug()) { logger.debug(&quot;Resuming suspended transaction&quot;); } resume(status.getTransaction(), status.getSuspendedResources()); } } protected void doResume(Object transaction, Object suspendedResources) { // 将挂起的事务绑定的 connection 重新绑定到当前上下文 ConnectionHolder conHolder = (ConnectionHolder) suspendedResources; TransactionSynchronizationManager.bindResource(this.dataSource, conHolder); } 事务的 resume 就是将挂起的事务重新绑定到当前上下文中。 rollback-事务回滚当 TransactionInterceptor 调用目标方法执行出现异常的时候，会进行异常处理执行方法 onThrowable private void onThrowable(MethodInvocation invocation, TransactionAttribute txAtt, TransactionStatus status, Throwable ex) { if (txAtt.rollbackOn(ex)) { try { // 异常需要回滚 this.transactionManager.rollback(status); } catch (TransactionException tex) { throw tex; } } else { // 异常不需要回滚的话 则提交事务 this.transactionManager.commit(status); } } onThrowable 方法会通过配置判断当前异常是否需要回滚。 public final void rollback(TransactionStatus status) throws TransactionException { DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status; try { try { triggerBeforeCompletion(defStatus); if (status.isNewTransaction()) { // 执行事务回滚 logger.info(&quot;Initiating transaction rollback&quot;); doRollback(defStatus); } else if (defStatus.getTransaction() != null) { if (defStatus.isDebug()) { logger.debug(&quot;Setting existing transaction rollback-only&quot;); } doSetRollbackOnly(defStatus); } else { logger.info(&quot;Should roll back transaction but cannot - no transaction available&quot;); } } catch (TransactionException ex) { triggerAfterCompletion(defStatus, TransactionSynchronization.STATUS_UNKNOWN, ex); throw ex; } triggerAfterCompletion(defStatus, TransactionSynchronization.STATUS_ROLLED_BACK, null); } finally { cleanupAfterCompletion(defStatus); } } protected void doRollback(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); try { // 执行回滚 txObject.getConnectionHolder().getConnection().rollback(); } catch (SQLException ex) { throw new TransactionSystemException(&quot;Could not rollback&quot;, ex); } } 小结此时我们基本明白了 Spring Transaction 的实现原理，下面对其实现做个小结： Spring Transaction 是基于 Spring AOP 的一种实现 Spring Transaction 通过配置创建事务 advisor 并创建目标对象代理类 目标方法执行时将会被 TransactionInterceptor 拦截 TransactionInterceptor 会委派 TransactionManager 执行事务的创建，事务提交，事务回滚的动作 TransactionManager 会根据当前方法配置的事务传播性及当前上下文是否存在事务来判断是否新建事务 TransactionManager 当新建事务时会将事务绑定到当前上下文，以保证目标方法执行时获取的事务为同一实例 TransactionManager 执行事务挂起时会将当前事务与当前上下文解除绑定关系 TransactionManager 执行事务恢复时会将已挂起的事务重新与当前上下文绑定","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.hxlzpnyist.site/tags/Spring/"}],"keywords":[]},{"title":"重拾-Spring AOP-自动代理","slug":"重拾-Spring-AOP-自动代理","date":"2019-03-04T07:17:34.000Z","updated":"2019-06-21T06:49:39.458Z","comments":true,"path":"2019/03/04/重拾-Spring-AOP-自动代理/","link":"","permalink":"https://www.hxlzpnyist.site/2019/03/04/重拾-Spring-AOP-自动代理/","excerpt":"","text":"概述在上一篇 重拾-Spring AOP 中我们会发现 Spring AOP 是通过类 ProxyFactoryBean 创建代理对象，其有个缺陷就是只能代理一个目标对象 bean, 当代理目标类过多时，配置文件臃肿不方便管理维护，因此 Spring 提供了能够实现自动创建代理的类 BeanNameAutoProxyCreator , DefaultAdvisorAutoProxyCreator ；下面我们看下二者是如何实现自动代理的。 BeanNameAutoProxyCreator BeanNameAutoProxyCreator 是通过判断当前 bean name 是否匹配，只有匹配的 bean 才会创建代理。 使用示例 Spring xml 配置 &lt;bean id=&quot;userService&quot; class=&quot;org.springframework.aop.UserServiceImpl&quot; /&gt; &lt;bean id=&quot;demoService&quot; class=&quot;org.springframework.aop.DemoServiceImpl&quot; /&gt; &lt;bean id=&quot;userBeforeAdvice&quot; class=&quot;org.springframework.aop.UserBeforeAdvice&quot; /&gt; &lt;bean id=&quot;userAfterAdvice&quot; class=&quot;org.springframework.aop.UserAfterAdvice&quot; /&gt; &lt;bean id=&quot;beanNameAutoProxyCreator&quot; class=&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt; &lt;!-- 配置要代理的 bean --&gt; &lt;property name=&quot;beanNames&quot;&gt; &lt;list&gt; &lt;value&gt;userService&lt;/value&gt; &lt;value&gt;demoService&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 配置 interceptor, advice, advisor --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;userAfterAdvice&lt;/value&gt; &lt;value&gt;userBeforeAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 测试 ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;/org/springframework/aop/aop.xml&quot;); UserService userService = (UserService) ctx.getBean(&quot;userService&quot;); userService.say(); DemoService demoService = (DemoService) ctx.getBean(&quot;demoService&quot;); demoService.demo(); 运行结果 do before advice .... do say method do after return advice .... do before advice .... do demo. do after return advice .... 实现分析类结构 如上图 BeanNameAutoProxyCreator 类结构可以看出，其实现了接口 BeanPostProcessor ; 那么我们可以大概猜测出其自动代理的实现原理与自动注入类似，都是在 bean 实例化后进行特殊的处理，下面就让我们看下源码验证下吧。 分析public Object postProcessAfterInitialization(Object bean, String name) throws BeansException { // Check for special cases. We don&#39;t want to try to autoproxy a part of the autoproxying // infrastructure, lest we get a stack overflow. if (isInfrastructureClass(bean, name) || shouldSkip(bean, name)) { logger.debug(&quot;Did not attempt to autoproxy infrastructure class &#39;&quot; + bean.getClass() + &quot;&#39;&quot;); return bean; } TargetSource targetSource = getTargetSource(bean, name); Object[] specificInterceptors = getInterceptorsAndAdvisorsForBean(bean, name); // proxy if we have advice or if a TargetSourceCreator wants to do some // fancy stuff such as pooling if (specificInterceptors != DO_NOT_PROXY || !(targetSource instanceof SingletonTargetSource)) { // handle prototypes correctly // 获取容器中配置的 advisors Advisor[] commonInterceptors = resolveInterceptorNames(); List allInterceptors = new ArrayList(); if (specificInterceptors != null) { allInterceptors.addAll(Arrays.asList(specificInterceptors)); if (commonInterceptors != null) { if (this.applyCommonInterceptorsFirst) { allInterceptors.addAll(0, Arrays.asList(commonInterceptors)); } else { allInterceptors.addAll(Arrays.asList(commonInterceptors)); } } } if (logger.isInfoEnabled()) { int nrOfCommonInterceptors = commonInterceptors != null ? commonInterceptors.length : 0; int nrOfSpecificInterceptors = specificInterceptors != null ? specificInterceptors.length : 0; logger.info(&quot;Creating implicit proxy for bean &#39;&quot; + name + &quot;&#39; with &quot; + nrOfCommonInterceptors + &quot; common interceptors and &quot; + nrOfSpecificInterceptors + &quot; specific interceptors&quot;); } ProxyFactory proxyFactory = new ProxyFactory(); // copy our properties (proxyTargetClass) inherited from ProxyConfig proxyFactory.copyFrom(this); if (!getProxyTargetClass()) { // Must allow for introductions; can&#39;t just set interfaces to // the target&#39;s interfaces only. // 添加设置代理的接口 Class[] targetsInterfaces = AopUtils.getAllInterfaces(bean); for (int i = 0; i &lt; targetsInterfaces.length; i++) { proxyFactory.addInterface(targetsInterfaces[i]); } } for (Iterator it = allInterceptors.iterator(); it.hasNext();) { Advisor advisor = GlobalAdvisorAdapterRegistry.getInstance().wrap(it.next()); // 添加 advisor proxyFactory.addAdvisor(advisor); } proxyFactory.setTargetSource(getTargetSource(bean, name)); // 创建代理对象，依旧采用的 jdk 动态代理; 因为上面设置了代理的 interface return proxyFactory.getProxy(); } else { return bean; } } protected Object[] getInterceptorsAndAdvisorsForBean(Object bean, String beanName) { if (this.beanNames != null) { // bean name 包含在配置的名称列表中，说明需要代理 if (this.beanNames.contains(beanName)) { return PROXY_WITHOUT_ADDITIONAL_INTERCEPTORS; } for (Iterator it = this.beanNames.iterator(); it.hasNext();) { String mappedName = (String) it.next(); // bean name 匹配通配符，说明需要代理 if (isMatch(beanName, mappedName)) { return PROXY_WITHOUT_ADDITIONAL_INTERCEPTORS; } } } // 说明 bean 不需要代理 return DO_NOT_PROXY; } protected boolean isMatch(String beanName, String mappedName) { // bean name 匹配通配符 return (mappedName.endsWith(&quot;*&quot;) &amp;&amp; beanName.startsWith(mappedName.substring(0, mappedName.length() - 1))) || (mappedName.startsWith(&quot;*&quot;) &amp;&amp; beanName.endsWith(mappedName.substring(1, mappedName.length()))); } 从 BeanNameAutoProxyCreator 的源码大概总结其自动代理流程： 判断当前 bean name 是否匹配配置 加载配置的 advisor, 也就是配置的 interceptorNames 采用 jdk 动态代理创建 bean 的代理对象 DefaultAdvisorAutoProxyCreator DefaultAdvisorAutoProxyCreator 会搜索 BeanFactory 容器内部所有可用的 Advisor; 并为容器中匹配的 bean 创建代理。 在上一篇 重拾-Spring AOP 中我们知道 Spring AOP 会默认创建实例为 DefaultPointcutAdvisor 的 Advisor； 那么在分析 DefaultAdvisorAutoProxyCreator 之前，我们看下 Spring AOP 还为我们提供了哪些内置的 Advisor 。 NameMatchMethodPointcutAdvisor NameMatchMethodPointcutAdvisor 是按 method name 匹配，只有当目标类执行方法匹配的时候，才会执行 Advice public class NameMatchMethodPointcut extends StaticMethodMatcherPointcut { // 配置拦截的 method name private String[] mappedNames = new String[0]; public boolean matches(Method m, Class targetClass) { for (int i = 0; i&lt;this.mappedNames.length; i++) { String mappedName = this.mappedNames[i]; // 目标方法是否与配置的 method name 相等；或者匹配通配符 if (mappedName.equals(m.getName()) || isMatch(m.getName(), mappedName)) { return true; } } return false; } // 是否以 * 开头或结束并匹配 protected boolean isMatch(String methodName, String mappedName) { return (mappedName.endsWith(&quot;*&quot;) &amp;&amp; methodName.startsWith(mappedName.substring(0, mappedName.length() - 1))) || (mappedName.startsWith(&quot;*&quot;) &amp;&amp; methodName.endsWith(mappedName.substring(1, mappedName.length()))); } } RegexpMethodPointcutAdvisor RegexpMethodPointcutAdvisor 是按照正则表达式匹配方法，能够精确定位到需要拦截的方法。 public class RegexpMethodPointcut extends StaticMethodMatcherPointcut implements ClassFilter { public boolean matches(Method m, Class targetClass) { // TODO use target class here? // 拼接表达式 String patt = m.getDeclaringClass().getName() + &quot;.&quot; + m.getName(); for (int i = 0; i &lt; this.compiledPatterns.length; i++) { // 正则匹配 boolean matched = this.matcher.matches(patt, this.compiledPatterns[i]); if (logger.isDebugEnabled()) { logger.debug(&quot;Candidate is: &#39;&quot; + patt + &quot;&#39;; pattern is &quot; + this.compiledPatterns[i].getPattern() + &quot;; matched=&quot; + matched); } if (matched) { return true; } } return false; } public boolean matches(Class clazz) { // TODO do with regexp return true; } public ClassFilter getClassFilter() { return this; } } 使用示例 xml 配置 &lt;beans&gt; &lt;bean id=&quot;userService&quot; class=&quot;org.springframework.aop.UserServiceImpl&quot; /&gt; &lt;bean id=&quot;demoService&quot; class=&quot;org.springframework.aop.DemoServiceImpl&quot; /&gt; &lt;bean id=&quot;userBeforeAdvice&quot; class=&quot;org.springframework.aop.UserBeforeAdvice&quot; /&gt; &lt;bean id=&quot;userAfterAdvice&quot; class=&quot;org.springframework.aop.UserAfterAdvice&quot; /&gt; &lt;!-- 按方法名称匹配 --&gt; &lt;bean id=&quot;nameMatchMethodPointcutAdvisor&quot; class=&quot;org.springframework.aop.support.NameMatchMethodPointcutAdvisor&quot;&gt; &lt;property name=&quot;mappedNames&quot;&gt; &lt;!-- 匹配 save 开头的方法 --&gt; &lt;value&gt;save*&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;advice&quot;&gt; &lt;ref bean=&quot;userBeforeAdvice&quot; /&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;regexpMethodPointcutAdvisor&quot; class=&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt; &lt;property name=&quot;pattern&quot;&gt; &lt;!-- 匹配以 del 开头的方法 --&gt; &lt;value&gt;org.springframework.aop.*.del*.*&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;advice&quot;&gt; &lt;ref bean=&quot;userAfterAdvice&quot; /&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot; /&gt; &lt;/beans&gt; 测试 ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;/org/springframework/aop/aop.xml&quot;); UserService userService = (UserService) ctx.getBean(&quot;userService&quot;); userService.saveUser(); userService.delUser(); DemoService demoService = (DemoService) ctx.getBean(&quot;demoService&quot;); demoService.saveDemo(); demoService.delDemo(); 测试结果 do before advice .... do save user ...... do del user ...... do after return advice .... do before advice .... do save demo ...... do del demo ...... do after return advice .... 从测试结果可以看出，通过配置不同 Advisor 匹配不同的 Method 采用相应的 Advice 进行处理。 实现分析类结构 从上图 DefaultAdvisorAutoProxyCreator 类结构，我们知道其实现与 BeanNameAutoProxyCreator 类似；都是通过实现接口 BeanPostProcessor 在 bean 完成实例化后进行自动代理处理。 分析因 DefaultAdvisorAutoProxyCreator 和 BeanNameAutoProxyCreator 都继承了类 AbstractAutoProxyCreator ,所以从源码中我们可以发现二者都重写了方法 getInterceptorsAndAdvisorsForBean ，也就是在获取当前 bean 所匹配的 Advisor 逻辑不一样之外其他处理一致； 那么下面针对 DefaultAdvisorAutoProxyCreator 的实现我们主要看下方法 getInterceptorsAndAdvisorsForBean 的处理。 protected Object[] getInterceptorsAndAdvisorsForBean(Object bean, String name) { // 查找与当前 bean 匹配的 advisor List advices = findEligibleAdvisors(bean.getClass()); if (advices.isEmpty()) { return DO_NOT_PROXY; } // 对 advisor 集合排序 advices = sortAdvisors(advices); return advices.toArray(); } 查找匹配的 Advisor protected List findEligibleAdvisors(Class clazz) { // 查找当前容器中所有定义的 advisor List candidateAdvice = findCandidateAdvisors(); List eligibleAdvice = new LinkedList(); for (int i = 0; i &lt; candidateAdvice.size(); i++) { // Sun, give me generics, please! Advisor candidate = (Advisor) candidateAdvice.get(i); // 判断 bean 是否可以应用 advisor if (AopUtils.canApply(candidate, clazz, null)) { // 将 advisor 添加到匹配的集合中 eligibleAdvice.add(candidate); logger.info(&quot;Candidate Advice [&quot; + candidate + &quot;] accepted for class [&quot; + clazz.getName() + &quot;]&quot;); } else { logger.info(&quot;Candidate Advice [&quot; + candidate + &quot;] rejected for class [&quot; + clazz.getName() + &quot;]&quot;); } } return eligibleAdvice; } 获取容器中所有的 Advisor protected List findCandidateAdvisors() { if (!(getBeanFactory() instanceof ListableBeanFactory)) { throw new IllegalStateException(&quot;Cannot use DefaultAdvisorAutoProxyCreator without a ListableBeanFactory&quot;); } ListableBeanFactory owningFactory = (ListableBeanFactory) getBeanFactory(); // 从容器中查找所有 bean 定义 type 为 Advisor 的 bean name String[] adviceNames = BeanFactoryUtils.beanNamesIncludingAncestors(owningFactory, Advisor.class); List candidateAdvisors = new LinkedList(); for (int i = 0; i &lt; adviceNames.length; i++) { String name = adviceNames[i]; if (!this.usePrefix || name.startsWith(this.advisorBeanNamePrefix)) { // 获取 advisor 实例 Advisor advisor = (Advisor) owningFactory.getBean(name); candidateAdvisors.add(advisor); } } return candidateAdvisors; } 判断 bean 是否匹配 Advisor public static boolean canApply(Advisor advisor, Class targetClass, Class[] proxyInterfaces) { if (advisor instanceof IntroductionAdvisor) { return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); } else if (advisor instanceof PointcutAdvisor) { PointcutAdvisor pca = (PointcutAdvisor) advisor; // 通过 advisor 的 pointcut 判断 bean 是否匹配 return canApply(pca.getPointcut(), targetClass, proxyInterfaces); } else { // It doesn&#39;t have a pointcut so we assume it applies return true; } } public static boolean canApply(Pointcut pc, Class targetClass, Class[] proxyInterfaces) { // 类是否匹配 if (!pc.getClassFilter().matches(targetClass)) { return false; } // 判断类中的 method 是否匹配 // 获取类下所有的method Method[] methods = targetClass.getMethods(); for (int i = 0; i &lt; methods.length; i++) { Method m = methods[i]; // If we&#39;re looking only at interfaces and this method // isn&#39;t on any of them, skip it if (proxyInterfaces != null &amp;&amp; !methodIsOnOneOfTheseInterfaces(m, proxyInterfaces)) { continue; } // 执行 pointcut 的 method match if (pc.getMethodMatcher().matches(m, targetClass)) return true; } return false; } 从 DefaultAdvisorAutoProxyCreator 的源码分析，可知其自动代理流程大概如下： 从容器中获取所有 Advisor 实例 匹配 bean 所支持的 Advisor 采用 jdk 动态代理创建 bean 的代理对象 小结从 BeanNameAutoProxyCreator, DefaultAdvisorAutoProxyCreator 二者的实现可以看出其相同点 都是基于实现接口 BeanPostProcessor 的实现 都是先获取当前 bean 所匹配的 Advisor，后在创建代理对象 二者的不同点在于: 前者是基于 bean name 判断是否判断，后者是通过 Advisor 内部的 Ponitcut 匹配判断 前者的 Advisor 是用户配置的，后者是容器中所有匹配的 Advisor","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.hxlzpnyist.site/tags/Spring/"}],"keywords":[]},{"title":"重拾-Spring-AOP","slug":"重拾-Spring-AOP","date":"2019-03-02T13:59:36.000Z","updated":"2019-06-21T06:49:41.492Z","comments":true,"path":"2019/03/02/重拾-Spring-AOP/","link":"","permalink":"https://www.hxlzpnyist.site/2019/03/02/重拾-Spring-AOP/","excerpt":"","text":"AOP 术语关于 AOP 的概念描述及相关术语可以参考 彻底征服 Spring AOP 之 理论篇 总结的很好； 本文将着重分析下 AOP 的实现过程。 使用示例定义接口public interface UserService { void say (); } 接口实现类如下： public class UserServiceImpl implements UserService { public void say() { System.out.println(&quot;do say method&quot;); } } 定义通知public class UserAdvice implements MethodBeforeAdvice { public void before(Method m, Object[] args, Object target) throws Throwable { System.out.println(&quot;do before advice ....&quot;); } } 配置 AOP&lt;beans&gt; &lt;!-- 配置接口实现类 --&gt; &lt;bean id=&quot;userService&quot; class=&quot;org.springframework.aop.UserServiceImpl&quot; /&gt; &lt;!-- 配置通知类 --&gt; &lt;bean id=&quot;userAdvice&quot; class=&quot;org.springframework.aop.UserAdvice&quot; /&gt; &lt;!--代理类--&gt; &lt;bean id=&quot;userProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!--要代理的接口 创建代理对象时需要--&gt; &lt;!-- 配置该属性会采用 jdk 动态代理，反之采用 cglib --&gt; &lt;property name=&quot;proxyInterfaces&quot;&gt; &lt;value&gt;org.springframework.aop.UserService&lt;/value&gt; &lt;/property&gt; &lt;!--拦截器名字，也就是我们定义的通知类，可配置多个通知类 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;userAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--目标类，就是我们业务的实现类--&gt; &lt;property name=&quot;target&quot;&gt; &lt;ref bean=&quot;userService&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 测试ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;/org/springframework/aop/aop.xml&quot;); UserService userService = (UserService) ctx.getBean(&quot;userProxy&quot;); userService.say(); 执行结果如下： do before advice .... do say method 从执行结果来看，前置通知对接口方法已经起增强作用。 下面我们将看下 Spring AOP 的具体实现。 实现分析 从上面的示例可以看出 Spring AOP 的配置主要基于类 ProxyFactoryBean ，那么我们就以此为入口去剖析其实现。 ProxyFactoryBean 类结构 创建切面链从 ProxyFactoryBean 的类结构，我们发现其实现了接口 BeanFactoryAware，也就说明在其实例化过程中会调用方法 setBeanFactory; 源码如下： public void setBeanFactory(BeanFactory beanFactory) throws BeansException { // 设置 beanFactory this.beanFactory = beanFactory; logger.debug(&quot;Set BeanFactory. Will configure interceptor beans...&quot;); // 创建 advisor chain createAdvisorChain(); logger.info(&quot;ProxyFactoryBean config: &quot; + this); if (singleton) { // Eagerly initialize the shared singleton instance getSingletonInstance(); // We must listen to superclass advice change events to recache singleton // instance if necessary addListener(this); } } 在 setBeanFactory 方法中除了设置 beanFactory , 还有一个重要的动作就是 createAdvisorChain 创建 advisor chain (也可以理解为就是切面链)。 那么下面我们将看下具体是怎样创建 advisor chain 的。 private void createAdvisorChain() throws AopConfigException, BeansException { // 检测是否配置了 interceptorNames, 也就是是否配置相关 advice 通知； 若没有配置直接返回 if (this.interceptorNames == null || this.interceptorNames.length == 0) { //throw new AopConfigException(&quot;Interceptor names are required&quot;); return; } // Globals can&#39;t be last if (this.interceptorNames[this.interceptorNames.length - 1].endsWith(GLOBAL_SUFFIX)) { throw new AopConfigException(&quot;Target required after globals&quot;); } // Materialize interceptor chain from bean names for (int i = 0; i &lt; this.interceptorNames.length; i++) { String name = this.interceptorNames[i]; logger.debug(&quot;Configuring interceptor &#39;&quot; + name + &quot;&#39;&quot;); // 判断 interceptor name 是否以 * 结尾 if (name.endsWith(GLOBAL_SUFFIX)) { if (!(this.beanFactory instanceof ListableBeanFactory)) { throw new AopConfigException(&quot;Can only use global advisors or interceptors with a ListableBeanFactory&quot;); } else { addGlobalAdvisor((ListableBeanFactory) this.beanFactory, name.substring(0, name.length() - GLOBAL_SUFFIX.length())); } } else { // add a named interceptor // 获取 advice bean Object advice = this.beanFactory.getBean(this.interceptorNames[i]); // 将 advisor 加入到链表中 addAdvisor(advice, this.interceptorNames[i]); } } } private void addAdvisor(Object next, String name) { logger.debug(&quot;Adding advisor or TargetSource [&quot; + next + &quot;] with name [&quot; + name + &quot;]&quot;); // We need to add a method pointcut so that our source reference matches // what we find from superclass interceptors. // 查找 advice 通知匹配的 pointcut, 并创建一个 advisor Object advisor = namedBeanToAdvisorOrTargetSource(next); if (advisor instanceof Advisor) { // if it wasn&#39;t just updating the TargetSource logger.debug(&quot;Adding advisor with name [&quot; + name + &quot;]&quot;); addAdvisor((Advisor) advisor); this.sourceMap.put(advisor, name); } else { logger.debug(&quot;Adding TargetSource [&quot; + advisor + &quot;] with name [&quot; + name + &quot;]&quot;); setTargetSource((TargetSource) advisor); // save target name this.targetName = name; } } 从 addAdvisor 方法可以看到，在添加 advisor 前，需要先创建 advisor , 会调用方法 namedBeanToAdvisorOrTargetSource private Object namedBeanToAdvisorOrTargetSource(Object next) { try { // 将 advice 包装成一个 advisor Advisor adv = GlobalAdvisorAdapterRegistry.getInstance().wrap(next); return adv; } catch (UnknownAdviceTypeException ex) { } } namedBeanToAdvisorOrTargetSource 方法会调用单例模式的 GlobalAdvisorAdapterRegistry 的方法 wrap 将 advice 包装成一个 advisor;在查看 wrap 的实现之前，我们可以先看下 GlobalAdvisorAdapterRegistry 是做什么的。 public class GlobalAdvisorAdapterRegistry extends DefaultAdvisorAdapterRegistry { private static GlobalAdvisorAdapterRegistry instance = new GlobalAdvisorAdapterRegistry(); public static GlobalAdvisorAdapterRegistry getInstance() { return instance; } private GlobalAdvisorAdapterRegistry() { } } public class DefaultAdvisorAdapterRegistry implements AdvisorAdapterRegistry { private List adapters = new LinkedList(); public DefaultAdvisorAdapterRegistry() { // register well-known adapters registerAdvisorAdapter(new BeforeAdviceAdapter()); registerAdvisorAdapter(new AfterReturningAdviceAdapter()); registerAdvisorAdapter(new ThrowsAdviceAdapter()); } } 从上面 GlobalAdvisorAdapterRegistry 的实现可以看出其采用了单例模式并继承了类 DefaultAdvisorAdapterRegistry 在构造的过程中内置了 3 种 advice adapter 用于匹配 advice 。 下面我们在看下它是如何 wrap 包装 advice 的。 public Advisor wrap(Object adviceObject) throws UnknownAdviceTypeException { if (adviceObject instanceof Advisor) { return (Advisor) adviceObject; } if (!(adviceObject instanceof Advice)) { throw new UnknownAdviceTypeException(adviceObject); } Advice advice = (Advice) adviceObject; if (advice instanceof Interceptor) { // So well-known it doesn&#39;t even need an adapter return new DefaultPointcutAdvisor(advice); } // 遍历内置的 advice adapters for (int i = 0; i &lt; this.adapters.size(); i++) { // Check that it is supported AdvisorAdapter adapter = (AdvisorAdapter) this.adapters.get(i); // 判断当前 adapter 是否支付当前 advice if (adapter.supportsAdvice(advice)) { // 如果支持的话，返回一个 DefaultPointcutAdvisor return new DefaultPointcutAdvisor(advice); } } throw new UnknownAdviceTypeException(advice); } 从 wrap 的实现可以发现，若 advice 匹配了某个 adapter 将会创建一个 DefaultPointcutAdvisor 实例并返回； public class DefaultPointcutAdvisor implements PointcutAdvisor, Ordered { private int order = Integer.MAX_VALUE; private Pointcut pointcut; private Advice advice; public DefaultPointcutAdvisor() { } public DefaultPointcutAdvisor(Advice advice) { this(Pointcut.TRUE, advice); } public DefaultPointcutAdvisor(Pointcut pointcut, Advice advice) { this.pointcut = pointcut; this.advice = advice; } } /** * Canonical instance that matches everything. * 默认匹配所有的类及类下的所有方法 */ Pointcut TRUE = new Pointcut() { public ClassFilter getClassFilter() { return ClassFilter.TRUE; } public MethodMatcher getMethodMatcher() { return MethodMatcher.TRUE; } public String toString() { return &quot;Pointcut.TRUE&quot;; } }; 从 DefaultPointcutAdvisor 的实例可以看出创建 advisor (切面) 的过程实际就是将 advice (通知) 和 pointcut (切入点) 绑定的过程；同时在 Spring AOP 默认的 pointcut 是拦截所有类下的所有方法。 简单点说也就是当前切面将会拦截哪些类下的哪些方法，拦截过程中会采用哪些增强处理（前置通知，返回通知，异常通知）。 至此 advisor chain 的创建流程结束，其过程大概如下： 遍历 interceptor names (也就是 advice 通知) 获取 advice bean 判断 advice 是否匹配内置的 advisorAdapter, 匹配的话则创建 DefaultPointcutAdvisor (默认拦截所有类所有方法) 加入到链表中 创建目标代理对象从 ProxyFactoryBean 类的名字及类结构，发现其实现接口 FactoryBean, 也就是说当其 getBean 的时候会调用方法 getObject, 源码如下： public Object getObject() throws BeansException { // 默认单例 return (this.singleton) ? getSingletonInstance() : newPrototypeInstance(); } private Object getSingletonInstance() { if (this.singletonInstance == null) { // This object can configure the proxy directly if it&#39;s // being used as a singleton. this.singletonInstance = createAopProxy().getProxy(); } return this.singletonInstance; } protected synchronized AopProxy createAopProxy() { if (!isActive) { activate(); } return getAopProxyFactory().createAopProxy(this); } public AopProxy createAopProxy(AdvisedSupport advisedSupport) throws AopConfigException { // 是否采用 cglib 代理 boolean useCglib = advisedSupport.getOptimize() || advisedSupport.getProxyTargetClass() || advisedSupport.getProxiedInterfaces().length == 0; if (useCglib) { return CglibProxyFactory.createCglibProxy(advisedSupport); } else { // Depends on whether we have expose proxy or frozen or static ts return new JdkDynamicAopProxy(advisedSupport); } } public Object getProxy(ClassLoader cl) { logger.debug(&quot;Creating JDK dynamic proxy&quot;); Class[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised); return Proxy.newProxyInstance(cl, proxiedInterfaces, this); } ProxyFactoryBean 通过判断 proxyTargetClass , interfaceNames 的配置去选择采用 cglib 或者 jdk 来创建目标代理对象。 目标代理对象执行上面简单介绍了代理对象的创建，那么在看下当我们调用目标方法的时候，代理是如何执行的，以 jdk 动态代理为例： public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { MethodInvocation invocation = null; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = advised.targetSource; Class targetClass = null; Object target = null; try { // Try special rules for equals() method and implementation of the // Advised AOP configuration interface // Short-circuit expensive Method.equals() call, as Object.equals() isn&#39;t overloaded if (method.getDeclaringClass() == Object.class &amp;&amp; &quot;equals&quot;.equals(method.getName())) { // What if equals throws exception!? // This class implements the equals() method itself return new Boolean(equals(args[0])); } else if (Advised.class == method.getDeclaringClass()) { // Service invocations on ProxyConfig with the proxy config return AopProxyUtils.invokeJoinpointUsingReflection(this.advised, method, args); } Object retVal = null; // May be null. Get as late as possible to minimize the time we &quot;own&quot; the target, // in case it comes from a pool. // 目标实现类 target = targetSource.getTarget(); if (target != null) { targetClass = target.getClass(); } if (this.advised.exposeProxy) { // Make invocation available if necessary oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; } // Get the interception chain for this method // 获取目标类，执行方法的 interception chain List chain = this.advised.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this.advised, proxy, method, targetClass); // Check whether we have any advice. If we don&#39;t, we can fallback on // direct reflective invocation of the target, and avoid creating a MethodInvocation if (chain.isEmpty()) { // We can skip creating a MethodInvocation: just invoke the target directly // Note that the final invoker must be an InvokerInterceptor so we know it does // nothing but a reflective operation on the target, and no hot swapping or fancy proxying retVal = AopProxyUtils.invokeJoinpointUsingReflection(target, method, args); } else { invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain // 方法调用 retVal = invocation.proceed(); } // Massage return value if necessary if (retVal != null &amp;&amp; retVal == target) { retVal = proxy; } return retVal; } finally { } } 首先我们看下如何获取匹配当前 method 的拦截器, 参考 calculateInterceptorsAndDynamicInterceptionAdvice 的实现如下： public static List calculateInterceptorsAndDynamicInterceptionAdvice(Advised config, Object proxy, Method method, Class targetClass) { // 用于存储拦截器 List interceptors = new ArrayList(config.getAdvisors().length); // 遍历 advisor (切面) for (int i = 0; i &lt; config.getAdvisors().length; i++) { Advisor advisor = config.getAdvisors()[i]; if (advisor instanceof PointcutAdvisor) { // Add it conditionally PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; // 判断当前 target class 是否当前 pointcut if (pointcutAdvisor.getPointcut().getClassFilter().matches(targetClass)) { // 获取 advisor 对应的 method interceptor MethodInterceptor interceptor = (MethodInterceptor) GlobalAdvisorAdapterRegistry.getInstance().getInterceptor(advisor); MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); // 判断当前 method 是否匹配 pointcut if (mm.matches(method, targetClass)) { if (mm.isRuntime()) { // Creating a new object instance in the getInterceptor() method // isn&#39;t a problem as we normally cache created chains interceptors.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm) ); } else { // 将拦截器加入链表中 interceptors.add(interceptor); } } } } else if (advisor instanceof IntroductionAdvisor) { IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (ia.getClassFilter().matches(targetClass)) { MethodInterceptor interceptor = (MethodInterceptor) GlobalAdvisorAdapterRegistry.getInstance().getInterceptor(advisor); interceptors.add(interceptor); } } } // for return interceptors; } // calculateInterceptorsAndDynamicInterceptionAdvice 我们在详细看下如何查找 advisor 匹配的拦截器呢，同样与上文中 wrap 类似，如下： public Interceptor getInterceptor(Advisor advisor) throws UnknownAdviceTypeException { Advice advice = advisor.getAdvice(); if (advice instanceof Interceptor) { return (Interceptor) advice; } // 遍历内置的 advisor adapter for (int i = 0; i &lt; this.adapters.size(); i++) { AdvisorAdapter adapter = (AdvisorAdapter) this.adapters.get(i); // 是否匹配当前 advice if (adapter.supportsAdvice(advice)) { // 匹配的话返回 interceptor return adapter.getInterceptor(advisor); } } throw new UnknownAdviceTypeException(advisor.getAdvice()); } 到目前为止，我们多次发现 AdvisorAdapter 的身影，下面我们看下其具体的实现, 以 BeforeAdviceAdapter 为例： class BeforeAdviceAdapter implements AdvisorAdapter { /** * @see org.springframework.aop.framework.adapter.AdvisorAdapter#supportsAdvice(java.lang.Object) */ public boolean supportsAdvice(Advice advice) { // 匹配 MethodBeforeAdvice return advice instanceof MethodBeforeAdvice; } /** * @see org.springframework.aop.framework.adapter.AdvisorAdapter#getInterceptor(org.springframework.aop.Advisor) */ public Interceptor getInterceptor(Advisor advisor) { MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); // 返回 MethodBeforeAdviceInterceptor return new MethodBeforeAdviceInterceptor(advice) ; } } 通过 AdvisorAdapter 很巧妙的将 Advice 和 Interceptor 结合起来，同时也会发现二者关系是一一对应的 下面在看下方法的真正调用过程, 由 ReflectiveMethodInvocation 的方法 proceed 实现： public Object proceed() throws Throwable { // We start with an index of -1 and increment early // 当执行到最后一个拦截器的时候将会调用目标方法 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) { return invokeJoinpoint(); } // 获取下一个拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) { // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) { return dm.interceptor.invoke(this); } else { // Dynamic matching failed // Skip this interceptor and invoke the next in the chain return proceed(); } } else { // It&#39;s an interceptor so we just invoke it: the pointcut will have // been evaluated statically before this object was constructed // 执行拦截器 return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); } } 下面具体看下 MethodInterceptor 的实现，分别是前置通知，返回通知，异常通知 public Object invoke(MethodInvocation mi) throws Throwable { // 目标方法前执行 advice.before(mi.getMethod(), mi.getArguments(), mi.getThis() ); return mi.proceed(); } public Object invoke(MethodInvocation mi) throws Throwable { // 先执行目标方法 Object retval = mi.proceed(); // 后置处理 advice.afterReturning(retval, mi.getMethod(), mi.getArguments(), mi.getThis() ); return retval; } public Object invoke(MethodInvocation mi) throws Throwable { try { // 执行目标方法 return mi.proceed(); } catch (Throwable t) { // 异常处理 Method handlerMethod = getExceptionHandler(t); if (handlerMethod != null) { invokeHandlerMethod(mi, t, handlerMethod); } throw t; } } 至此 Spring AOP 代理对象的执行过程处理结束，其流程可大概总结如下： 获取当前目标方法的 interceptor chain 遍历 advisor ，判断当前目标类和目标方法是否匹配 advisor 对应的 ponitcut 通过匹配的 advisor 对应的 advice 匹配对应的 advisorAdapter , 进而获取对应的 methodInterceptor 执行拦截器 执行目标方法 小结Spring AOP 中的对象关系小结下： Advisor : 翻译是顾问，简单理解其就是一个 Aspect (切面); 其内部绑定了对应的 Pointcut(切入点) 和 Advice(通知)。 Advisor Chain ： 切面链，是一系列的切面的集合。 Advice : 通知，是对拦截方法的增强处理；在 1.0 版本中包含 BeforeAdivce, AfterReturningAdvice, ThrowsAdvice; 其面向的是用户。 MethodInterceptor : 方法拦截器，是 Advice 的执行者; 与 Advice 是一一对应的。 AdvisorAdapter : Advice 的适配器，是 Advice 和 MethodInterceptor 匹配的纽带。 AdvisorAdapterRegistry : 是 AdvisorAdapter 的注册中心，内置了 BeforeAdviceAdapter, AfterReturnAdviceAdapter, ThrowsAdviceAdapter； 用来将 Advice wrap 成一个 Advisor 并提供获取 Advice 对应的 MethodInterceptor。 坑当我们自定义 Advice 时，可不可以同时支持多种 Advice 呢 ？ 譬如： public class UserAdvice implements MethodBeforeAdvice, AfterReturningAdvice { public void before(Method m, Object[] args, Object target) throws Throwable { System.out.println(&quot;do before advice ....&quot;); } public void afterReturning(Object returnValue, Method m, Object[] args, Object target) throws Throwable { System.out.println(&quot;do after returning ....&quot;); } } 那么当测试后，您会发现只有 before 调用了，而 afterReturning 未调用了；这是为什么呢 ? (好好看源码额)","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.hxlzpnyist.site/tags/Spring/"}],"keywords":[]},{"title":"LeetCode-数组-删除元素","slug":"LeetCode-数组-删除元素","date":"2019-03-01T11:44:57.000Z","updated":"2019-06-21T06:48:04.729Z","comments":true,"path":"2019/03/01/LeetCode-数组-删除元素/","link":"","permalink":"https://www.hxlzpnyist.site/2019/03/01/LeetCode-数组-删除元素/","excerpt":"","text":"题目描述给定一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val 的元素，返回移除后数组的新长度。 不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 解题思路 本题解题思路与上一篇的删除有序数组重复元素类似，如下所示： 设定左右指针 i, j，变量 count 用于计数 指针 i 从左向右移动，判断元素是否等于 val；当于 val 相等时 count–, 并移动指针 j，当于 val 不等时指针 i 继续向右移动 当指针 j 移动时，判断元素是否等于 val； 当于 val 相等时 count– 继续移动指针 j, 当不等时互换 i, j 元素并继续移动指针 i 当指针 i，j 交汇时完成退出轮询 可见如下图示： 实现public int removeElement(int[] nums, int val) { int i = 0, count = nums.length, j = count; while (true) { while (i &lt; j) { if (nums[i] == val) { count--; break; } else { if (i + 1 == j) { break; } i++; } } while (j &gt; i) { j--; if (j == i) { break; } if (nums[j] == val) { count--; } else { nums[i] = nums[j]; i++; break; } } if (i &gt;= j) { break; } } return count; }","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://www.hxlzpnyist.site/tags/LeetCode/"}],"keywords":[]},{"title":"重拾-Spring IOC","slug":"重拾-Spring-IOC","date":"2019-02-27T14:58:14.000Z","updated":"2019-06-21T06:49:47.133Z","comments":true,"path":"2019/02/27/重拾-Spring-IOC/","link":"","permalink":"https://www.hxlzpnyist.site/2019/02/27/重拾-Spring-IOC/","excerpt":"","text":"为何重拾使用了 Spring 多年，但是对其底层的一些实现还是一知半解，一些概念比较模糊；故决定重新拾起，加深对 Spring 的认识。 重拾计划spring 版本说明Spring 在经过多年的演进过程中，其功能越来越丰富，组件越来越多；为了避免在阅读源码的过程中深陷泥潭中，决定采用最原始的版本 1.0； 但又不局限于 1.0 版本。 spring iocspring aopspring 事务管理spring orm 集成实现分析Spring 容器启动 在本文中，通过常用的构造 ClassPathXmlApplicationContext 实例来作为对 Spring 实现分析的入口 ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); 通过调用链追踪，Spring 容器启动核心操作由 AbstractApplicationContext 类中 refresh 方法实现 public void refresh() throws BeansException { this.startupTime = System.currentTimeMillis(); // tell subclass to refresh the internal bean factory // 完成 xml 配置文件的解析， 解析 bean 标签生成 BeanDefinition 对象，并注册到 BeanFactory refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // configure the bean factory with context semantics beanFactory.registerCustomEditor(Resource.class, new ContextResourceEditor(this)); beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); beanFactory.ignoreDependencyType(ResourceLoader.class); beanFactory.ignoreDependencyType(ApplicationContext.class); postProcessBeanFactory(beanFactory); // invoke factory processors registered with the context instance // 获取内置 BeanFactoryPostProcessor 实例，并遍历调用 postProcessBeanFactory 方法 // 对 BeanFactory 进行后置处理 for (Iterator it = getBeanFactoryPostProcessors().iterator(); it.hasNext();) { BeanFactoryPostProcessor factoryProcessor = (BeanFactoryPostProcessor) it.next(); factoryProcessor.postProcessBeanFactory(beanFactory); } if (getBeanDefinitionCount() == 0) { logger.warn(&quot;No beans defined in ApplicationContext [&quot; + getDisplayName() + &quot;]&quot;); } else { logger.info(getBeanDefinitionCount() + &quot; beans defined in ApplicationContext [&quot; + getDisplayName() + &quot;]&quot;); } // invoke factory processors registered as beans in the context // 从 Bean Definition 集合中查找 BeanFactoryPostProcessor 定义并实例化 // 获取 BeanFactoryPostProcessor 实例，并遍历调用 postProcessBeanFactory 方法 // 对 BeanFactory 进行后置处理 invokeBeanFactoryPostProcessors(); // register bean processor that intercept bean creation // 从 Bean Definition 集合中查找 BeanPostProcessor 类定义实例化并注册到 BeanFactory 中 registerBeanPostProcessors(); // initialize message source for this context initMessageSource(); // initialize other special beans in specific context subclasses onRefresh(); // check for listener beans and register them refreshListeners(); // instantiate singletons this late to allow them to access the message source // 对 Bean Definition 中单例且非延迟加载的类型进行实例化 /** * bean 初始化过程如下: * 1 : bean 构造初始化 * 2 : bean 属性注入 (通过 bean definition 中的 property , autowire(byType, byName) 实现) * 3 : bean 若实现 BeanNameAware 接口，调用 setBeanName() 方法 * 4 : bean 若实现 BeanFactoryAware 接口, 调用 setBeanFactory() 方法 * 5 : 遍历调用 BeanFactory 中注册的 BeanPostProcessor 实例的 postProcessorBeforeInitialization() 方法 * 6 : bean 若实现了 InitializingBean 接口，调用 afterPropertiesSet() 方法 * 7 : bean 实例对应的 bean definition 中若定义了 init-method 属性则调用对应的 init 方法 * 8 : 遍历调用 BeanFactory 中注册的 BeanPostProcessor 实例的 postProcessorAfterInitialization() 方法 */ beanFactory.preInstantiateSingletons(); // last step: publish respective event publishEvent(new ContextRefreshedEvent(this)); } 从源码中可知，Spring 容器在启动过程中，主要完成以下流程 ： 通过加载指定的配置文件，完成 Bean Definition 解析并注册到 BeanFactory 实例中 通过内置及应用自定义的 BeanFactoryPostProcessor 对 BeanFactory 实例进行后置处理 实例化应用自定义的 BeanPostProcessor 并注册到 BeanFactory 实例中 实例化 Spring 容器中的 Bean Spring 容器关闭public void close() { logger.info(&quot;Closing application context [&quot; + getDisplayName() + &quot;]&quot;); // destroy all cached singletons in this context, // invoking DisposableBean.destroy and/or &quot;destroy-method&quot; // 销毁容器中缓存的单例对象实例 // 执行容器中 DisposableBean 的 destroy 方法 getBeanFactory().destroySingletons(); // publish respective event // 发送 spring 上下文关闭事件 publishEvent(new ContextClosedEvent(this)); } 通过调用链追踪，Spring 会遍历容器中缓存的 bean 实例调用 destroyBean 方法。 protected void destroyBean(String beanName, Object bean) { logger.debug(&quot;Retrieving depending beans for bean &#39;&quot; + beanName + &quot;&#39;&quot;); // 先销毁所有依赖当前 bean 的实例 String[] dependingBeans = getDependingBeanNames(beanName); if (dependingBeans != null) { for (int i = 0; i &lt; dependingBeans.length; i++) { destroySingleton(dependingBeans[i]); } } if (bean instanceof DisposableBean) { // 如果 bean 实现了 DisposableBean 接口，将会执行 destroy 方法 logger.debug(&quot;Calling destroy() on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;); try { ((DisposableBean) bean).destroy(); } catch (Exception ex) { logger.error(&quot;destroy() on bean with name &#39;&quot; + beanName + &quot;&#39; threw an exception&quot;, ex); } } try { RootBeanDefinition bd = getMergedBeanDefinition(beanName, false); if (bd.getDestroyMethodName() != null) { // 如果 bean 定义了 destroy-method 属性，将会调用自定义的销毁方法 logger.debug(&quot;Calling custom destroy method &#39;&quot; + bd.getDestroyMethodName() + &quot;&#39; on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;); invokeCustomDestroyMethod(beanName, bean, bd.getDestroyMethodName()); } } catch (NoSuchBeanDefinitionException ex) { // ignore, from manually registered singleton } } 下面将针对 Spring Bean 在容器启动过程中的各个环节的实现进行详细说明 Spring Bean 定义解析通过对 refreshBeanFactory 方法的调用链追踪，可以看到在 DefaultXmlBeanDefinitonParser 类的 registerBeanDefinitions 方法中实现对 Spring Bean 定义的解析及注册。 public void registerBeanDefinitions(BeanDefinitionRegistry beanFactory, ClassLoader beanClassLoader, Document doc, Resource resource) { this.beanFactory = beanFactory; this.beanClassLoader = beanClassLoader; this.resource = resource; logger.debug(&quot;Loading bean definitions&quot;); Element root = doc.getDocumentElement(); this.defaultLazyInit = root.getAttribute(DEFAULT_LAZY_INIT_ATTRIBUTE); logger.debug(&quot;Default lazy init &#39;&quot; + this.defaultLazyInit + &quot;&#39;&quot;); this.defaultDependencyCheck = root.getAttribute(DEFAULT_DEPENDENCY_CHECK_ATTRIBUTE); logger.debug(&quot;Default dependency check &#39;&quot; + this.defaultDependencyCheck + &quot;&#39;&quot;); this.defaultAutowire = root.getAttribute(DEFAULT_AUTOWIRE_ATTRIBUTE); logger.debug(&quot;Default autowire &#39;&quot; + this.defaultAutowire + &quot;&#39;&quot;); NodeList nl = root.getChildNodes(); int beanDefinitionCounter = 0; for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element &amp;&amp; BEAN_ELEMENT.equals(node.getNodeName())) { beanDefinitionCounter++; loadBeanDefinition((Element) node); } } logger.debug(&quot;Found &quot; + beanDefinitionCounter + &quot; &lt;&quot; + BEAN_ELEMENT + &quot;&gt; elements defining beans&quot;); } protected void loadBeanDefinition(Element ele) { // 获取 bean 的 id, name 属性 String id = ele.getAttribute(ID_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); List aliases = new ArrayList(); if (nameAttr != null &amp;&amp; !&quot;&quot;.equals(nameAttr)) { String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, BEAN_NAME_DELIMITERS, true, true); aliases.addAll(Arrays.asList(nameArr)); } if (id == null || &quot;&quot;.equals(id) &amp;&amp; !aliases.isEmpty()) { id = (String) aliases.remove(0); logger.debug(&quot;No XML &#39;id&#39; specified - using &#39;&quot; + id + &quot;&#39; as ID and &quot; + aliases + &quot; as aliases&quot;); } // 解析 bean 标签, 获取 bean 配置的属性，构造，是否懒加载 作用域 AbstractBeanDefinition beanDefinition = parseBeanDefinition(ele, id); if (id == null || &quot;&quot;.equals(id)) { if (beanDefinition instanceof RootBeanDefinition) { id = ((RootBeanDefinition) beanDefinition).getBeanClassName(); logger.debug(&quot;Neither XML &#39;id&#39; nor &#39;name&#39; specified - using bean class name [&quot; + id + &quot;] as ID&quot;); } else { throw new BeanDefinitionStoreException(this.resource, &quot;&quot;,&quot;Child bean definition has neither &#39;id&#39; nor &#39;name&#39;&quot;); } } logger.debug(&quot;Registering bean definition with id &#39;&quot; + id + &quot;&#39;&quot;); // 将 bean definiton 注册到 beanFactory this.beanFactory.registerBeanDefinition(id, beanDefinition); for (Iterator it = aliases.iterator(); it.hasNext();) { this.beanFactory.registerAlias(id, (String) it.next()); } } protected AbstractBeanDefinition parseBeanDefinition(Element ele, String beanName) { String className = null; try { // 获取 class 属性 if (ele.hasAttribute(CLASS_ATTRIBUTE)) { className = ele.getAttribute(CLASS_ATTRIBUTE); } String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) { parent = ele.getAttribute(PARENT_ATTRIBUTE); } if (className == null &amp;&amp; parent == null) { throw new BeanDefinitionStoreException(this.resource, beanName, &quot;Either &#39;class&#39; or &#39;parent&#39; is required&quot;); } AbstractBeanDefinition bd = null; // 获取属性 MutablePropertyValues pvs = getPropertyValueSubElements(beanName, ele); if (className != null) { // 获取构造 ConstructorArgumentValues cargs = getConstructorArgSubElements(beanName, ele); RootBeanDefinition rbd = null; if (this.beanClassLoader != null) { Class clazz = Class.forName(className, true, this.beanClassLoader); rbd = new RootBeanDefinition(clazz, cargs, pvs); } else { rbd = new RootBeanDefinition(className, cargs, pvs); } // 设置 bean dependOn if (ele.hasAttribute(DEPENDS_ON_ATTRIBUTE)) { String dependsOn = ele.getAttribute(DEPENDS_ON_ATTRIBUTE); rbd.setDependsOn(StringUtils.tokenizeToStringArray(dependsOn, BEAN_NAME_DELIMITERS, true, true)); } String dependencyCheck = ele.getAttribute(DEPENDENCY_CHECK_ATTRIBUTE); if (DEFAULT_VALUE.equals(dependencyCheck)) { dependencyCheck = this.defaultDependencyCheck; } rbd.setDependencyCheck(getDependencyCheck(dependencyCheck)); // 设置 bean 自动注册的方式 byType, byName or none String autowire = ele.getAttribute(AUTOWIRE_ATTRIBUTE); if (DEFAULT_VALUE.equals(autowire)) { autowire = this.defaultAutowire; } rbd.setAutowireMode(getAutowireMode(autowire)); // 设置 bean 的 init-method String initMethodName = ele.getAttribute(INIT_METHOD_ATTRIBUTE); if (!initMethodName.equals(&quot;&quot;)) { rbd.setInitMethodName(initMethodName); } // 设置 bean 的 destroy-method String destroyMethodName = ele.getAttribute(DESTROY_METHOD_ATTRIBUTE); if (!destroyMethodName.equals(&quot;&quot;)) { rbd.setDestroyMethodName(destroyMethodName); } bd = rbd; } else { bd = new ChildBeanDefinition(parent, pvs); } // 设置 bean 是否为单例 if (ele.hasAttribute(SINGLETON_ATTRIBUTE)) { bd.setSingleton(TRUE_VALUE.equals(ele.getAttribute(SINGLETON_ATTRIBUTE))); } // 是否懒加载 String lazyInit = ele.getAttribute(LAZY_INIT_ATTRIBUTE); if (DEFAULT_VALUE.equals(lazyInit) &amp;&amp; bd.isSingleton()) { // just apply default to singletons, as lazy-init has no meaning for prototypes lazyInit = this.defaultLazyInit; } bd.setLazyInit(TRUE_VALUE.equals(lazyInit)); bd.setResourceDescription(this.resource.getDescription()); return bd; } catch (ClassNotFoundException ex) { } catch (NoClassDefFoundError err) {} } Spring 容器在将配置文件加载后，会解析 bean 标签并通过其相应的属性配置构造 BeanDefinition 对象，然后将 BeanDefinition 对象注册添加到 BeanFactory 中。 Spring Bean 实例化public void preInstantiateSingletons() { if (logger.isInfoEnabled()) { logger.info(&quot;Pre-instantiating singletons in factory [&quot; + this + &quot;]&quot;); } // 遍历注册的 bean definition for (Iterator it = this.beanDefinitionNames.iterator(); it.hasNext();) { String beanName = (String) it.next(); if (containsBeanDefinition(beanName)) { RootBeanDefinition bd = getMergedBeanDefinition(beanName, false); // 如果 bean 定义为单例且非延迟加载的 if (bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { // 判断 bean 是否为 FactoryBean if (FactoryBean.class.isAssignableFrom(bd.getBeanClass())) { FactoryBean factory = (FactoryBean) getBean(FACTORY_BEAN_PREFIX + beanName); if (factory.isSingleton()) { getBean(beanName); } } else { // 若是普通 bean 则调用 getBean getBean(beanName); } } } } } public Object getBean(String name) throws BeansException { String beanName = transformedBeanName(name); // eagerly check singleton cache for manually registered singletons // 检查单例缓存池中 是否存在 bean 实例，如果有从缓存中获取 bean 实例 Object sharedInstance = this.singletonCache.get(beanName); if (sharedInstance != null) { if (logger.isDebugEnabled()) { logger.debug(&quot;Returning cached instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;); } return getObjectForSharedInstance(name, sharedInstance); } else { // check if bean definition exists RootBeanDefinition mergedBeanDefinition = null; try { mergedBeanDefinition = getMergedBeanDefinition(beanName, false); } catch (NoSuchBeanDefinitionException ex) { // not found -&gt; check parent if (this.parentBeanFactory != null) { return this.parentBeanFactory.getBean(name); } throw ex; } // create bean instance if (mergedBeanDefinition.isSingleton()) { synchronized (this.singletonCache) { // re-check singleton cache within synchronized block sharedInstance = this.singletonCache.get(beanName); if (sharedInstance == null) { logger.info(&quot;Creating shared instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;); sharedInstance = createBean(beanName, mergedBeanDefinition); addSingleton(beanName, sharedInstance); } } return getObjectForSharedInstance(name, sharedInstance); } else { return createBean(name, mergedBeanDefinition); } } } protected Object createBean(String beanName, RootBeanDefinition mergedBeanDefinition) throws BeansException { if (mergedBeanDefinition.getDependsOn() != null) { for (int i = 0; i &lt; mergedBeanDefinition.getDependsOn().length; i++) { // guarantee initialization of beans that the current one depends on getBean(mergedBeanDefinition.getDependsOn()[i]); } } // bean 初始化并包装，也就是 new BeanWrapper instanceWrapper = null; if (mergedBeanDefinition.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mergedBeanDefinition.hasConstructorArgumentValues()) { instanceWrapper = autowireConstructor(beanName, mergedBeanDefinition); } else { instanceWrapper = new BeanWrapperImpl(mergedBeanDefinition.getBeanClass()); initBeanWrapper(instanceWrapper); } Object bean = instanceWrapper.getWrappedInstance(); // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. if (mergedBeanDefinition.isSingleton()) { // 单例的bean 则添加到缓存中 addSingleton(beanName, bean); } // bean 属性注入 populateBean(beanName, mergedBeanDefinition, instanceWrapper); try { if (bean instanceof BeanNameAware) { // bean 若实现接口 BeanNameAware 则调用 setBeanName 方法 ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanFactoryAware) { // bean 若实现接口 BeanFactoryAware 则调用 setBeanFactory 方法 ((BeanFactoryAware) bean).setBeanFactory(this); } // 调用 BeanPostProcessor 执行 postProcessBeforeInitialization 方法 bean = applyBeanPostProcessorsBeforeInitialization(bean, beanName); // 若 bean 实现 InitializingBean 接口则执行 afterPropertiesSet 方法 // 若 bean 定义中定义了 init-method 属性则执行对应的init 方法 invokeInitMethods(bean, beanName, mergedBeanDefinition); // 调用 BeanPostProcessor 执行 postProcessAfterInitialization 方法 bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); } catch (InvocationTargetException ex) { throw new BeanCreationException(mergedBeanDefinition.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex.getTargetException()); } catch (Exception ex) { throw new BeanCreationException(mergedBeanDefinition.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex); } return bean; } 从 bean 的实例化过程中，Spring 容器在启动时只针对单例且非延迟加载的 bean 进行初始化；其他的 bean 只有在显示调用 getBean() 方法时才去实例化；下面将会对实例化过程中的详细过程进行说明。 Spring Bean 作用域singleton 单例模式 Spring IoC 容器中只会存在一个共享的Bean实例，无论有多少个Bean引用它，始终指向同一对象。 &lt;bean id=&quot;test&quot; singleton=&quot;true&quot; /&gt; &lt;bean scope=&quot;singleton&quot; /&gt; Spring 1.0 中通过 bean 定义属性 singleton=&#39;true&#39; 表示单例； 在 Spring 2.x 之后版本改为定义属性 scope=&#39;singleton&#39;, 同时兼容 1.0 的配置 prototype 原型模式 每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态 &lt;bean id=&quot;test&quot; singleton=&quot;false&quot; /&gt; &lt;bean scope=&quot;prototype&quot; /&gt; Spring 1.0 中通过 bean 定义属性 singleton=&#39;false&#39; 表示原型模式； 在 Spring 2.x 之后版本改为定义属性 scope=&#39;prototype&#39;, 同时兼容 1.0 的配置 Spring Bean 生命周期 示例public class LifecycleBean implements BeanNameAware, InitializingBean, BeanFactoryAware, ResourceLoaderAware, ApplicationContextAware, DisposableBean { public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;set bean factory&quot;); } public void setBeanName(String name) { System.out.println(&quot;set bean name&quot;); } public void afterPropertiesSet() throws Exception { System.out.println(&quot;Initializing Bean afterPropertiesSet&quot;); } public void setApplicationContext(ApplicationContext context) throws BeansException { System.out.println(&quot;set application context&quot;); } public void setResourceLoader(ResourceLoader resourceLoader) { System.out.println(&quot;set resource loader&quot;); } public void init () { System.out.println(&quot;do init method&quot;); } public Object postProcessBeforeInitialization(Object bean, String name) throws BeansException { System.out.println(&quot;post Process Before Initialization&quot;); return bean; } public Object postProcessAfterInitialization(Object bean, String name) throws BeansException { System.out.println(&quot;post Process After Initialization&quot;); return bean; } public void destroy() throws Exception { System.out.println(&quot;do destroy &quot;); } public void destroyMethod() throws Exception { System.out.println(&quot;do destroy method&quot;); } } public class PostProcessor implements BeanPostProcessor { public Object postProcessBeforeInitialization(Object bean, String name) throws BeansException { if (bean instanceof LifecycleBean) { ((LifecycleBean) bean).postProcessBeforeInitialization(bean, name); } return bean; } public Object postProcessAfterInitialization(Object bean, String name) throws BeansException { if (bean instanceof LifecycleBean) { ((LifecycleBean) bean).postProcessAfterInitialization(bean, name); } return bean; } } spring 配置文件如下 &lt;beans&gt; &lt;bean id=&quot;lifecycleBean&quot; class=&quot;org.springframework.beans.factory.LifecycleBean&quot; init-method=&quot;init&quot; /&gt; &lt;bean id=&quot;postProcessor&quot; class=&quot;org.springframework.beans.factory.PostProcessor&quot; /&gt; &lt;/beans&gt; 运行结果如下： set bean name set bean factory set resource loader set application context post Process Before Initialization Initializing Bean afterPropertiesSet do init method post Process After Initialization do destroy do destroy method Spring Bean 注入方式构造注入&lt;bean&gt; &lt;constructor-arg index=&quot;1&quot;&gt; &lt;value&gt;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean autowire=&quot;constructor&quot; /&gt; 当 bean 定义配置如以上方式的时候，会触发 autowireConstructor (详细实现参考源码吧) BeanWrapper instanceWrapper = null; if (mergedBeanDefinition.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mergedBeanDefinition.hasConstructorArgumentValues()) { instanceWrapper = autowireConstructor(beanName, mergedBeanDefinition); } byType 注入&lt;bean autowire=&quot;byType&quot; /&gt; 当 bean 定义配置如以上方式的时候，会触发 autowireByType 如下： protected void autowireByType(String beanName, RootBeanDefinition mergedBeanDefinition, BeanWrapper bw, MutablePropertyValues pvs) { // 查找 bean 存在可写方法的非基本数据类型的成员变量 String[] propertyNames = unsatisfiedObjectProperties(mergedBeanDefinition, bw); for (int i = 0; i &lt; propertyNames.length; i++) { String propertyName = propertyNames[i]; // look for a matching type // 获取成员变量的类型 Class requiredType = bw.getPropertyDescriptor(propertyName).getPropertyType(); // 查找成员变量对应的 bean 实例 Map matchingBeans = findMatchingBeans(requiredType); if (matchingBeans != null &amp;&amp; matchingBeans.size() == 1) { // 成员变量查找到匹配的bean实例，有且只有一个的时候 // 将属性名和属性值 添加到 PropertyValues 中 pvs.addPropertyValue(propertyName, matchingBeans.values().iterator().next()); if (logger.isDebugEnabled()) { logger.debug(&quot;Autowiring by type from bean name &#39;&quot; + beanName + &quot;&#39; via property &#39;&quot; + propertyName + &quot;&#39; to bean named &#39;&quot; + matchingBeans.keySet().iterator().next() + &quot;&#39;&quot;); } } else if (matchingBeans != null &amp;&amp; matchingBeans.size() &gt; 1) { // 当存在多个同类型的实例时 抛出异常 throw new UnsatisfiedDependencyException(beanName, propertyName, &quot;There are &quot; + matchingBeans.size() + &quot; beans of type [&quot; + requiredType + &quot;] for autowire by type. &quot; + &quot;There should have been 1 to be able to autowire property &#39;&quot; + propertyName + &quot;&#39; of bean &#39;&quot; + beanName + &quot;&#39;.&quot;); } else { if (logger.isDebugEnabled()) { logger.debug(&quot;Not autowiring property &#39;&quot; + propertyName + &quot;&#39; of bean &#39;&quot; + beanName + &quot;&#39; by type: no matching bean found&quot;); } } } } byName 注入&lt;bean autowire=&quot;byName&quot; /&gt; 当 bean 定义配置如以上方式的时候，会触发 autowireByName 如下： protected void autowireByName(String beanName, RootBeanDefinition mergedBeanDefinition, BeanWrapper bw, MutablePropertyValues pvs) { // 查找 bean 存在可写方法的非基本数据类型的成员变量 String[] propertyNames = unsatisfiedObjectProperties(mergedBeanDefinition, bw); for (int i = 0; i &lt; propertyNames.length; i++) { String propertyName = propertyNames[i]; // 在 Spring 容器中查找是否存在以 propertyName 命名的 bean definition if (containsBean(propertyName)) { // 实例化依赖的 bean, 并添加到 MutablePropertyValues 中 Object bean = getBean(propertyName); pvs.addPropertyValue(propertyName, bean); if (logger.isDebugEnabled()) { logger.debug(&quot;Added autowiring by name from bean name &#39;&quot; + beanName + &quot;&#39; via property &#39;&quot; + propertyName + &quot;&#39; to bean named &#39;&quot; + propertyName + &quot;&#39;&quot;); } } else { if (logger.isDebugEnabled()) { logger.debug(&quot;Not autowiring property &#39;&quot; + propertyName + &quot;&#39; of bean &#39;&quot; + beanName + &quot;&#39; by name: no matching bean found&quot;); } } } } set 注入&lt;bean&gt; &lt;property name=&quot;age&quot;&gt; &lt;value&gt;11&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; 当 bean 定义配置如上，或者采用 byName, byType 的注入方式时，都会调用 applyPropertyValues 方法完成属性的注入。（详细实现参考源码吧） Spring Bean 注解式注入 自 Spring 2.5 版本之后，支持通过注解方式实现 Bean 的自动注入，譬如 @Autowired, @Resource 等注解 为了引入注解式自动注入, Spring 在 2.x 版本中新增了 InstantiationAwareBeanPostProcessor 接口，该接口继承 BeanPostProcessor 并新增了方法 postProcessPropertyValues ; 该方法主要实现 Post-process the given property values before the factory applies them to the given bean Autowired 注解 采用 Autowired 注解实现自动注入，需在配置文件中配置 AutowiredAnnotationBeanPostProcessor Bean public AutowiredAnnotationBeanPostProcessor() { this.autowiredAnnotationTypes.add(Autowired.class); this.autowiredAnnotationTypes.add(Value.class); ClassLoader cl = AutowiredAnnotationBeanPostProcessor.class.getClassLoader(); try { this.autowiredAnnotationTypes.add((Class&lt;? extends Annotation&gt;) cl.loadClass(&quot;javax.inject.Inject&quot;)); logger.info(&quot;JSR-330 &#39;javax.inject.Inject&#39; annotation found and supported for autowiring&quot;); } catch (ClassNotFoundException ex) { // JSR-330 API not available - simply skip. } } 从 AutowiredAnnotationBeanPostProcessor 构造可以看出其支持 @Autowired,@Value,@Inject 注解的自动注入。 下面大概看下其如何实现自动注入 public PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException { // 查找 bean 中需要自动注入的元数据，包括 field， method InjectionMetadata metadata = findAutowiringMetadata(bean.getClass()); try { // 实现注入 metadata.inject(bean, beanName, pvs); } catch (Throwable ex) { throw new BeanCreationException(beanName, &quot;Injection of autowired dependencies failed&quot;, ex); } return pvs; } Resource 注解 采用 Resource 注解实现自动注入，需在配置文件中配置 CommonAnnotationBeanPostProcessor Bean public CommonAnnotationBeanPostProcessor() { setOrder(Ordered.LOWEST_PRECEDENCE - 3); setInitAnnotationType(PostConstruct.class); setDestroyAnnotationType(PreDestroy.class); ignoreResourceType(&quot;javax.xml.ws.WebServiceContext&quot;); } 从 CommonAnnotationBeanPostProcessor 构造可以看出，该类同时支持对注解 @PostConstruct, @PreDestroy 生效。 public PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException { // 查找 bean 中标注有 @Resource 注解的 Field， method InjectionMetadata metadata = findResourceMetadata(bean.getClass()); try { // 实现注入 metadata.inject(bean, beanName, pvs); } catch (Throwable ex) { throw new BeanCreationException(beanName, &quot;Injection of resource dependencies failed&quot;, ex); } return pvs; } public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { // 查找 bean 定义中标注了 PostConstruct 注解的方法 LifecycleMetadata metadata = findLifecycleMetadata(bean.getClass()); try { // 调用指定 post construct method metadata.invokeInitMethods(bean, beanName); } catch (InvocationTargetException ex) { throw new BeanCreationException(beanName, &quot;Invocation of init method failed&quot;, ex.getTargetException()); } catch (Throwable ex) { throw new BeanCreationException(beanName, &quot;Couldn&#39;t invoke init method&quot;, ex); } return bean; } public void postProcessBeforeDestruction(Object bean, String beanName) throws BeansException { // 查找 bean 定义中标注了 PreDestroy 注解的方法 LifecycleMetadata metadata = findLifecycleMetadata(bean.getClass()); try { // 调用指定 destroy method metadata.invokeDestroyMethods(bean, beanName); } catch (InvocationTargetException ex) { String msg = &quot;Invocation of destroy method failed on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;; if (logger.isDebugEnabled()) { logger.warn(msg, ex.getTargetException()); } else { logger.warn(msg + &quot;: &quot; + ex.getTargetException()); } } catch (Throwable ex) { logger.error(&quot;Couldn&#39;t invoke destroy method on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;, ex); } } private LifecycleMetadata buildLifecycleMetadata(Class clazz) { final boolean debug = logger.isDebugEnabled(); LinkedList&lt;LifecycleElement&gt; initMethods = new LinkedList&lt;LifecycleElement&gt;(); LinkedList&lt;LifecycleElement&gt; destroyMethods = new LinkedList&lt;LifecycleElement&gt;(); Class&lt;?&gt; targetClass = clazz; do { LinkedList&lt;LifecycleElement&gt; currInitMethods = new LinkedList&lt;LifecycleElement&gt;(); LinkedList&lt;LifecycleElement&gt; currDestroyMethods = new LinkedList&lt;LifecycleElement&gt;(); // 遍历 bean 的所有方法 for (Method method : targetClass.getDeclaredMethods()) { if (this.initAnnotationType != null) { // 判断 method 是否标注了 @PostConstruct 注解 if (method.getAnnotation(this.initAnnotationType) != null) { LifecycleElement element = new LifecycleElement(method); currInitMethods.add(element); if (debug) { logger.debug(&quot;Found init method on class [&quot; + clazz.getName() + &quot;]: &quot; + method); } } } if (this.destroyAnnotationType != null) { // 判断 method 是否标注了 @PreDestroy 注解 if (method.getAnnotation(this.destroyAnnotationType) != null) { currDestroyMethods.add(new LifecycleElement(method)); if (debug) { logger.debug(&quot;Found destroy method on class [&quot; + clazz.getName() + &quot;]: &quot; + method); } } } } initMethods.addAll(0, currInitMethods); destroyMethods.addAll(currDestroyMethods); targetClass = targetClass.getSuperclass(); } while (targetClass != null &amp;&amp; targetClass != Object.class); return new LifecycleMetadata(clazz, initMethods, destroyMethods); } &lt;context: annotation-config&gt; 为了简化 Spring 配置文件中的 bean 配置，Spring 提供了 &lt;context: annotation-config&gt; 标签自动加载 AutowiredAnnotationBeanPostProcessor, CommonAnnotationBeanPostProcessor 等 bean。 在 spring-context 包 resources/META-INF 下的 spring.handlers 文件中配置如下： http\\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler public class ContextNamespaceHandler extends NamespaceHandlerSupport { public void init() { registerBeanDefinitionParser(&quot;property-placeholder&quot;, new PropertyPlaceholderBeanDefinitionParser()); registerBeanDefinitionParser(&quot;property-override&quot;, new PropertyOverrideBeanDefinitionParser()); registerBeanDefinitionParser(&quot;annotation-config&quot;, new AnnotationConfigBeanDefinitionParser()); registerBeanDefinitionParser(&quot;component-scan&quot;, new ComponentScanBeanDefinitionParser()); registerBeanDefinitionParser(&quot;load-time-weaver&quot;, new LoadTimeWeaverBeanDefinitionParser()); registerBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser()); registerBeanDefinitionParser(&quot;mbean-export&quot;, new MBeanExportBeanDefinitionParser()); registerBeanDefinitionParser(&quot;mbean-server&quot;, new MBeanServerBeanDefinitionParser()); } } public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, Object source) { Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(4); if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) { RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); } if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) { // 加载注册 AutowiredAnnotationBeanPostProcessor RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); } if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) { // 加载注册 RequiredAnnotationBeanPostProcessor RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); } // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) { // 加载注册 CommonAnnotationBeanPostProcessor RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); } // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) { RootBeanDefinition def = new RootBeanDefinition(); try { ClassLoader cl = AnnotationConfigUtils.class.getClassLoader(); def.setBeanClass(cl.loadClass(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME)); } catch (ClassNotFoundException ex) { throw new IllegalStateException( &quot;Cannot load optional framework class: &quot; + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); } def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); } return beanDefs; } 可以看出在 Spring 启动时，通过解析 &lt;context: annotation-config&gt; 标签，完成对 CommonAnnotationBeanPostProcessor, AutowiredAnnotationBeanPostProcessor 的加载注册，进而实现通过注解方式的自动注入。 小结BeanFactory &amp; ApplicationContext BeanFactoryPostProcessor &amp; BeanPostProcessor BeanFactoryPostProcessor 是 ApplicationContext 在 BeanFactory 完成创建后对其进行后置处理的接口 BeanPostProcessor 是 BeanFactory 在 Bean 完成实例化对其进行的后置处理接口 BeanFactory &amp; FactoryBean BeanFactory 是 Spring 框架底层的核心接口，其提供了创建 bean，获取 bean 等核心功能。 FactoryBean 是生产 bean 的一个模式，也就是以工厂模式的方式生产 bean。","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.hxlzpnyist.site/tags/Spring/"}],"keywords":[]},{"title":"LeetCode-数组-删除有序数组重复元素","slug":"LeetCode-数组-删除有序数组重复元素","date":"2019-02-26T05:39:13.000Z","updated":"2019-06-21T06:48:07.219Z","comments":true,"path":"2019/02/26/LeetCode-数组-删除有序数组重复元素/","link":"","permalink":"https://www.hxlzpnyist.site/2019/02/26/LeetCode-数组-删除有序数组重复元素/","excerpt":"","text":"题目描述给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。 不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 解题思路 采用双指针方式处理。 初始指针 i, j 位置为 0 指针 j 先向右移动 比较指针 i,j 元素是否相同，若指针i，j元素相同则指针 j 继续向右移动；反之将指针 j 元素复制到指针 i + 1 处元素 当指针 j 移动到数组末尾时则停止 其流程如下图所示： 实现public static int solution (int[] nums) { int i = 0, j = 0; while (true) { // 指针 j 向右移动 j++; // 指针 j 移动到数组末尾则退出，说明数组元素都判断了去重 if (j &gt;= nums.length) { break; } if (nums[j] == nums[i]) { // 指针 i, j 元素相同，说明重复元素； // 指针 j 继续向右移动 continue; } else { // 指针 i, j 元素不相同；则将指针 j 元素复制到 指针 i 后一位，这样就保证指针 i 后元素不重复 nums[i + 1] = nums[j]; // 指针 i 向右移动，继续处理 i++; } } return i + 1; }","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://www.hxlzpnyist.site/tags/LeetCode/"}],"keywords":[]},{"title":"LeetCode-数组-三数之和","slug":"LeetCode-数组-三数之和","date":"2019-02-24T09:44:40.000Z","updated":"2019-06-21T06:48:02.054Z","comments":true,"path":"2019/02/24/LeetCode-数组-三数之和/","link":"","permalink":"https://www.hxlzpnyist.site/2019/02/24/LeetCode-数组-三数之和/","excerpt":"","text":"题目描述给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 习题原文 解题思路 求三数之和为 0, nums[i] + nums[j] + nums[k] = 0 可以转换为求两个数之和，也即是 nums[i] + nums[j] = -nums[k]; 那么就可以通过指针移动去查找满足公式的数字，而为了方便控制指针的移动，前提是一组数字是有序的。 那么大概的解题思路如下: 对数组排序 定义三个指针 i, left, right; 指针 i 指向的是求和项，指针 left, right 分别指向数组的头部和尾部 当 -nums[i] = nums[left] + nums[right] 时满足公式，指针 left, right 继续向中部移动 当 -nums[i] &gt; nums[left] + nums[right] 时指针 left 向中部移动 当 -nums[i] &lt; nums[left] + nums[right] 时指针 righr 向中部移动 当指针 left，right 交叉时停止移动，指针 i 向下移动，指针 left, right 重置 其流程如下图所示: 实现public static List&lt;List&lt;Integer&gt;&gt; solution(int[] nums) { // 排序 Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; rs = new ArrayList&lt;&gt;(); int i = 0, left = 1, right = nums.length - 1; while (i &lt; nums.length - 2) { while (true) { // 左右指针交叉退出 if (right &lt;= left) { break; } if (-nums[i] == nums[left] + nums[right]) { rs.add(Arrays.asList(nums[i], nums[left], nums[right])); // 过滤同一结果内重复的数字 // 左右指针继续向中间移动 while (true) { if (left &gt;= nums.length - 1) { break; } if (nums[left] != nums[left + 1]) { left++; break; } else { left++; } } while (true) { if (right &lt;= 0) { break; } if (nums[right] != nums[right - 1]) { right--; break; } else { right--; } } continue; } if (-nums[i] &lt;= nums[left] + nums[right]) { right--; continue; } if (-nums[i] &gt; nums[left] + nums[right]) { left++; continue; } } // 过滤同一结果值的数字 while (true) { if (i &gt;= nums.length - 1) { break; } if (nums[i] != nums[i + 1]) { i++; break; } else { i++; } } //i++; left = i + 1; right = nums.length - 1; } return rs; }","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://www.hxlzpnyist.site/tags/LeetCode/"}],"keywords":[]},{"title":"Thread的中断理解","slug":"Thread的中断理解","date":"2018-12-28T08:09:28.000Z","updated":"2019-02-22T08:41:28.889Z","comments":true,"path":"2018/12/28/Thread的中断理解/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/28/Thread的中断理解/","excerpt":"","text":"Thread 的中断理解 首先我们需要明确一个概念 中断并非是终止。 interrupt() 线程中断方法, 调用该方法时会将线程的中断标志位标记为 true; (注意你可以理解为只是单纯的改变下标记，并不是使线程停止运行) isInterrupted() 获取线程的中断标志位，也就是判断是否被中断过; true 表示被中断过 InterruptedException 当线程处于阻塞状态时（执行过 wait , sleep 等），此时调用线程的 interrupt() 方法，在抛出 InterruptedException 之前会将中断标志位复位, 也就是说在抛出中断异常之后在调用 isInterrupted 会返回 false 而不是 true interrupted() 该方法是 Thread 的静态方法，返回当前线程是否中断过，同时对中断标志进行复位","categories":[],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"FutureTask 源码分析","slug":"FutureTask","date":"2018-12-25T08:09:28.000Z","updated":"2019-06-21T06:47:33.325Z","comments":true,"path":"2018/12/25/FutureTask/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/25/FutureTask/","excerpt":"","text":"FutureTask 源码分析 基于 JDK 1.7 成员变量 private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; /** The underlying callable; nulled out after running */ private Callable&lt;V&gt; callable; /** The result to return or exception to throw from get() */ private Object outcome; // non-volatile, protected by state reads/writes /** The thread running the callable; CASed during run() */ private volatile Thread runner; /** Treiber stack of waiting threads */ private volatile WaitNode waiters; 变量 state 记录当前任务的状态，其可取值范围如下： NEW : 任务初始状态 COMPLETING : 任务执行中 NORMAL : 任务已完成 CANCELLED : 任务取消 EXCEPTIONAL : 任务执行异常 INTERRUPTING : 任务中断 INTERRUPTED : 任务已中断 状态的流转可能会有以下几种情形： NEW -&gt; COMPLETING -&gt; NORMAL NEW -&gt; COMPLETING -&gt; EXCEPTIONAL NEW -&gt; CANCELLED NEW -&gt; INTERRUPTING -&gt; INTERRUPTED 变量 callable 存储的是可执行的任务，变量 outcome 存储任务的返回值，变量 runner 指向当前执行该任务的线程，变量 waiters 执行等待链表的头节点。 初始化 public FutureTask(Callable&lt;V&gt; callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; } FutureTask 在构造时会设置 state 为初始状态 NEW 。 任务的执行 - run() public void run() { // 只有状态 state 为 NEW， runner 为空的情况下才可以执行 if (state != NEW || // 将变量 runner 设置为当前线程， // 此处应该是为了保证任务只允许被一个线程处理，也即只允许执行一次 !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) { V result; boolean ran; try { // 执行 callable result = c.call(); ran = true; } catch (Throwable ex) { result = null; ran = false; setException(ex); } if (ran) // 成功执行后，设置结果值 set(result); } } finally { runner = null; int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } protected void set(V v) { // 设置 state 为 COMPLETING if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { // 设置返回结果 outcome = v; // 设置 state 为 NORMAL UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state // 任务完成唤醒挂起的线程 finishCompletion(); } } private void finishCompletion() { // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) { // 将 waiters 重置为空 if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) { // 采用死循环的方式唤醒挂起的线程 for (;;) { // 获取等待节点关联的线程 Thread t = q.thread; if (t != null) { q.thread = null; // 唤醒线程 LockSupport.unpark(t); } // 获取等待链表的下一个节点继续唤醒 WaitNode next = q.next; if (next == null) // 节点为空的时候 跳出循环 break; q.next = null; // unlink to help gc q = next; } break; } } done(); callable = null; // to reduce footprint } 从上述源码中可以看出 callable 只会被执行一次，执行过程如下： 设置 runner 为当前线程 回调 callable 设置状态 state 为 COMPLETING 设置返回结果 outcome 设置状态 state 为 NORMAL 唤醒等待链表 waiters 里的线程 那么 waiters 等待链表什么时候存在等待的节点呢 ？ 获取任务结果 - get() public V get() throws InterruptedException, ExecutionException { int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s); } private int awaitDone(boolean timed, long nanos) throws InterruptedException { // 等待时长 final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; // 采用死循环的方式 for (;;) { if (Thread.interrupted()) { removeWaiter(q); throw new InterruptedException(); } int s = state; if (s &gt; COMPLETING) { // 此时任务已完成，可退出循环 if (q != null) q.thread = null; return s; } else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) // 创建等待节点 q = new WaitNode(); else if (!queued) // 若未加入等待链表时，将 q 的 next 指向 waiters , 然后将 waiters 移动到 q queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) { nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) { // 超过等待时长 将等待节点移除 removeWaiter(q); return state; } LockSupport.parkNanos(this, nanos); } else // 挂起调用者线程 // 当任务执行完 执行 finishCompletion 是会被唤醒 LockSupport.park(this); } } private V report(int s) throws ExecutionException { Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x); } 从 get() 操作源码可以看出，当调用者线程执行 futureTask.get() 时首先判断当前 state 是否大于 COMPLETING; 若小于等于 COMPLETING 则调用 awaitDone 方法； 在 awaitDone 方法中采用轮询的方式执行以下逻辑： 创建 WaitNode 将调用者线程 WaitNode 的 next 指向 waiters， 然后将 waiters 指向调用者线程 WaitNode 若需要超时等待，则将调用者线程按指定时间挂起，反之将调用者线程挂起等待任务完成唤醒 state &gt; COMPLETING 任务完成退出循环 结合上述分析可得 FutureTask 执行活动图如下： 同时也可以看出，在 FutureTask 中内部维护了一个单向链表 waiters , 在执行 get 的时候会向其中添加节点: 任务取消 - cancel() /** * mayInterruptIfRunning 是否中断执行线程 */ public boolean cancel(boolean mayInterruptIfRunning) { if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) // 只有 FutureTask 为初始状态的时候 允许取消 return false; try { // in case call to interrupt throws exception if (mayInterruptIfRunning) { try { Thread t = runner; if (t != null) // 中断执行线程 t.interrupt(); } finally { // final state // 设置状态为 INTERRUPTED UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); } } } finally { // 唤醒挂起的线程 finishCompletion(); } return true; } 小结从上可以看出 FutureTask 可以用于当一个线程需要等待另外一个线程执行完某个任务后才能继续执行的场景下。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"DelayQueue 延迟阻塞队列使用及分析","slug":"DelayQueue 延迟阻塞队列使用及分析","date":"2018-12-22T08:09:28.000Z","updated":"2019-06-21T06:47:28.427Z","comments":true,"path":"2018/12/22/DelayQueue 延迟阻塞队列使用及分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/22/DelayQueue 延迟阻塞队列使用及分析/","excerpt":"","text":"延迟阻塞队列 DelayQueue DelayQueue 是一个支持延时获取元素的阻塞队列， 内部采用优先队列 PriorityQueue 存储元素，同时元素必须实现 Delayed 接口；在创建元素时可以指定多久才可以从队列中获取当前元素，只有在延迟期满时才能从队列中提取元素。 使用场景 因延迟阻塞队列的特性， 我们一般将 DelayQueue 作用于以下场景 ： 缓存系统 ： 当能够从 DelayQueue 中获取元素时，说该缓存已过期 定时任务调度 ： 下面我们以缓存系统的应用，看下 DelayQueue 的使用，代码如下： public class DelayQueueDemo { static class Cache implements Runnable { private boolean stop = false; private Map&lt;String, String&gt; itemMap = new HashMap&lt;&gt;(); private DelayQueue&lt;CacheItem&gt; delayQueue = new DelayQueue&lt;&gt;(); public Cache () { // 开启内部线程检测是否过期 new Thread(this).start(); } /** * 添加缓存 * * @param key * @param value * @param exprieTime 过期时间,单位秒 */ public void put (String key, String value, long exprieTime) { CacheItem cacheItem = new CacheItem(key, exprieTime); // 此处忽略添加重复 key 的处理 delayQueue.add(cacheItem); itemMap.put(key, value); } public String get (String key) { return itemMap.get(key); } public void shutdown () { stop = true; } @Override public void run() { while (!stop) { CacheItem cacheItem = delayQueue.poll(); if (cacheItem != null) { // 元素过期, 从缓存中移除 itemMap.remove(cacheItem.getKey()); System.out.println(&quot;key : &quot; + cacheItem.getKey() + &quot; 过期并移除&quot;); } } System.out.println(&quot;cache stop&quot;); } } static class CacheItem implements Delayed { private String key; /** * 过期时间(单位秒) */ private long exprieTime; private long currentTime; public CacheItem(String key, long exprieTime) { this.key = key; this.exprieTime = exprieTime; this.currentTime = System.currentTimeMillis(); } @Override public long getDelay(TimeUnit unit) { // 计算剩余的过期时间 // 大于 0 说明未过期 return exprieTime - TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - currentTime); } @Override public int compareTo(Delayed o) { // 过期时间长的放置在队列尾部 if (this.getDelay(TimeUnit.MICROSECONDS) &gt; o.getDelay(TimeUnit.MICROSECONDS)) { return 1; } // 过期时间短的放置在队列头 if (this.getDelay(TimeUnit.MICROSECONDS) &lt; o.getDelay(TimeUnit.MICROSECONDS)) { return -1; } return 0; } public String getKey() { return key; } } public static void main(String[] args) throws InterruptedException { Cache cache = new Cache(); // 添加缓存元素 cache.put(&quot;a&quot;, &quot;1&quot;, 5); cache.put(&quot;b&quot;, &quot;2&quot;, 4); cache.put(&quot;c&quot;, &quot;3&quot;, 3); while (true) { String a = cache.get(&quot;a&quot;); String b = cache.get(&quot;b&quot;); String c = cache.get(&quot;c&quot;); System.out.println(&quot;a : &quot; + a + &quot;, b : &quot; + b + &quot;, c : &quot; + c); // 元素均过期后退出循环 if (StringUtils.isEmpty(a) &amp;&amp; StringUtils.isEmpty(b) &amp;&amp; StringUtils.isEmpty(c)) { break; } TimeUnit.MILLISECONDS.sleep(1000); } cache.shutdown(); } } 执行结果如下： a : 1, b : 2, c : 3 a : 1, b : 2, c : 3 a : 1, b : 2, c : 3 key : c 过期并移除 a : 1, b : 2, c : null key : b 过期并移除 a : 1, b : null, c : null key : a 过期并移除 a : null, b : null, c : null cache stop 从执行结果可以看出，因循环内部每次停顿 1 秒，当等待 3 秒后，元素 c 过期并从缓存中清除，等待 4 秒后，元素 b 过期并从缓存中清除，等待 5 秒后，元素 a 过期并从缓存中清除。 实现原理变量重入锁private final transient ReentrantLock lock = new ReentrantLock(); 用于保证队列操作的线程安全性 优先队列private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;(); 存储介质，用于保证延迟低的优先执行 leader leader 指向的是第一个从队列获取元素阻塞等待的线程，其作用是减少其他线程不必要的等待时间。（这个地方我一直没搞明白 怎么就减少其他线程的等待时间了） conditionprivate final Condition available = lock.newCondition(); 条件对象，当新元素到达，或新线程可能需要成为leader时被通知 下面将主要对队列的入队，出队动作进行分析 ： 入队 - offer public boolean offer(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { // 入队 q.offer(e); if (q.peek() == e) { // 若入队的元素位于队列头部，说明当前元素延迟最小 // 将 leader 置空 leader = null; // 唤醒阻塞在等待队列的线程 available.signal(); } return true; } finally { lock.unlock(); } } 出队 - pollpublic E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { for (;;) { E first = q.peek(); if (first == null) // 等待 add 唤醒 available.await(); else { long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) // 已过期则直接返回队列头节点 return q.poll(); first = null; // don&#39;t retain ref while waiting if (leader != null) // 若 leader 不为空 // 说明已经有其他线程调用过 take 操作 // 当前调用线程 follower 挂起等待 available.await(); else { // 若 leader 为空 // 将 leader 指向当前线程 Thread thisThread = Thread.currentThread(); leader = thisThread; try { // 当前调用线程在指定 delay 时间内挂起等待 available.awaitNanos(delay); } finally { if (leader == thisThread) leader = null; } } } } } finally { if (leader == null &amp;&amp; q.peek() != null) // leader 处理完之后，唤醒 follower available.signal(); lock.unlock(); } } Leader-follower 模式 该图引用自 CSDN 《Leader/Follower多线程网络模型介绍》 小结 看了 DelayQueue 的实现 我们大概也明白 PriorityQueue 采用小顶堆的原因了。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"ThreadPoolExecutor线程池的实现分析","slug":"ThreadPoolExecutor-线程池的实现分析","date":"2018-12-20T08:09:28.000Z","updated":"2019-06-21T06:48:34.091Z","comments":true,"path":"2018/12/20/ThreadPoolExecutor-线程池的实现分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/20/ThreadPoolExecutor-线程池的实现分析/","excerpt":"","text":"ThreadPoolExecutor 线程池在 JAVA 中是运用场景最多的并发框架，合理的运用线程池能够带来以下好处： 降低资源消耗。 提高响应速度。 提高线程的可管理性 构造public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } 参数说明： corePoolSize ：核心线程数 maximumPoolSize : 最大线程数 keepAliveTime : 空闲线程最大存活时间 unit : 空闲线程存活时间单位 workQueue : 用于保存等待执行的任务的阻塞队列 threadFactory : 用于创建线程的工厂 RejectedExecutionHandler : 饱和策略，就是当队列和线程池满了之后，采用何种策略处理提交的新任务 线程池状态private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl // 计算 线程池运行状态 private static int runStateOf(int c) { return c &amp; ~CAPACITY; } // 计算 工作线程数 private static int workerCountOf(int c) { return c &amp; CAPACITY; } // 计算 ctl 值 private static int ctlOf(int rs, int wc) { return rs | wc; } RUNNING : 运行中，接收新的任务并且处理队列中的任务 SHUTDOWN : 关闭，停止接收新的任务，但是可以处理队列中的任务 STOP : 停止接收新的任务，也不处理队列中的任务；并中断处理中的任务 ThreadPoolExecutor 采用一个原子的整形变量按位存储线程池的状态和线程池的当前工作线程数。前 3 位为线程池状态，后 29 位为线程池工作线程数 为什么采用高 3 位， 因为目前线程池状态值有 5 种，采用 3 位的话正好可以存储 executepublic void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // workerCountOf 获取当前工作线程数 // 若当前工作线程数小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) { // 开启线程执行 command // 成功执行则返回 true 退出 if (addWorker(command, true)) return; // 执行失败 // 失败的原因 ：线程池状态变更为 SHUTDOWN 或 其他任务被提交执行导致工作线程数超过了核心线程数 c = ctl.get(); } // 判断线程池状态是否为 RUNNING // 将任务添加到 workQueue if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); // 任务被添加到 workQueue 后，再次检查线程池的运行状态 // 若线程池状态非 RUNNING, 则将任务从 workQueue 中移除 if (! isRunning(recheck) &amp;&amp; remove(command)) // 按指定的饱和拒绝策略处理任务 reject(command); // 当工作线程数为 0 的时候，则开启新的线程从 workQueue 中获取任务并执行 else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 若队列满，任务无法加入队列中，则开启线程执行任务 else if (!addWorker(command, false)) // 若无法开启线程执行任务，说明当前工作线程数超过最大线程数 // 按指定饱和策略处理任务 reject(command); } 创建 Workerprivate boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 此处的判断说明当线程池状态为 SHUTDOWN 的时候，如果工作队列 workQueue 中还有任务的话，将会继续处理；反之不处理 （firstTask == null 说明不是新提交的任务， 也就是新提交的任务不予处理） // 若状态大于 SHUTDOWN 也就是 STOP 时，无论工作队列中 workQueue 是否有任务都不予处理 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) { // 获取工作线程数 int wc = workerCountOf(c); // 判断当前工作线程数是否超过线程池最大容量 // 判断当前工作线程数是否超过核心线程数或者最大线程数 // 若超过则退出，也就是开启线程执行任务失败 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 工作线程数加一 if (compareAndIncrementWorkerCount(c)) // 退出循环 break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) // 运行状态发生变化 则继续轮询 continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 创建 worker 对象 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 添加到 workers 工作线程集合中 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { // 线程启动 t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; } 如下图所示为线程池创建 Worker 流程： 从 addWorker 的实现可以看出，当线程池状态为 SHUTDOWN, STOP 时，将不会在接收新的任务 Worker 执行 接下来我们看下 Worker 的构建 Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 创建线程 this.thread = getThreadFactory().newThread(this); } 从 Worker 的构建可以看出，当线程启动时，实际上执行的是 Worker 的 run 方法。 public void run() { runWorker(this); } final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { // 若能够获取一个待执行的任务 // 也即是 firstTask 不为空或者 workQueue 工作队列中有待执行的任务 while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); Throwable thrown = null; try { // 任务执行 task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); } } finally { task = null; // 当前 worker 完成的任务数加一 w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } 接下来我们看下如何从 workQueue 中获取待执行的任务 private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 线程池状态为 SHUTDOWN 并且 workQueue 为空的时候返回 null // 线程池状态为 STOP 返回 null if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } // 获取当前工作线程数 int wc = workerCountOf(c); // Are workers subject to culling? // allowCoreThreadTimeOut 该变量是指是否允许核心线程在指定存活时间内未获取到任务后回收; // wc &gt; corePoolSize 说明超过核心线程数的线程将会被回收 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 工作线程数超过最大线程数 可销毁 // 工作线程数超过核心线程数且上次等待获取任务超时 可销毁 // 若工作线程数等于 1 且 workQueue 队列为空的时候 可销毁 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) { // 工作线程数减一 if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 从队列获取任务 // 若 timed 为 true, 则当前 worker 在指定的 keepAliveTime 时间内等待获取任务；若为空，那么 worker 在下次轮询的时候满足条件下将会退出被回收 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } 如下图所示为 worker 获取任务及执行任务的流程： 从 getTask 的实现可以看出在以下情况下将对 worker 执行退出销毁 线程池状态为 STOP 线程池状态为 SHUTDOWN, 且 workQueue 队列为空 线程池工作线程数超过最大线程数 线程池工作线程数大于 1，且允许核心线程回收（allowCoreThreadTimeOut = true）同时 worker 上次从队列获取任务时 timeout 线程池工作线程数大于核心线程数并大于 1，同时 worker 上次从队列获取任务时 timeout 线程池工作线程数等于 1 且 workQueue 为空 个人理解 ：当 workQueue 不为空的时候，线程池最少会保留一个 worker 去执行任务 接下来看下当 worker 退出后的逻辑 : private void processWorkerExit(Worker w, boolean completedAbruptly) { // completedAbruptly 表示 worker 是否正常退出； true 说明用户任务处理过程中出现异常，false 是正常退出 if (completedAbruptly) // If abrupt, then workerCount wasn&#39;t adjusted // 若是异常退出的话，执行工作线程数减一 decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 累加完成的任务数 completedTaskCount += w.completedTasks; // 将 worker 从工作线程集合 workers 中移除 workers.remove(w); } finally { mainLock.unlock(); } // 尝试终止线程池 tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) { if (!completedAbruptly) { // 计算线程池允许的最小线程数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) // 若 min = 0，而 workQueue 不为空的话，说明有待处理的任务，则 min = 1，也就是至少有 1 个工作线程 min = 1; // 若当前工作线程数 &gt;= min, 则退出；反之创建新的 worker if (workerCountOf(c) &gt;= min) return; // replacement not needed } // worker 非正常退出的话，重新创建新的 worker addWorker(null, false); } } shutdown 关闭线程池，运行状态改为 SHUTDOWN; 并中断空闲的工作线程 public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 线程池状态修改为 SHUTDOWN advanceRunState(SHUTDOWN); // 中断空闲 worker interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } // 尝试终止线程池 tryTerminate(); } private void advanceRunState(int targetState) { for (;;) { int c = ctl.get(); // 当前状态值 小于 SHUTDOWN 的时候，执行更新 if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) break; } } private void interruptIdleWorkers() { interruptIdleWorkers(false); } private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) { Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) { // worker 对应的线程未被中断过，且能够获取到锁，说明线程空闲（因为 worker 在获取到任务执行的时候，会 lock） try { // 执行中断 // 此时会唤醒阻塞在 workQueue.take 或 poll 操作上的 worker; 当 worker 在 getTask 继续轮询的时候会退出 t.interrupt(); } catch (SecurityException ignore) { } finally { w.unlock(); } } if (onlyOne) break; } } finally { mainLock.unlock(); } } final void tryTerminate() { for (;;) { int c = ctl.get(); // 线程池状态为 STOP // 线程池状态为 SHUTDOWN 且 workQueue 为空的时候可终止 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 工作线程数等于 0 的时候可终止 if (workerCountOf(c) != 0) { // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 将工作线线程数改为 0，运行状态改为 TIDYING if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { // 执行终止操作，由子类实现 terminated(); } finally { // 将运行状态改为 TERMINATED ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } shutdownNow 关闭线程池，运行状态修改为 STOP, 中断所有线程； 并返回未处理的任务 public List&lt;Runnable&gt; shutdownNow() { List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 将线程池状态改为 STOP advanceRunState(STOP); // 中断所有的 Worder interruptWorkers(); // 清除任务队列，并返回任务列表 tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks; } private void interruptWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 将所有 worker 执行中断 for (Worker w : workers) w.interruptIfStarted(); } finally { mainLock.unlock(); } } 对于线程池的关闭操作 tryTerminate() 方法中的一段逻辑需要重点说明下，如下 if (workerCountOf(c) != 0) { // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; } interruptIdleWorkers(ONLY_ONE)是什么意思呢？中断闲置的Worker，直到回收全部的Worker。这里没有那么暴力，只中断一个，中断之后退出方法，中断了Worker之后，Worker会回收，然后还是会调用tryTerminate方法，如果还有闲置线程，那么继续中断 譬如有个场景 ： 线程池在执行 shutdown 操作后，假设工作线程 A, B 还在执行任务，此时假设 workQueue 队列中还有一个任务； 当 A, B 分别在继续执行 getTask 时，有可能 A 先获取到任务，B 被阻塞到 workQueue.task() 操作上，如果不进行 interruptIdleWorkers(ONLY_ONE) 处理，那么工作线程 B 将一直存活而无法回收。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"Semaphore-源码分析","slug":"Semaphore-的实现分析","date":"2018-12-15T08:09:28.000Z","updated":"2019-02-22T08:40:26.491Z","comments":true,"path":"2018/12/15/Semaphore-的实现分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/15/Semaphore-的实现分析/","excerpt":"","text":"Semaphore Semaphore 信号量：可以用来控制同时访问特定资源的线程数量；通过协调各个线程以保证合理的使用公共资源。 构造// permits 设置许可证的数量 public Semaphore(int permits) { // 默认非公平 sync = new NonfairSync(permits); } // permits 设置许可数量 // fair 设置是否采用公平模式 public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); } 非公平模式acquire() 获取许可。只有当获取到可用的许可，或者当前线程被中断；否则该线程被阻塞 public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1); } 默认会调用 NonfairSync 下的 tryAcquireShared 方法，继续调用父类的 nonfairTryAcquireShared 方法 protected int tryAcquireShared(int acquires) { return nonfairTryAcquireShared(acquires); } final int nonfairTryAcquireShared(int acquires) { for (;;) { // 获取当前 state 值 // 也即是当前可用的许可数 int available = getState(); // 当前可用许可数减去尝试获取许可的数 // 得到剩余许可数 int remaining = available - acquires; // remaining &lt; 0 说明当前可用许可数小于尝试获取许可数，也即是获取同步状态失败 直接返回 remaining, 退出循环 当前线程会被添加到同步队列中 // remaining &gt; 0 说明当前可用许可数大于尝试获取许可数， // 则执行 compareAndSetState 更新 state , 若更新成功则返回 退出循环 当前线程获取到许可 // 若 compareAndSetState 更新失败，说明有其他线程获取到许可，则继续轮询 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; } } release 释放许可 public void release() { sync.releaseShared(1); } protected final boolean tryReleaseShared(int releases) { for (;;) { // 获取当前许可数 int current = getState(); // 当前许可 + 释放的许可数 int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); // 更新 state 值, 更新成功则返回 true 退出循环；并唤醒同步队列上阻塞的线程 // 更新 state 值失败，说明有其他线程获取许可或释放了许可，则继续轮询 if (compareAndSetState(current, next)) return true; } } 公平模式acquire 公平模式下获取许可 protected int tryAcquireShared(int acquires) { for (;;) { // 判断同步队列上是否有阻塞的线程 // 若有的话，返回 -1 表示获取许可失败 退出循环加入同步队列中 if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; } } 从上述代码中可以看到，公平模式下获取许可和非公平模式下基本类似，只是为了保证 FIFO ，添加了 hasQueuedPredecessors 判断限制。 release 公平模式下与非公平模式一样 小结Semaphore 可以用来实现限流的作用。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"ReentrantReadWriteLock-读写锁源码分析","slug":"ReentrantReadWriteLock-读写锁","date":"2018-12-13T08:09:28.000Z","updated":"2019-06-21T06:48:28.441Z","comments":true,"path":"2018/12/13/ReentrantReadWriteLock-读写锁/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/13/ReentrantReadWriteLock-读写锁/","excerpt":"","text":"ReentrantReadWriteLock 读写锁 读写锁不同于 ReentrantLock ，ReentrantLock 是排他锁同一时刻只允许一个线程访问，而读写锁同一时刻允许多个读线程访问，但是在写线程操作时，所有的读写操作均被阻塞。 读写状态实现 如何通过一个 int 值记录读状态，写状态呢 ? 在 ReentrantReadWriteLock 中通过对同步状态值进行“按位切割”，因为 int 占 32 位 bit，故一分为二，采用高 16 位表示读状态，低 16 位表示写状态。 如何获取写状态值我们假设同步状态值转换为二进制如下： 0000 0000 0000 0010 | 0000 0000 0000 0101 上述同步状态值表示：读状态为 2， 写状态为 5 那么我们如何获取状态值呢 ？ 我们思考下位的相关运算 ： 位与操作(&amp;) 两个数同为 1 则为 1， 否则为 0 位或操作(|) 两个数有一个为 1 则为 1， 否则为 0 了解了 &amp; ，| 运算规律我们是不是可以这样操作呢，将同步状态值与如下二进制进行 &amp; 运算 0000 0000 0000 0000 | 1111 1111 1111 1111 结果可得 0000 0000 0000 0000 | 0000 0000 0000 0101 也就是写状态的二进制表示，值为 5. 那么 0000 0000 0000 0000 | 1111 1111 1111 1111 该位与操作数转成十进制也即是 65535 (2^15 + 2^14 + ….. + 2^0)，由等比数列可知等于 2^16 - 1, 也等于 (1 &lt;&lt; 16) - 1 。 这也是 ReentrantReadWriteLock 内部定义的常量实现 ： static final int SHARED_SHIFT = 16; static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; 如何获取读状态值获取读状态相比写状态来说就比较简单了，只需同步状态值 &gt;&gt; 右移 16 位即可 写状态值加一当写锁重入的时候，如何更新写状态值呢 ? 我们知道状态值的低 16 位表示写状态，那么每次写状态加一操作相当于下面二进制相加操作（逢二进一） 0000 0000 0000 0000 | 0000 0000 0000 0011 0000 0000 0000 0000 | 0000 0000 0000 0001 相加可得 0000 0000 0000 0000 | 0000 0000 0000 0100 也就是写状态值由 3 加一变成 4；那么对于写状态增加一时，也就是同步状态值 S + 1 即可。 读状态值加一读状态增加一，与写状态一样；只不过因为是高 16 位表示读状态，故是同步状态 S + (1 &lt;&lt; 16). 构造public ReentrantReadWriteLock() { this(false); } public ReentrantReadWriteLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); } writerLock() - 写锁public ReentrantReadWriteLock.WriteLock writeLock() { return writerLock; } 获取锁当执行 writeLock.lock() 的时候，实际上调用的是 sync.acquire(), 如下： public void lock() { // 写锁是独占模式 sync.acquire(1); } 下面我们看下 sync 的 tryAcquire 实现如下： protected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); // 获取同步状态值 int c = getState(); // 获取写状态值 int w = exclusiveCount(c); if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) // c != 0 说明此时已经有读或有写或有读写 // 若 w == 0 说明此时有读操作，则获取写锁失败 // 若 w != 0 说明此时已经有写操作 // 若 current != getExclusiveOwnerThread() 说明当前获取写锁的线程并非是写锁对象的持有者, 则重入失败 if (w == 0 || current != getExclusiveOwnerThread()) return false; // 重入次数超过最大值 抛出异常 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire // 设置状态值 setState(c + acquires); return true; } if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; // 设置当前线程为写锁的持有者 setExclusiveOwnerThread(current); return true; } 从代码的实现及注释中所描述的内容，可得知以下场景会获取写锁失败 : 当前已经有读操作，则获取写锁失败 当前已经有写操作，但当前线程并非写锁对象的持有者，则获取写锁失败（也是重入失败） 当前没有任何操作，CAS 更新状态值失败，则获取写锁失败 释放锁protected final boolean tryRelease(int releases) { // 判断当前线程是否为写锁对象的持有者 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 同步状态值释放 int nextc = getState() - releases; // 判断写状态是否为 0; 写状态为 0 说明写锁完成释放 boolean free = exclusiveCount(nextc) == 0; if (free) // 清空写锁的持有者 setExclusiveOwnerThread(null); setState(nextc); return free; } readLock() - 读锁public ReentrantReadWriteLock.ReadLock readLock() { return readerLock; } 获取锁public void lock() { sync.acquireShared(1); } 因为读写锁是支持同时多个线程获取读锁，所以调用的是 sync 共享式获取同步状态。 这里针对读锁的获取和释放我们简化下实现忽略对读锁计数统计的操作。 protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); for (;;) { // 获取读状态值 int c = getState(); // exclusiveCount(c) != 0 说明有写操作 // getExclusiveOwnerThread != current 说明当前线程非写锁的对象持有者; 则获取读锁失败 // 若 getExclusiveOwnerThread == current 也就是说明线程获取写锁之后是可以继续获取读锁的 if (exclusiveCount(c) != 0) { if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. } if (sharedCount(c) == MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); if (compareAndSetState(c, c + SHARED_UNIT)) { // 忽略读锁计数统计的操作 return 1; } } } 释放锁protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); // 忽略读锁计数统计的操作 for (;;) { int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; } } 小结 读写锁的实现关键在于如何通过一个 int 值，分别记录读写状态。（采用按位切割，高 16 位为读状态，低 16 位状态） 何时可以获取读锁 ? 获取写锁的线程可以再次获取读锁，获取读锁的线程数未超过 2^16 - 1 时是可以获取读锁。 何时可以获取写锁 ? 已经有读锁在操作则不可用获取写锁","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"ReentrantLock-重入锁源码分析","slug":"ReentrantLock-重入锁源码分析","date":"2018-12-11T08:09:28.000Z","updated":"2019-06-21T06:48:24.404Z","comments":true,"path":"2018/12/11/ReentrantLock-重入锁源码分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/11/ReentrantLock-重入锁源码分析/","excerpt":"","text":"ReentrantLock 重入锁, 表示该锁支持一个线程对资源的重复加锁 类结构首先让我们先看下 ReentrantLock 的类结构如下图所示： 从图中我们可以看出 ReentrantLock 实现 Lock 接口，同时内部类 Sync 是 AQS 的子类；而 Sync 又有两个子类 NonfairSync 和 FairSync 分别对应非公平和公平锁两种策略。 构造public ReentrantLock() { sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } ReentrantLock 默认采用非公平的策略，也可以在构造的时候指定是否公平的策略。 非公平锁 非公平锁是指在竞争获取锁的过程中，有可能后来者居上 lock() 获取锁static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() { // CAS 设置 state 值为 1 if (compareAndSetState(0, 1)) // CAS 成功则说明获取到锁, 此时将当前线程设置为独占模式下锁对象的持有者 setExclusiveOwnerThread(Thread.currentThread()); else // CAS 失败 // 可能是同一线程再次获取锁 // 也可能是不同线程获取锁 acquire(1); } protected final boolean tryAcquire(int acquires) { // 调用父类 sync return nonfairTryAcquire(acquires); } } final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 此时说明已有线程释放了锁 // 有可能是同步队列里阻塞的线程被唤醒时尝试获取锁 if (compareAndSetState(0, acquires)) { // CAS 成功则说明获取到锁, 此时将当前线程设置为独占模式下锁对象的持有者 setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { // 说明同一线程再次获取锁 // state 加 1 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 获取锁的过程如下 ： 通过 CAS 操作， 设置 state = 1 若 CAS 操作成功，则将当前线程设置为独占模式锁对象的持有者 若 CAS 操作失败, 最终会调用 sync 的方法 nonfairTryAcquire; 此时说明可能是同一线程再次尝试获取锁，也有可能是其他线程尝试获取锁 若当前 state == 0, 继续执行前两步操作 若当前 state != 0, 则判断当前线程是否为锁的持有者；若判断成立，则对 state + 1 unlock() - 释放锁 非公平锁的释放调用的是父类 sync 的 tryRelease 方法 protected final boolean tryRelease(int releases) { // state 减一操作 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) // 当前线程不是当前锁的持有者时抛出异常 throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { // 只有 state == 0 时 才是真正完成锁的释放 free = true; // 将锁的持有者清空 setExclusiveOwnerThread(null); } setState(c); return free; } 从释放锁的实现可以看出，获取锁与释放锁的操作是对等的，譬如下方伪代码： ReentrantLock lock = new ReentrantLock(); public void do () { lock.lock(); try { do(); // 退出递归 } finally { lock.unlock(); } } 公平锁 公平锁是指获取锁的顺序完全符合请求时间的顺序，也就是先到先得 lock() - 获取锁接下来我们下公平锁与非公平锁在获取锁时有什么不同 protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 不同于非公平锁操作，公平锁多了个判断条件 hasQueuedPredecessors if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // h != t 说明同步队列已有等待的节点 // s = h.next == null 这个有点没明白; head 的后置为空应该就是 head == tail 吧 // s.thread != Thread.currentThread 是判断当前线程是不是同步队列的首个阻塞线程 如果是是允许获取到锁的 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); } Queries whether any threads have been waiting to acquire longer than the current thread. hasQueuedPredecessors 方法主要实现的是查找是否有等待时间超过当前线程的其他线程, 公平锁也就是通过该方法保证获取锁的有序性。 unlock() - 释放锁公平锁的释放与非公平锁的释放操作一致 小结 ReentrantLock 如何实现可重入 ? (通过判断当前线程是否为当前锁对象的持有者) 如何实现公平锁 ? (若当前同步队列中有等待的节点则获取锁失败) 非公平锁和公平锁对性能有什么影响 ? (公平锁会造成大量的线程切换，非公平锁会出现线程“饥饿”现象，但线程切换少提高吞吐量)","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"CyclicBarrier 同步屏障的源码分析","slug":"CyclicBarrier-同步屏障的实现分析","date":"2018-12-09T04:09:28.000Z","updated":"2019-06-21T06:47:25.825Z","comments":true,"path":"2018/12/09/CyclicBarrier-同步屏障的实现分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/09/CyclicBarrier-同步屏障的实现分析/","excerpt":"","text":"CyclicBarrier CyclicBarrier 是可循环使用的屏障，主要功能是让一组线程到达一个屏障时被阻塞，直到最后一个线程到达屏障时，屏障才会打开；所有被屏障拦截的线程才会继续执行。 使用示例public class CyclicBarrierTest { // 线程个数 private int parties = 3; private AtomicInteger atomicInteger = new AtomicInteger(parties); private CyclicBarrier cyclicBarrier; class Protector implements Runnable { @Override public void run() { try { System.out.println(Thread.currentThread().getName() + &quot; - 到达屏障前&quot;); TimeUnit.SECONDS.sleep(2); cyclicBarrier.await(); atomicInteger.decrementAndGet(); System.out.println(Thread.currentThread().getName() + &quot; - 到达屏障后&quot;); } catch (InterruptedException e) { System.out.println(Thread.currentThread().getName() + &quot; - 等待中断&quot;); } catch (BrokenBarrierException e) { System.out.println(Thread.currentThread().getName() + &quot; - 屏障被破坏&quot;); } } } @Before public void init() { cyclicBarrier = new CyclicBarrier(parties); } @Test public void allAwait() { for (int i = 0; i &lt; parties; i++) { new Thread(new Protector(), &quot;Thread-&quot; + i).start(); } while (true) { if (atomicInteger.get() == 0) { // 所有线程到达屏障后退出结束 System.out.println(&quot;test over&quot;); break; } } } @Test public void oneAwaitInterrupted() throws InterruptedException { Thread threadA = new Thread(new Protector(), &quot;Thread-A&quot;); Thread threadB = new Thread(new Protector(), &quot;Thread-B&quot;); threadA.start(); threadB.start(); // 等待 3 秒，避免是 time sleep 触发中断异常 TimeUnit.SECONDS.sleep(3); threadA.interrupt(); while (true) { if (atomicInteger.get() == 0) { System.out.println(&quot;test over&quot;); break; } if (cyclicBarrier.isBroken()) { System.out.println(&quot;屏障中断退出&quot;); break; } } } } Thread-A - 到达屏障前 Thread-B - 到达屏障前 屏障中断退出 Thread-A - 等待中断 Thread-B - 屏障被破坏 Thread-0 - 到达屏障前 Thread-1 - 到达屏障前 Thread-2 - 到达屏障前 Thread-2 - 到达屏障后 Thread-0 - 到达屏障后 Thread-1 - 到达屏障后 test over 从 oneAwaitInterrupted 方法执行结果可以看出，当一个线程 A 执行中断时，另外一个线程 B 会抛出 BrokenBarrierException 构造// 可以指定拦截线程个数 public CyclicBarrier(int parties) { this(parties, null); } // 指定拦截线程个数和所有线程到达屏障处后执行的动作 public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; } 实现概念 barrier : 屏障 parties : 为屏障拦截的线程数 tripped : 跳闸，可以理解为打开屏障 generation.broken : 屏障是否破损，当屏障被打开或被重置的时候会改变值 简单的理解就是，当线程都到达屏障的时候，会打开屏障。 await() await 说明线程到达屏障 public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen } } private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; // 获取排他锁 lock.lock(); try { final Generation g = generation; // 屏障被破坏则抛异常 if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) { // 线程中断 则退出屏障 breakBarrier(); throw new InterruptedException(); } // 到达屏障的计数减一 int index = --count; if (index == 0) { // tripped // index == 0, 说明指定 count 的线程均到达屏障 // 此时可以打开屏障 boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) // 若指定了 barrierCommand 则执行 command.run(); ranAction = true; // 唤醒阻塞在屏障的线程并重置 generation nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) // 若未指定阻塞在屏障处的等待时间，则一直等待；直至最后一个线程到达屏障处的时候被唤醒 trip.await(); else if (nanos &gt; 0L) // 若指定了阻塞在屏障处的等待时间，则在指定时间到达时会返回 nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation &amp;&amp; ! g.broken) { // 若等待过程中，线程发生了中断，则退出屏障 breakBarrier(); throw ie; } else { // We&#39;re about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // &quot;belong&quot; to subsequent execution. Thread.currentThread().interrupt(); } } // 屏障被破坏 则抛出异常 if (g.broken) throw new BrokenBarrierException(); if (g != generation) // g != generation 说明所有线程均到达屏障处 可直接返回 // 因为所有线程到达屏障处的时候，会重置 generation // 参考 nextGeneration return index; if (timed &amp;&amp; nanos &lt;= 0L) { // 说明指定时间内，还有线程未到达屏障处，也就是等待超时 // 退出屏障 breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); } } private void nextGeneration() { // signal completion of last generation // 唤醒阻塞在等待队列的线程 trip.signalAll(); // set up next generation // 重置 count count = parties; // 重置 generation generation = new Generation(); } private void breakBarrier() { // broken 设置为 true generation.broken = true; // 重置 count count = parties; // 唤醒等待队列的线程 trip.signalAll(); } 如下图为 CyclicBarrier 实现效果图： isBroken() 返回屏障是否被破坏，也是是否被中断 public boolean isBroken() { final ReentrantLock lock = this.lock; lock.lock(); try { return generation.broken; } finally { lock.unlock(); } } reset()public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { // 唤醒阻塞的线程 breakBarrier(); // break the current generation // 重新设置 generation nextGeneration(); // start a new generation } finally { lock.unlock(); } } getNumberWaiting 获取阻塞在屏障处的线程数 public int getNumberWaiting() { final ReentrantLock lock = this.lock; lock.lock(); try { // 拦截线程数 - 未到达屏障数 return parties - count; } finally { lock.unlock(); } } 小结CyclicBarrier 和 CountDownLatch 功能类似，不同之处在于 CyclicBarrier 支持重复利用，而 CountDownLatch 计数只能使用一次。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"CountDownLatch-源码分析","slug":"CountDownLatch实现分析","date":"2018-12-07T08:09:28.000Z","updated":"2019-02-22T08:38:46.202Z","comments":true,"path":"2018/12/07/CountDownLatch实现分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/07/CountDownLatch实现分析/","excerpt":"","text":"CountDownLatch CountdownLatch 是 JDK 并发包中提供的并发工具类，其允许一个或多个线程等待其他线程完成操作。常用作将一个任务拆分成多个子任务同时执行，只有子任务都执行完毕主线程才往下执行。 使用示例public class App implements Runnable { private CountDownLatch countDownLatch; public App (CountDownLatch countDownLatch) { this.countDownLatch = countDownLatch; } public static void main( String[] args ) { // 指定同时运行3个子任务 int count = 3; CountDownLatch countDownLatch = new CountDownLatch(count); for (int i = 0; i &lt; count; i++) { new Thread(new App(countDownLatch), &quot;Thread-&quot; + i).start(); } try { countDownLatch.await(); } catch (InterruptedException e) { } System.out.println(&quot;count down over !&quot;); } @Override public void run() { try { TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread().getName() + &quot; - 执行完毕.&quot; ); } catch (InterruptedException e) { } finally { countDownLatch.countDown(); } } } 运行结果如下： Thread-2 - 执行完毕. Thread-0 - 执行完毕. Thread-1 - 执行完毕. count down over ! 从结果中可以看出 main 主线程会在 3 个子线程处理完毕之后才继续执行。 构造public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count); } CountDownLatch 与其他同步组件一样，内部类 Sync 继承了 AQS，构造的时候会指定子任务个数 count , 也即是同步状态初始值。 await()public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); } 接下来看下 sync 获取共享同步状态的实现 protected int tryAcquireShared(int acquires) { // state == 0 的时候返回 1，反之返回 -1 // state != 0 说明还有子任务未处理完 return (getState() == 0) ? 1 : -1; } 从实现可以看出 await() 方法执行时，当子任务未处理完毕时(state ！= 0)，调用线程会被添加到同步队列而阻塞等待。 countDown()public void countDown() { sync.releaseShared(1); } 接下来看下 sync 的共享同步状态值释放 protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; // 每次释放的时候，也就是子任务完成的时候计数值减一 int nextc = c-1; // 更新 state 值 if (compareAndSetState(c, nextc)) // 子任务均处理完毕后，返回 true； 也就是真正的释放 // 将唤醒阻塞在同步队列的线程 return nextc == 0; } } 从实现可以看出，每次子任务在调用 countDown 时，会将同步状态值减一，当所有子任务均完成时 (state = 0) 此时会唤醒阻塞在同步队列的节点。 小结子任务在进行 countDown 操作时，最好是在 finally 块处理； 避免出现子任务处理异常，导致主线程一直阻塞的问题。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"AQS 之 Condition-的源码分析","slug":"AQS 之 Condition","date":"2018-12-05T08:09:28.000Z","updated":"2019-06-21T06:47:22.316Z","comments":true,"path":"2018/12/05/AQS 之 Condition/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/05/AQS 之 Condition/","excerpt":"","text":"在使用 Lock 锁的过程中，我们往往会使用到另外一个对象 Condition ，用于等待/通知模式的处理。 Condition 的创建 Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); 使用 Condition 的前提是获取锁 final ConditionObject newCondition() { return new ConditionObject(); } 从 newCondition 方法看出 Condition 对象实际上是 AQS 的内部类 ConditionObject ()。 成员变量/** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; 从内部定义的变量 firstWaiter, lastWaiter 看出， ConditionObject 对象内部维护了一个同样以 Node 为节点的等待队列。 await() await 操作会使当前线程释放锁并进入等待模式。 public final void await() throws InterruptedException { if (Thread.interrupted()) // 当前线程中断 抛出中断异常 throw new InterruptedException(); // 将当前线程构造节点插入等待队列尾部 Node node = addConditionWaiter(); // 当前线程释放锁，唤醒同步队列 head 的后置节点 int savedState = fullyRelease(node); int interruptMode = 0; // 节点添加到同步队列后 退出循环 while (!isOnSyncQueue(node)) { LockSupport.park(this); // 应该是在其他线程释放锁后被唤醒 // 检查当前线程是否中断，若未中断则返回 0 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // node 进入自旋过程尝试获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { // 移除等待队列中状态非 CONDITION 的节点 unlinkCancelledWaiters(); t = lastWaiter; } // 将当前线程构造节点并设置状态为 CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) // 等待队列为空的时候将 firstWaiter 指向 node firstWaiter = node; else // 等待队列非空时将 lastWaiter 尾节点的 nextWaiter 指向 node t.nextWaiter = node; // 移动尾节点 lastWaiter = node; return node; } final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); // 当前线程释放锁，并唤醒同步队列中 head 的后置节点 if (release(savedState)) { failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } // 判断节点是否在同步队列上 final boolean isOnSyncQueue(Node node) { // 节点状态为 CONDITION 或 节点的前置为空 说明节点还在等待队列上 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 如果节点存在后置节点 next 则说明节点在同步队列上 if (node.next != null) // If has successor, it must be on queue return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. */ // 从 tail 尾节点开始遍历同步队列查找 node 节点；若存在返回 true,反之返回 false return findNodeFromTail(node); } await 操作流程如下 ： 将当前线程构造一个新的 node 节点，状态为 CONDITION 添加到等待队列尾部 释放锁，唤醒同步队列 head 的后置节点 判断当前 node 节点是否在同步队列中，若不在同步队列上则挂起当前线程，等待其他线程释放锁时被唤醒 节点 node 被唤醒后若在同步队列上，则进入自旋过程再次尝试获取锁 signal() signal 操作激活等待队列中节点 public final void signal() { // 判断当前线程是否为锁的持有者 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); } private void doSignal(Node first) { do { // 判断 first 的后置节点是否为空，为空说明等待队列为空 if ( (firstWaiter = first.nextWaiter) == null) // 等待队列的尾节点置为空 lastWaiter = null; // 将 first 的后置节点置为空，也即是将 first 节点从等待队列中移除 first.nextWaiter = null; // 执行信号转移 } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); } // 将节点从等待队列 (condition queue) 转移到 同步队列 (sync queue) final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. */ // 将节点状态设置为 0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ // 将节点添加到同步队列(sync queue)尾部， 此时 p 应该是 node 的前置节点 ws 为 0 Node p = enq(node); // int ws = p.waitStatus; // 将 node 的前置节点状态改为 SIGNAL; 便于节点 p 释放锁的时候唤醒 node if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; } signal 操作的流程如下： 将等待队列中的节点从队列中移除 将等待队列中的节点状态由 CONDITION 改为 0 将等待队列中的节点添加到 AQS 的同步队列尾部 signal 的作用 只是将节点从等待队列转移到同步队列中，只有当前线程释放锁后，转移到同步队列的节点才会有机会获取到锁。 如下图所示为 Condition 操作节点的转移过程： 小结从 Condition 的 await()、signal() 操作可以看出，其作用等效于 Object 对象的 await(), notify() 方法；","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"AbstractQueuedSynchronizer 队列同步器源码分析-共享锁","slug":"AbstractQueuedSynchronizer 队列同步器源码分析-共享锁","date":"2018-12-04T07:09:28.000Z","updated":"2019-06-21T06:47:09.018Z","comments":true,"path":"2018/12/04/AbstractQueuedSynchronizer 队列同步器源码分析-共享锁/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/04/AbstractQueuedSynchronizer 队列同步器源码分析-共享锁/","excerpt":"","text":"AQS 共享式同步状态获取和释放 上一篇文章中主要分析了 AQS 的独占模式对同步状态的获取和释放过程，本文主要分析下共享模式下的同步状态的获取和释放是如何实现的 共享锁获取public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) // 获取锁失败 doAcquireShared(arg); } private void doAcquireShared(int arg) { // 不同于独占模式下，创建的节点模式不同 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { // 不同独占模式 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 从 doAcquireShared 实现可以看出，共享模式下同步队列的节点在自旋的过程与独占模式基本类似，不同在于自旋过程中成功获取同步状态时的处理 private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); // 若 progagate &gt; 0 说明可继续向下传播唤醒节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); } } 从 setHeadAndPropagate 的实现我们可以看出在移动 head 节点之后，若满足继续往下传播唤醒的条件时将会调用 doReleaseShared 方法。 共享锁释放public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { // 释放同步状态 doReleaseShared(); return true; } return false; } `` ```java private void doReleaseShared() { for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { // 将 head 节点状态重置为 0 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // CAS 成功则唤醒下个节点 unparkSuccessor(h); } else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } // 头节点指向未发生变化的时候 退出循环 if (h == head) // loop if head changed break; } } 因共享模式下，会存在多个线程同时释放同步状态的场景， doReleaseShared 通过不断的轮询和 CAS 操作保证节点的唤醒。我们还是以图的形式模拟下多线程释放的场景：","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"AbstractQueuedSynchronizer 队列同步器源码分析","slug":"AbstractQueuedSynchronizer-队列同步器源码分析","date":"2018-12-02T08:09:28.000Z","updated":"2019-06-21T06:47:19.463Z","comments":true,"path":"2018/12/02/AbstractQueuedSynchronizer-队列同步器源码分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/12/02/AbstractQueuedSynchronizer-队列同步器源码分析/","excerpt":"","text":"AbstractQueuedSynchronizer 队列同步器（AQS） 队列同步器 (AQS), 是用来构建锁或其他同步组件的基础框架，它通过使用 int 变量表示同步状态，通过内置的 FIFO 的队列完成资源获取的排队工作。（摘自《Java并发编程的艺术》） 我们知道获取同步状态有独占和共享两种模式，本文先针对独占模式进行分析。 变量定义private transient volatile Node head; head 同步队列头节点 private transient volatile Node tail; tail 同步队列尾节点 private volatile int state; state 同步状态值 Node - 同步队列节点定义volatile int waitStatus; waitStatus 节点的等待状态，可取值如下 : 0 : 初始状态 -1 : SIGNAL 处于该状态的节点，说明其后置节点处于等待状态； 若当前节点释放了锁可唤醒后置节点 -2 : CONDITION 该状态与 Condition 操作有关后续在说明 -3 : PROPAGATE 该状态与共享式获取同步状态操作有关后续在说明 1 : CANCELLED 处于该状态的节点会取消等待，从队列中移除 volatile Node prev; prev 指向当前节点的前置节点 volatile Node next; next 指向当前节点的后置节点 volatile Thread thread; thread 节点对应的线程也是指当前获取锁失败的线程 Node nextWaiter; acquire() 独占模式下获取同步状态， 既是当前只允许一个线程获取到同步状态 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 从 acquire 方法中我们可以大概猜测下，获取锁的过程如下： tryAcquire 尝试获取同步状态， 具体如何判定获取到同步状态由子类实现 当获取同步状态失败时，执行 addWaiter 创建独占模式下的 Node 并将其添加到同步队列尾部 加入同步队列之后，再次尝试获取同步状态，当达到某种条件的时候将当前线程挂起等待唤醒 下面具体看下各个阶段如何实现： private Node addWaiter(Node mode) { // 绑定当前线程 创建 Node 节点 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 判断同步队列尾节点是否为空 if (pred != null) { // node 的前置节点指向队列尾部 node.prev = pred; // 将同步队列的 tail 移动指向 node if (compareAndSetTail(pred, node)) { // 将原同步队列的尾部后置节点指向 node pred.next = node; return node; } } // tail 为空说明同步队列还未初始化 // 此时调用 enq 完成队列的初始化及 node 入队 enq(node); return node; } private Node enq(final Node node) { // 轮询的方式执行 // 成功入队后退出 for (;;) { Node t = tail; if (t == null) { // Must initialize // 创建 Node, 并将 head 指向该节点 // 同时将 tail 指向该节点 // 完成队列的初始化 if (compareAndSetHead(new Node())) tail = head; } else { // node 的前置节点指向队列尾部 node.prev = t; // 将同步队列的 tail 移动指向 node if (compareAndSetTail(t, node)) { // 将原同步队列的尾部后置节点指向 node t.next = node; return t; } } } } 从代码中可以看出通过 CAS 操作保证节点入队的有序安全，其入队过程中如下图所示： final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; // for (;;) { // 获取当前节点的前置节点 final Node p = node.predecessor(); // 判断前置节点是否为 head 头节点 // 若前置节点为 head 节点，则再次尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) { // 若获取同步状态成功 // 则将队列的 head 移动指向当前节点 setHead(node); // 将原头部节点的 next 指向为空，便于对象回收 p.next = null; // help GC failed = false; // 退出轮询过程 return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ // 若前置节点状态为 -1 ，则说明后置节点 node 可以安全挂起了 return true; if (ws &gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { // ws &gt; 0 说明前置节点状态为 CANCELLED , 也就是说前置节点为无效节点 // 此时从前置节点开始向队列头节点方向寻找有效的前置节点 // 此操作也即是将 CANCELLED 节点从队列中移除 node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&#39;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 若前置节点状态为初始状态 则将其状态设为 -1 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } private final boolean parkAndCheckInterrupt() { // 将当前线程挂起 LockSupport.park(this); // 被唤醒后检查当前线程是否被挂起 return Thread.interrupted(); } 从 acquireQueued 的实现可以看出，节点在入队后会采用轮询的方式（自旋）重复执行以下过程： 判断前置节点是否为 head， 若为 head 节点则尝试获取同步状态； 若获取同步状态成功则移动 head 指向当前节点并退出循环 若前置节点非 head 节点或者获取同步状态失败，则将前置节点状态修改为 -1， 并挂起当前线程，等待被唤醒重复执行以上过程 如下图所示： 接下来我们看看同步状态释放的实现。 release 释放同步状态 public final boolean release(int arg) { // 尝试释放同步状态 if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒后置节点 unparkSuccessor(h); return true; } return false; } private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) // 将 head 节点状态改为 0 compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 获取后置节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) // 唤醒后置节点上所阻塞的线程 LockSupport.unpark(s.thread); } 从上述代码，我们可以明白释放同步状态的过程如下： 调用 tryRelease 尝试释放同步状态，同样其具体的实现由子类控制 成功释放同步状态后，将 head 节点状态改为 0 唤醒后置节点上阻塞的线程 如下图所示（红色曲线表示节点自旋过程） : acquireInterruptibly() 独占模式下获取同步状态，不同于 acquire 方法，该方法对中断操作敏感； 也就是说当前线程在获取同步状态的过程中，若被中断则会抛出中断异常 public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) // 检查线程是否被中断 // 中断则抛出中断异常由调用方处理 throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } private void doAcquireInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 不同于 acquire 的操作，此处在唤醒后检查是否中断，若被中断直接抛出中断异常 throw new InterruptedException(); } } finally { if (failed) // 抛出中断异常后最终执行 cancelAcquire cancelAcquire(node); } } private void cancelAcquire(Node node) { // Ignore if node doesn&#39;t exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. // 若当前节点为 tail 节点，则将 tail 移动指向 node 的前置节点 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) { // 同时将node 前置节点的 next 指向 null compareAndSetNext(pred, predNext, null); } else { // If successor needs signal, try to set pred&#39;s next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) { // 当前节点位于队列中部 Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) // 将前置节点的 next 指向 node 的后置节点 compareAndSetNext(pred, predNext, next); } else { // 若 node 的前置节点为 head 节点则唤醒 node 节点的后置节点 unparkSuccessor(node); } node.next = node; // help GC } } 从 acquireInterruptibly 的实现可以看出，若线程在获取同步状态的过程中出现中断操作，则会将当前线程对应的同步队列等待节点从队列中移除并唤醒可获取同步状态的线程。 tryAcquireNanos() 独占模式超时获取同步状态，该操作与acquireInterruptibly一样对中断操作敏感，不同在于超过等待时间若未获取到同步状态将会返回 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); } private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (nanosTimeout &lt;= 0L) return false; // 计算等待到期时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return true; } nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) // 超时时间到期直接返回 return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) // 按指定时间挂起s LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } 节点的状态同步队列中的节点在自旋获取同步状态的过程中，会将前置节点的状态由 0 初始状态改为 -1 SIGNAL, 若是中断敏感的操作则会将状态由 0 改为 1 同步队列中的节点在释放同步状态的过程中会将同步队列的 head 节点的状态改为 0， 也即是由 -1 变为 0； 小结本文主要分析了独占模式获取同步状态的操作，其大概流程如下： 在获取同步状态时，AQS 内部维护了一个同步队列，获取状态失败的线程会被构造一个节点加入到队列中并进行一系列自旋操作 在释放同步状态时，唤醒 head 的后置节点去获取同步状态","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"},{"name":"多线程","slug":"多线程","permalink":"https://www.hxlzpnyist.site/tags/多线程/"}],"keywords":[]},{"title":"TCP：三次握手、四次握手、backlog及其他","slug":"TCP：三次握手、四次握手、backlog及其他","date":"2018-03-13T11:58:41.000Z","updated":"2019-02-22T09:35:43.602Z","comments":true,"path":"2018/03/13/TCP：三次握手、四次握手、backlog及其他/","link":"","permalink":"https://www.hxlzpnyist.site/2018/03/13/TCP：三次握手、四次握手、backlog及其他/","excerpt":"","text":"参考博客 TCP：三次握手、四次握手、backlog及其他","categories":[],"tags":[],"keywords":[]},{"title":"Java内存模型","slug":"Java内存模型","date":"2018-03-11T11:42:20.000Z","updated":"2019-06-21T06:47:35.314Z","comments":true,"path":"2018/03/11/Java内存模型/","link":"","permalink":"https://www.hxlzpnyist.site/2018/03/11/Java内存模型/","excerpt":"","text":"定义Java 虚拟机规范中通过定义一种 Java 内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现 Java 程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存主内存 : 在 Java 内存模型中规定了所有的变量都存储在主内存中。工作内存 : 每个线程都有自己的工作内存，在工作内存中保存了该线程使用到的变量的主内存副本拷贝；线程对变量的所有操作必须在工作内存中完成，而不能直接读写主内存的变量；不同线程之间无法直接访问对方的工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 此处我们描述的主内存，工作内存与 Java 运行时数据中的堆,栈，方法区并不是同一层次的内存划分；二者基本上是没有关系的，不过也可以理解为主内存对应于 Java 堆中的对象实例，而工作内存对应于虚拟机中的栈。 内存间如何交互在 Java 内存模型中定义了８中操作用来实现内存间的交互，也即是变量如何从主内存拷贝到工作内存，以及工作内存中的变量如何同步回主内存。 ８中操作如下： lock : 锁定，作用于主内存的变量，将变量标志为一条线程独占的状态 unlock : 解锁，作用于主内存的变量，将处于锁定状态的变量释放，方便其他线程锁定 read : 读取，作用于主内存的变量，将一个变量的值从主内存传输到工作内存中 load : 载入，作用于工作内存，将read操作从主内存得到的变量放入工作内存的变量副本中 use : 使用，作用于工作内存的变量 assign : 赋值 store : 存储 write : 在 Java 模型中还规定了在完成上述操作时必须满足以下规则： 变量在工作内存中改变之后必须把该变化同步到主内存 一个变量在同一时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次；多次 lock 之后，只有执行相同次数的 unlock 操作，变量才会被解锁；也就是可重入锁。 对一个变量执行 lock 操作，将会清空工作内存中此变量的值也就是从主内存重新获取该变量的值更新到工作内存中 对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中","categories":[],"tags":[],"keywords":[]},{"title":"Jdk之LinkedHashMap","slug":"Jdk之LinkedHashMap","date":"2018-03-05T13:29:13.000Z","updated":"2019-06-21T06:47:59.201Z","comments":true,"path":"2018/03/05/Jdk之LinkedHashMap/","link":"","permalink":"https://www.hxlzpnyist.site/2018/03/05/Jdk之LinkedHashMap/","excerpt":"概述LinkedHashMap 与 HashMap 的不同之处在于前者遍历有序，后者遍历无序 从上图中可以看出 LinkedHashMap 继承至 HashMap , 并重写了 init, createEntry, addEntry, iterator 等方法。 同时新增了全局变量 header, 并自定义了 LinkedHashMap.Entry 内部类","text":"概述LinkedHashMap 与 HashMap 的不同之处在于前者遍历有序，后者遍历无序 从上图中可以看出 LinkedHashMap 继承至 HashMap , 并重写了 init, createEntry, addEntry, iterator 等方法。 同时新增了全局变量 header, 并自定义了 LinkedHashMap.Entry 内部类 private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; { // These fields comprise the doubly linked list used for iteration. Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) { super(hash, key, value, next); } /** * Removes this entry from the linked list. */ private void remove() { before.after = after; after.before = before; } /** * Inserts this entry before the specified existing entry in the list. */ private void addBefore(Entry&lt;K,V&gt; existingEntry) { after = existingEntry; before = existingEntry.before; before.after = this; after.before = this; } } 从代码中可以看出 LinkedHashMap.Entry 继承至 HashMap.Entry , 新增了变量 before, after; 以及内部方法 addBefore; 那么 LinkedHashMap 如何保证遍历有序的呢？下文将详细说明，首先我们先看下 LinkedHashMap 的初始化操作有何不同。 init void init() { header = new Entry&lt;&gt;(-1, null, null, null); header.before = header.after = header; } 在初始化过程中 构建了 header 节点 createEntry /** * This override differs from addEntry in that it doesn&#39;t resize the * table or remove the eldest entry. */ void createEntry(int hash, K key, V value, int bucketIndex) { HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); table[bucketIndex] = e; e.addBefore(header); size++; } 从代码中可以看出与 HashMap 不同之处在于 构建 Entry 实例之后执行了 e.addBefore 方法 private void addBefore(Entry&lt;K,V&gt; existingEntry) { // 当前节点的后驱节点指向 existingEntry after = existingEntry; // 当前节点的前驱节点指向 existingEntry 的后驱节点 before = existingEntry.before; // 当前节点的前驱节点的后驱节点指向当前节点 before.after = this; // 当前节点的后驱节点的前驱节点指向当前节点 after.before = this; } 从init, Entry.addBefore 方法可以看出 LinkedHashMap 内部维护了一个”双向链表”，每次添加元素的时候会将该节点添加到链表中；如下图所示： iteratorprivate abstract class LinkedHashIterator&lt;T&gt; implements Iterator&lt;T&gt; { Entry&lt;K,V&gt; nextEntry = header.after; Entry&lt;K,V&gt; lastReturned = null; /** * The modCount value that the iterator believes that the backing * List should have. If this expectation is violated, the iterator * has detected concurrent modification. */ int expectedModCount = modCount; public boolean hasNext() { // 当 nextEntry 不等于 header 的表示还未遍历到链表末尾 return nextEntry != header; } public void remove() { if (lastReturned == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); LinkedHashMap.this.remove(lastReturned.key); lastReturned = null; expectedModCount = modCount; } Entry&lt;K,V&gt; nextEntry() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (nextEntry == header) throw new NoSuchElementException(); Entry&lt;K,V&gt; e = lastReturned = nextEntry; // 指向节点的后驱节点 nextEntry = e.after; return e; } } 从内部类 LinkedHashIterator 中可以看出 LinkedHashMap 是遍历双向链表，从而保证遍历的时候有序. 同样 LinkedHashSet 内部是调用 LinkedHashMap 实现，同样也保证了遍历有序。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://www.hxlzpnyist.site/tags/数据结构/"}],"keywords":[]},{"title":"Jdk之HashMap","slug":"Jdk之HashMap","date":"2018-03-05T11:10:27.000Z","updated":"2019-06-21T06:47:45.028Z","comments":true,"path":"2018/03/05/Jdk之HashMap/","link":"","permalink":"https://www.hxlzpnyist.site/2018/03/05/Jdk之HashMap/","excerpt":"","text":"概述HashMap 是散列表的一种基于拉链法的实现方式。 本文先看下 HashMap 的迭代实现方式 private abstract class HashIterator&lt;E&gt; implements Iterator&lt;E&gt; { Entry&lt;K,V&gt; next; // next entry to return int expectedModCount; // For fast-fail int index; // current slot Entry&lt;K,V&gt; current; // current entry HashIterator() { expectedModCount = modCount; if (size &gt; 0) { // advance to first entry Entry[] t = table; // 遍历数组 直到发现一个不为空的 Entry while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; } } public final boolean hasNext() { return next != null; } final Entry&lt;K,V&gt; nextEntry() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); // 获取当前 Entry 链表的下一个节点，如果下个节点为空说明当前链表已经遍历结束 // 此时继续遍历数组 直到发现一个不为空的 Entry if ((next = e.next) == null) { Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; } current = e; return e; } public void remove() { if (current == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); Object k = current.key; current = null; HashMap.this.removeEntryForKey(k); expectedModCount = modCount; } } 遍历过程如下图所示：","categories":[],"tags":[],"keywords":[]},{"title":"jdk之LinkedList","slug":"jdk之LinkedList","date":"2018-02-28T11:54:31.000Z","updated":"2019-02-22T09:35:30.202Z","comments":true,"path":"2018/02/28/jdk之LinkedList/","link":"","permalink":"https://www.hxlzpnyist.site/2018/02/28/jdk之LinkedList/","excerpt":"定义public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 从定义可以看出 LinkedList 实现了接口 List, Deque, 表明其支持列表,栈，队列，双端队列的操作。","text":"定义public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 从定义可以看出 LinkedList 实现了接口 List, Deque, 表明其支持列表,栈，队列，双端队列的操作。 变量 transient int size = 0; /** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; size : 链表元素个数 first : 指向链表的头节点 last : 指向链表的尾节点 内部类 private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; } } Node 是 LinkedList 的内部类，定义了链表的节点结构: item : 节点存储的元素 prev : 当前节点的前驱节点 next : 当前节点的后驱节点 Apiadd(E)向链表中添加元素 public boolean add(E e) { linkLast(e); return true; } void linkLast(E e) { final Node&lt;E&gt; l = last; // 定义插入节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) // 链表为空 头尾节点均指向新插入的节点 first = newNode; else // 链表的尾节点后驱节点指向新插入的节点 l.next = newNode; // 元素个数加一 size++; modCount++; } 首先构建待插入的节点 将尾节点指向待插入的节点 若原尾节点为空，说明队列为空，将头节点也指向待插入的节点 若原尾节点非空，则将原尾节点的后驱节点指向待插入节点 元素个数加一 add(index, e)向链表中指定的位置插入元素 public void add(int index, E element) { // 检查位置index 是否在链表范围内 checkPositionIndex(index); if (index == size) // 表明在链表的末尾插入节点 linkLast(element); else linkBefore(element, node(index)); } node(index) 方法用于获取链表指定位置的节点 Node&lt;E&gt; node(int index) { // assert isElementIndex(index); // 判断index 是否比链表长度的一半小；size &gt;&gt; 1 相当于 size/2 // 如果小于链表的一半，则从头节点开始遍历 // 如果大于链表的一半，则从尾节点开始遍历 if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; } } linkBefor(E e, Node succ) 方法用于在指定节点前插入元素 void linkBefore(E e, Node&lt;E&gt; succ) { // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; } set(index, e)更新链表指定位置节点的元素，并返回老的元素 public E set(int index, E element) { checkElementIndex(index); // 获取指定位置的节点 Node&lt;E&gt; x = node(index); E oldVal = x.item; // 更新节点元素 x.item = element; return oldVal; } get(index)获取链表指定位置的元素 public E get(int index) { checkElementIndex(index); // 获取指定位置的节点 然后返回其存储的元素 return node(index).item; } remove(index)删除链表指定位置的节点并返回该节点存储的元素 public E remove(int index) { checkElementIndex(index); return unlink(node(index)); } unlink(node) 该方法从字面上理解即解除节点与链表的链接 E unlink(Node&lt;E&gt; x) { // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) { // 前驱节点为空，说明删除的节点为头节点 // 那么将头节点指向删除节点的后驱节点 first = next; } else { // 前驱节点不为空 // 将前驱节点的后驱节点指向删除节点的后驱节点 prev.next = next; // 删除节点的前驱节点指向空 x.prev = null; } if (next == null) { // 删除节点的后驱节点为空，说明删除节点为尾节点 // 那么将尾节点指向删除节点的前驱节点 last = prev; } else { // 后驱节点不为空 // 将后驱节点的前驱节点指向删除节点的前驱节点 next.prev = prev; // 删除节点的后驱节点指向空 x.next = null; } // 存储元素改为空,元素个数减一 x.item = null; size--; modCount++; return element; } iterator()链表的迭代, 内部调用的是 listIterator(0) 方法 public ListIterator&lt;E&gt; listIterator(int index) { checkPositionIndex(index); return new ListItr(index); } private class ListItr implements ListIterator&lt;E&gt; { private Node&lt;E&gt; lastReturned = null; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) { // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; } public boolean hasNext() { // nextIndex 小于 size 表明还未遍历到链表结尾 return nextIndex &lt; size; } public E next() { checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; // next 指向下一个节点 next = next.next; // nextIndex 加一 nextIndex++; return lastReturned.item; } }","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"}],"keywords":[]},{"title":"数据结构-平衡二叉树","slug":"数据结构-平衡二叉树","date":"2018-02-26T10:50:42.000Z","updated":"2019-06-21T07:05:20.573Z","comments":true,"path":"2018/02/26/数据结构-平衡二叉树/","link":"","permalink":"https://www.hxlzpnyist.site/2018/02/26/数据结构-平衡二叉树/","excerpt":"概念平衡二叉树平衡二叉树(Self-Balancing Binary Search Tree) 是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于１。","text":"概念平衡二叉树平衡二叉树(Self-Balancing Binary Search Tree) 是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于１。 平衡因子平衡因子 BF (Balance Factor) : 我们将二叉树上节点的左子树的深度减去右子树的深度值称为平衡因子；那么平衡二叉树上所有节点的平衡因子只可能是 -1, 0, 1。 只要二叉树上有一个节点的平衡因子的绝对值大于１, 那么该二叉树就是不平衡的 最小不平衡子树最小不平衡子树: 当我们在执行平衡二叉树插入节点时，距离插入节点最近的，且平衡因子的绝对值大于１的节点为根的子树，我们将其称之为最小不平衡子树。 示例现通过下图一些样例说明何为平衡二叉树 图１为平衡二叉树：因为除了根节点的平衡因子为０，其他节点的平衡因子的绝对值均为１，符合平衡二叉树的条件 图２不是平衡二叉树：因为节点５８的左节点为５９，５９ &gt; 58 不符合二叉树的性质左节点小于根节点，所以也不符合平衡二叉树 图３不是平衡二叉树：因为节点５８的左子树的深度为２，而右子树为空；平衡因子为２，所以不符合平衡二叉树的条件 图４为平衡二叉树，满足平衡二叉树的条件 同样如上图所示，插入节点３７时，距离它最近的且平衡因子超过１的节点为５８，所以５８节点开始以下的子树为最小不平衡子树。 实现原理平衡二叉树构建的基本思想就是在构建二叉排序树的过程中，每当插入一个节点时先检查是否因插入而破坏了树的平衡性；若是则找出最小不平衡子树，在保持二叉排序树特性的前提下调整最小不平衡子树中各节点之间的链接关系进行相应的旋转，使其成为新的平衡子树。 下面以一个数组 a[10] = {3, 2, 1, 4, 5, 6, 7, 10, 9, 8} 构建平衡二叉树的过程来说明其实现原理。 以上两张图说明了平衡二叉树在构建过程的原理。针对构建过程发现不平衡的处理有如下几个步骤： 当最小不平衡子树根节点的平衡因子BF大于１时，右旋；当平衡因子小于-1时左旋 当最小不平衡子树的BF与其子节点BF符号相反时，需要先对子节点进行一次旋转使得符号相同后再进行一次旋转已达到平衡 右旋 : 将旋转节点的左节点指向其左节点的右节点，然后将旋转节点的左节点的右节点指向旋转节点（旋转节点下降，其左节点上浮） 左旋 : 将旋转节点的右节点指向其右节点的左节点，然后将旋转节点的右节点的左节点指向旋转节点（旋转节点下降，其右节点上浮）","categories":[],"tags":[],"keywords":[]},{"title":"jdk之LinkedBlockingQueue","slug":"jdk之LinkedBlockingQueue","date":"2018-01-26T06:18:59.000Z","updated":"2019-06-21T06:47:48.233Z","comments":true,"path":"2018/01/26/jdk之LinkedBlockingQueue/","link":"","permalink":"https://www.hxlzpnyist.site/2018/01/26/jdk之LinkedBlockingQueue/","excerpt":"概述在上一篇文章中我们分析了 ArrayBlockingQueue , 今天在看下采用链表结构实现的阻塞队列。 分析前我们同样有以下疑问： 如何通过链表实现队列的 FIFO ? 如何保证队列操作的同步 ? 与 ArrayBlockingQueue 相比有如何优势 ?","text":"概述在上一篇文章中我们分析了 ArrayBlockingQueue , 今天在看下采用链表结构实现的阻塞队列。 分析前我们同样有以下疑问： 如何通过链表实现队列的 FIFO ? 如何保证队列操作的同步 ? 与 ArrayBlockingQueue 相比有如何优势 ? 定义同样首先我们先来看下 LinkedBlockingQueue 的相关属性定义如下： /** * 定义链表节点 * * item : 节点存储的元素 * next : 当前节点的后继节点 */ static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node(E x) { item = x; } } /** 定义队列的容量 默认为 Integer.MAX_VALUE */ private final int capacity; /** 定义当前队列的存储元素个数 */ private final AtomicInteger count = new AtomicInteger(0); /** * 队列头节点 * Invariant: head.item == null */ private transient Node&lt;E&gt; head; /** * 队列尾节点 * Invariant: last.next == null */ private transient Node&lt;E&gt; last; /** Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition(); 从定义中有以下几个疑问： 当前队列元素个数为什么采用原子操作类 AtomicInteger ? int 类型的变量为什么不可以？ 队列的头尾节点定义注释中为什么说 head last 都有一个不变性 item 永远为空 ? 构造 public LinkedBlockingQueue() { // 队列默认容量为 int 最大值 this(Integer.MAX_VALUE); } public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); // 设置队列容量 this.capacity = capacity; // 初始队列头尾节点 last = head = new Node&lt;E&gt;(null); } APIoffer(E e) public boolean offer(E e) { if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) // 若队列满了 返回 false; 说明插入失败 return false; int c = -1; // 定义节点 Node&lt;E&gt; node = new Node(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try { if (count.get() &lt; capacity) { // 插入队列 enqueue(node); // 队列元素个数加一，并返回原来的个数 c = count.getAndIncrement(); if (c + 1 &lt; capacity) // 队列未满唤醒因为队列满而阻塞的 put 操作 notFull.signal(); } } finally { putLock.unlock(); } // c == 0 说明队列曾经为空，那么需要唤醒阻塞在 take poll 操作上的线程 if (c == 0) signalNotEmpty(); return c &gt;= 0; } private void enqueue(Node&lt;E&gt; node) { // 将原尾节点的后继节点 指向 node // 将尾节点指针指向 node last = last.next = node; } offer 之后 last 永远指向链表的最近插入的节点，所以 last 节点的 next 永远为空。 poll() public E poll() { final AtomicInteger count = this.count; if (count.get() == 0) // 队列为空 返回 null return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { if (count.get() &gt; 0) { // 出队 获取队列头部元素 x = dequeue(); // 队列元素个数减一 并返回原个数 c = count.getAndDecrement(); if (c &gt; 1) // 唤醒因队列为空而阻塞的 take poll 操作 notEmpty.signal(); } } finally { takeLock.unlock(); } // c== capacity 说明队列曾经满了有 offer put 线程阻塞，故需唤醒 if (c == capacity) signalNotFull(); return x; } private E dequeue() { Node&lt;E&gt; h = head; // 取 head 的后继节点 Node&lt;E&gt; first = h.next; // 将 head 节点的 next 指向自己 h.next = h; // help GC // 将 head 重新指向头节点 head = first; E x = first.item; // 将 item 置为空 first.item = null; return x; } 此时我们可以看出 LinkedBlockingQueue 中通过移动节点 head last 指针来实现队列的 FIFO; 效果如下图所示： 因为插入和获取头部操作里采用的是两个不同的锁，所以为了保持不同线程不同操作内队列元素个数的一致性所以采用 AtomicInteger 计算而非 int 类型。 put(E e)public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { while (count.get() == capacity) { notFull.await(); } enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } if (c == 0) signalNotEmpty(); } take()","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"}],"keywords":[]},{"title":"jdk之ArrayBlockingQueue","slug":"jdk之ArrayBlockingQueue","date":"2018-01-24T06:28:27.000Z","updated":"2019-06-21T07:02:02.833Z","comments":true,"path":"2018/01/24/jdk之ArrayBlockingQueue/","link":"","permalink":"https://www.hxlzpnyist.site/2018/01/24/jdk之ArrayBlockingQueue/","excerpt":"概述ArrayBlockingQueue 又称为数组阻塞队列；其基于数组实现的有界阻塞队列，能容纳的元素数量固定，一旦创建就不能再增加其容量。 那么接下来我们会带着以下两个疑问进行分析： 如何通过数组实现队列的特性 FIFO ? 如何保证队列插入获取操作的同步 ?","text":"概述ArrayBlockingQueue 又称为数组阻塞队列；其基于数组实现的有界阻塞队列，能容纳的元素数量固定，一旦创建就不能再增加其容量。 那么接下来我们会带着以下两个疑问进行分析： 如何通过数组实现队列的特性 FIFO ? 如何保证队列插入获取操作的同步 ? 定义首先看下 ArrayBlockingQueue 的属性定义 如下： /** 固定大小数组用于存储队列元素 */ final Object[] items; /** 指向下次获取元素的下标 可以理解为指向队列头部 */ int takeIndex; /** 指向下次插入元素的下标 可以理解为指向队列尾部 */ int putIndex; /** 当前队列存储元素的个数 */ int count; /** 定义可重入锁 */ final ReentrantLock lock; /** 用于控制 take 操作的 condition */ private final Condition notEmpty; /** 用于控制 put 操作的 condition */ private final Condition notFull; 构造函数 public ArrayBlockingQueue(int capacity) { this(capacity, false); } /** * 创建固定容量的阻塞队列并设置访问策略 * @param capacity 队列的最大容量 * @param fair 队列的访问策略，true为公平锁策略, false为非公平锁；默认为 false */ public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); } 从构造函数可以看出，在创建 ArrayBlockinQueue 实例时，需指定队列最大存储元素的容量并设置内部重入锁的访问策略默认为非公平锁。 APIadd(E e) public boolean add(E e) { return super.add(e); } 从代码可以看出 ArrayBlockingQueue 的 add 方法的实现是基于父类 AbstractQueu 的实现如下： public boolean add(E e) { if (offer(e)) return true; else throw new IllegalStateException(&quot;Queue full&quot;); } 从代码中我们知道 add 方法的主要实现在 offer 方法内（将会在下文分析），如果能够插入成功则返回 true, 否则抛出 IllegalStateException 异常 remove()remove 方法移除队列的头部元素并返回, 其实现是在父类 AbstractQueue 中如下: public E remove() { E x = poll(); if (x != null) return x; else throw new NoSuchElementException(); } 如上代码知道 remov的主要实现在 poll 方法内；如果获取的头部元素不为空将返回，若为空则抛出 NoSUchElementException 异常。 offer(E e) public boolean offer(E e) { // 检查元素是否为空 checkNotNull(e); final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try { // 元素个数达到最大容量时返回 fae if (count == items.length) return false; // 执行插入返回 true else { insert(e); return true; } } finally { // 释放锁 lock.unlock(); } } private void insert(E x) { // 将元素插入数组指定的位置 items[putIndex] = x; // 将 putIndex 移动到下一个位置 putIndex = inc(putIndex); // 元素个数加一 ++count; // 当前队列非空，唤醒阻塞在获取元素操作上的线程 notEmpty.signal(); } 从代码可以看出 offer 方法将元素插入队列的逻辑如下： 判断元素是否为空 获取锁 判断队列是否已满，若已满则返回 false 通过指针 putIndex 将元素放入数组 移动指针 putIndex 指向下一个位置 队列当前元素个数加一 唤醒阻塞在获取元素操作上的线程 释放锁 poll() public E poll() { final ReentrantLock lock = this.lock; lock.lock(); try { // 队列空的时候 返回 null; 非空的时候调用 extract return (count == 0) ? null : extract(); } finally { lock.unlock(); } } private E extract() { final Object[] items = this.items; // 获取头部的元素 E x = this.&lt;E&gt;cast(items[takeIndex]); // 将队列头部置为空 items[takeIndex] = null; // 移动头部指针 takeIndex = inc(takeIndex); // 队列元素个数减一 --count; // 唤醒因队列满而阻塞的插入操作 notFull.signal(); return x; } poll 方法获取头部元素逻辑如下： 获取锁 判断队列是否为空，若空则返回 null 通过 takeIndex 头部指针获取队列头元素 将队列头部置为空 移动头部指针指向下个位置 队列元素个数减一 唤醒因队列满而阻塞的插入操作 返回头部元素并释放锁 此时我们可以看出 ArrayBlockingQueue 中通过两个指针 takeIndex putIndex 的移动来保证队列的 FIFO,如下图所示： 我们知道数组有界 在队列中又是如何保证循环利用的呢？ final int inc(int i) { return (++i == items.length) ? 0 : i; } 从 inc 方法可以看出在移动 takeindex putindex 指针的时候，当他们到达末尾的时候重新指向头部。 offer(E e,long timeout,TimeUnit u)该方法表示在指定的时间内将元素插入队列中，若失败返回 false 。 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 当前元素个数达到队列最大容量时 等待 while (count == items.length) { if (nanos &lt;= 0) // 说明已超时 队列满了插入失败 返回 false return false; nanos = notFull.awaitNanos(nanos); } // 执行插入 insert(e); return true; } finally { // 释放锁 lock.unlock(); } } 该方法与 offer(e) 实现基本相同，只是在当队列满的情况下会在设置的 timeout 时间内等待。 poll(long timeout, TimeUnit unit) public E poll(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 当队列空的时候等待队列有元素；若等待超时之后还未有元素则返回 false while (count == 0) { if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); } // 队列非空时 获取头部元素 return extract(); } finally { // 释放锁 lock.unlock(); } } 与 poll() 方法类似，不同之处在于当队列为空的时候等待。 put(E e) public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 队列满的时候 while (count == items.length) // 释放锁当前线程阻塞；等待 take 操作唤醒 notFull.await(); // 队列未满执行插入 insert(e); } finally { // 释放锁 lock.unlock(); } } 该方法与 offer 不同之处在于当队列满的时候，当前线程会阻塞直至等待 take 操作唤醒。 take() public E take() throws InterruptedException { final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 队列为空的时候 while (count == 0) // 释放锁当前线程阻塞；等待 put 操作唤醒 notEmpty.await(); // 队列非空 获取头部元素 return extract(); } finally { // 释放锁 lock.unlock(); } } 该方法与 poll 不同之处在于当队列为空的时候，当前线程会一直阻塞直至等待 put 操作唤醒。 小结 ArrayBlockingQueue 采用数组作为元素存储，故其为有界队列 ArrayBlockingQueue 通过指针 takeIndex putIndex 的移动来实现 FIFO ArrayBlockingQueue 通过定义 ReentrantLock 重入锁来保证插入获取操作的同步。也就是当前若有线程在执行插入操作，则获取操作同样会被阻塞。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"}],"keywords":[]},{"title":"jdk之BlockingQueue","slug":"jdk之BlockingQueue","date":"2018-01-24T03:20:13.000Z","updated":"2018-01-24T06:08:37.000Z","comments":true,"path":"2018/01/24/jdk之BlockingQueue/","link":"","permalink":"https://www.hxlzpnyist.site/2018/01/24/jdk之BlockingQueue/","excerpt":"概述BlockingQueue 被称为阻塞队列，除了具备 Queue 的特点外，还支持另外两项重要特性： 对于有界队列，当队列满的时候，插入操作会阻塞等待队列可用； 当队列空的时候，获取元素的操作会阻塞等待队列为非空 阻塞队列常用于“生产者－消费者”模式的业务场景，生产者就是往阻塞队列中插入元素的线程，消费者就是从阻塞队列中获取元素的线程；当生产者的速度大于消费者的速度，就可能出现有界队列满的情况，此时生产者就会出现阻塞等待状态直到队列中出现空闲；当生产者的速度小于消费者的速度就可能出现空队列的情况，消费者就会出现阻塞等待状态，直到队列中有元素。","text":"概述BlockingQueue 被称为阻塞队列，除了具备 Queue 的特点外，还支持另外两项重要特性： 对于有界队列，当队列满的时候，插入操作会阻塞等待队列可用； 当队列空的时候，获取元素的操作会阻塞等待队列为非空 阻塞队列常用于“生产者－消费者”模式的业务场景，生产者就是往阻塞队列中插入元素的线程，消费者就是从阻塞队列中获取元素的线程；当生产者的速度大于消费者的速度，就可能出现有界队列满的情况，此时生产者就会出现阻塞等待状态直到队列中出现空闲；当生产者的速度小于消费者的速度就可能出现空队列的情况，消费者就会出现阻塞等待状态，直到队列中有元素。 APIadd(Object o)该方法是将指定元素插入到队列中，如果队列可插入则返回 true, 否则抛出异常 offer(Object o)该方法将指定元素插入到队列中，如果队列可插入则返回 true, 否则返回 false offer (Object, timeout, timeunit)该方法在设定的等待时间内如果能将指定元素插入到队列中返回 true, 否则返回 false poll(long timeout,TimeUnit unit)该方法从队列中取出一个队首的元素，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。超时后，依然没有取得数据则返回NULL put(Object o)把对象o加入到BlockingQueue里，如果BlockingQueue没有足够空间，则调用此方法的线程会被阻塞等待，直到BlockingQueue里面有空闲空间时再继续执行 take( )取走BlockingQueue里排在首位的对象，如果BlockingQueue为空，则调用此方法的线程会被阻塞等待，直到BlockingQueue里面有新元素被加入后再继续执行 后续将会对 BlockingQueue 的几种实现进行分析.","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://www.hxlzpnyist.site/tags/jdk/"}],"keywords":[]},{"title":"Netty客户端链接派发分析","slug":"Netty客户端链接派发分析","date":"2018-01-20T02:39:43.000Z","updated":"2019-06-21T07:03:22.981Z","comments":true,"path":"2018/01/20/Netty客户端链接派发分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/01/20/Netty客户端链接派发分析/","excerpt":"在上篇针对 Netty 的服务端启动过程进行了分析，我们知道服务端包含了两个 NioEventLoopGroup, 一个是 boss 用于接收客户端的请求，一个是 worker 用于处理客户端的读写操作；那么 boss group 是如何将客户端链接通道派发到 worker 呢？本文主要针对这个问题进行分析。","text":"在上篇针对 Netty 的服务端启动过程进行了分析，我们知道服务端包含了两个 NioEventLoopGroup, 一个是 boss 用于接收客户端的请求，一个是 worker 用于处理客户端的读写操作；那么 boss group 是如何将客户端链接通道派发到 worker 呢？本文主要针对这个问题进行分析。 NioEventLoop上文中我们知道 netty 主要通过 NioEventLoop 内部的线程处理客户端请求，那么我们接下来详细看下该线程的实现： protected SingleThreadEventExecutor( EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.parent = parent; this.addTaskWakesUp = addTaskWakesUp; thread = threadFactory.newThread(new Runnable() { @Override public void run() { boolean success = false; updateLastExecutionTime(); try { SingleThreadEventExecutor.this.run(); success = true; } catch (Throwable t) { logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); } finally { } } }); threadProperties = new DefaultThreadProperties(thread); this.maxPendingTasks = Math.max(16, maxPendingTasks); taskQueue = newTaskQueue(); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;); } NioEventLoop 内部的线程运行时会调用抽象方法 run, 其实现如下： protected void run() { for (;;) { try { switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) { case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) { selector.wakeup(); } // fall through default: } cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) { try { processSelectedKeys(); } finally { // Ensure we always run tasks. runAllTasks(); } } else { final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); } finally { // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); } } } catch (Throwable t) { handleLoopException(t); } // Always handle shutdown even if the loop processing threw an exception. try { if (isShuttingDown()) { closeAll(); if (confirmShutdown()) { return; } } } catch (Throwable t) { handleLoopException(t); } } } 该线程内部以“死循环”的方式 执行 select 后处理 selectedKeys : private void processSelectedKeys() { if (selectedKeys != null) { processSelectedKeysOptimized(); } else { processSelectedKeysPlain(selector.selectedKeys()); } } selectedKeys 是在NioEventLoop构建时创建的SelectedSelectionKeySet实例，故会调用 processSelectedKeysOptimized 方法如下： private void processSelectedKeysOptimized() { for (int i = 0; i &lt; selectedKeys.size; ++i) { final SelectionKey k = selectedKeys.keys[i]; // null out entry in the array to allow to have it GC&#39;ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.keys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) { processSelectedKey(k, (AbstractNioChannel) a); } else { @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); } if (needsToSelectAgain) { // null out entries in the array to allow to have it GC&#39;ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.reset(i + 1); selectAgain(); i = -1; } } } 其实现是循环遍历 selectedKeys 集合中的 selectedKey 进行处理，那么此时我们会有一个疑惑： selector 选择器中就绪的通道的 selectedKey 是如何添加到 selectedKeys 集合中呢？ 让我们回过头在看下 NioEventLoop 开启 selector 的过程： private SelectorTuple openSelector() { final Selector unwrappedSelector; try { // 开启 selector 返回 EpollSelectorImpl 实例 unwrappedSelector = provider.openSelector(); } catch (IOException e) { throw new ChannelException(&quot;failed to open a new selector&quot;, e); } if (DISABLE_KEYSET_OPTIMIZATION) { return new SelectorTuple(unwrappedSelector); } final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); // ...... final Class&lt;?&gt; selectorImplClass = (Class&lt;?&gt;) maybeSelectorImplClass; Object maybeException = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { try { Field selectedKeysField = selectorImplClass.getDeclaredField(&quot;selectedKeys&quot;); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(&quot;publicSelectedKeys&quot;); Throwable cause = ReflectionUtil.trySetAccessible(selectedKeysField); if (cause != null) { return cause; } cause = ReflectionUtil.trySetAccessible(publicSelectedKeysField); if (cause != null) { return cause; } // 将 Selector 实现类的属性 selectedKeys 替换为 netty 自定义的 SelectedSelectionKeySet // 这样当选择器 有就绪的通道时 就会把 selectKey 添加到 SelectedSelectionKeySet 中 selectedKeysField.set(unwrappedSelector, selectedKeySet); publicSelectedKeysField.set(unwrappedSelector, selectedKeySet); return null; } catch (NoSuchFieldException e) { return e; } catch (IllegalAccessException e) { return e; } } }); if (maybeException instanceof Exception) { selectedKeys = null; Exception e = (Exception) maybeException; logger.trace(&quot;failed to instrument a special java.util.Set into: {}&quot;, unwrappedSelector, e); return new SelectorTuple(unwrappedSelector); } selectedKeys = selectedKeySet; logger.trace(&quot;instrumented a special java.util.Set into: {}&quot;, unwrappedSelector); return new SelectorTuple(unwrappedSelector, new SelectedSelectionKeySetSelector(unwrappedSelector, selectedKeySet)); } 从代码中可以看出 NioEventLoop 内部对于 selector 进行了包装，通过反射对 EpollSelectorImpl 实例内字段 selectedKeys publicSelectedKeys 替换为 SelectedSelectionKeySet 实例；这样就保证了当选择器有就绪的通道时就会把 selectKey 添加到 selectedSelectionKeySet 中 我们在回到 processSelectedKeysOptimized 方法中，当集合中有就绪的 selectedKey 时，会获取绑定在该 key 上的附件 attachment 针对服务端来说 也就是 NioServerSocketChannel （注册的时候绑定的)；接下来会调用 processSelectedKey 如下： private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final NioUnsafe unsafe = ch.unsafe(); try { int readyOps = k.readyOps(); // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise // the NIO JDK channel implementation may throw a NotYetConnectedException. if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) { // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); } // Process OP_WRITE first as we may be able to write some queued buffers and so free memory. if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) { // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); } // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { unsafe.read(); } } catch (CancelledKeyException ignored) { unsafe.close(unsafe.voidPromise()); } } 因服务端监听的是 ACCEPT 事件，故当有客户端链接请求就绪的时候会调用 unsafe.read() ,此时 unsafe 实例为 NioMessageSafe: public void read() { assert eventLoop().inEventLoop(); final ChannelConfig config = config(); if (!config.isAutoRead() &amp;&amp; !isReadPending()) { // ChannelConfig.setAutoRead(false) was called in the meantime removeReadOp(); return; } final int maxMessagesPerRead = config.getMaxMessagesPerRead(); final ChannelPipeline pipeline = pipeline(); boolean closed = false; Throwable exception = null; try { try { for (;;) { int localRead = doReadMessages(readBuf); // 当没有客户端通道时退出 if (localRead == 0) { break; } if (localRead &lt; 0) { closed = true; break; } // stop reading and remove op if (!config.isAutoRead()) { break; } if (readBuf.size() &gt;= maxMessagesPerRead) { break; } } } catch (Throwable t) { exception = t; } setReadPending(false); int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) { // 触发 pipeline 的 channelRead 事件 pipeline.fireChannelRead(readBuf.get(i)); } readBuf.clear(); // 触发 pipeline 的 channelReadComplete 事件 pipeline.fireChannelReadComplete(); if (exception != null) { closed = closeOnReadError(exception); pipeline.fireExceptionCaught(exception); } if (closed) { if (isOpen()) { close(voidPromise()); } } } finally { } } protected int doReadMessages(List&lt;Object&gt; buf) throws Exception { // 获取客户端通道 SocketChannel ch = SocketUtils.accept(javaChannel()); try { if (ch != null) { // 将 nio socketChannel 封装为 NioSocketChannell 添加到 buf 集合中 buf.add(new NioSocketChannel(this, ch)); return 1; } } catch (Throwable t) { logger.warn(&quot;Failed to create a new channel from an accepted socket.&quot;, t); try { ch.close(); } catch (Throwable t2) { logger.warn(&quot;Failed to close a socket.&quot;, t2); } } return 0; } 其流程为： 获取客户端通道 socketChannel 并将其封装为 NioSocketChannel 添加到缓冲中 触发 pipeline 的 channelRead 事件 触发 pipeline 的 channelReadComplete 事件 最终会触发 ServerBootstrapAcceptor handler 的 channelRead 事件如下： public void channelRead(ChannelHandlerContext ctx, Object msg) { // msg 为 NioSocketChannel 实例 final Channel child = (Channel) msg; // 将 ServerBootstrap 设置的 childHandler 添加到 NioSocketChannel 的 pipeline 中 child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) { child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); } try { // childGroup 也就是我们所理解的 wrker group // 执行注册 nioSocketChannel 即将 NioSocektChannel 注册到 worker group 中的 NioEventLoop 的 selector childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); } } channelReadComplete 事件在执行过程中最终会调用 NioSocktChannel 的 doBegingRead 方法如下： protected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called if (inputShutdown) { return; } final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) { // NioSocetChannel 创建的时候 readInterestop 值为 O_READ selectionKey.interestOps(interestOps | readInterestOp); } } protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) { super(parent, ch, SelectionKey.OP_READ); } 至此将 SocketChannel 客户端通道注册到 worker group 中的 NioEventLoop 内的 selector 并监听 OP_READ 事件。 此时 netty 内部线程模型如下：","categories":[],"tags":[{"name":"netty","slug":"netty","permalink":"https://www.hxlzpnyist.site/tags/netty/"}],"keywords":[]},{"title":"Netty服务端启动源码分析","slug":"Netty服务端启动源码分析","date":"2018-01-17T08:28:57.000Z","updated":"2019-06-21T07:03:58.475Z","comments":true,"path":"2018/01/17/Netty服务端启动源码分析/","link":"","permalink":"https://www.hxlzpnyist.site/2018/01/17/Netty服务端启动源码分析/","excerpt":"Netty 是一个高性能异步事件驱动的 NIO 框架, 因其底层采用的 NIO, 故其启动过程一样可以分为以下几个步骤: selector 多路复用选择器开启 ServerSocketChannel 通道建立并绑定端口 ServerSocketChannel 通道注册到 selector 并监听 accept 事件 在进行服务端启动分析前，我们先看下 netty 的服务端使用示例。","text":"Netty 是一个高性能异步事件驱动的 NIO 框架, 因其底层采用的 NIO, 故其启动过程一样可以分为以下几个步骤: selector 多路复用选择器开启 ServerSocketChannel 通道建立并绑定端口 ServerSocketChannel 通道注册到 selector 并监听 accept 事件 在进行服务端启动分析前，我们先看下 netty 的服务端使用示例。 示例// Configure the server. EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc())); } p.addLast(new EchoServerHandler()); } }); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); } finally { // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } 从示例可以看出 netty 服务端通过创建 ServerBootstrap 实例，并对其配置 EventLoopGroup, channel, handler 之后即完成服务端的启动。 NioEventLoopGroup - selector的创建从示例中可以看出 ServerBootstrap 启动的过程中需要两个 EventLoopGroup 实例，从职责上可以将其分为两种 boss 和 worker;前者主要负责客户端链接的接收以及派发到 worker, 后者主要负责客户端链接的读写请求操作。 NioEventLoopGroup 的创建 public NioEventLoopGroup(int nThreads) { this(nThreads, null); } public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory) { this(nThreads, threadFactory, SelectorProvider.provider()); } public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, final SelectorProvider selectorProvider) { this(nThreads, threadFactory, selectorProvider, DefaultSelectStrategyFactory.INSTANCE); } public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, final SelectorProvider selectorProvider, final SelectStrategyFactory selectStrategyFactory) { super(nThreads, threadFactory, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject()); } static { DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt( &quot;io.netty.eventLoopThreads&quot;, NettyRuntime.availableProcessors() * 2)); if (logger.isDebugEnabled()) { logger.debug(&quot;-Dio.netty.eventLoopThreads: {}&quot;, DEFAULT_EVENT_LOOP_THREADS); } } protected MultithreadEventLoopGroup(int nThreads, ThreadFactory threadFactory, Object... args) { super(nThreads == 0? DEFAULT_EVENT_LOOP_THREADS : nThreads, threadFactory, args); } 加载 MultithreadEventLoopGroup 类时，会先计算默认线程数其值为处理器个数的两倍。 在看下父类MultithreadEventExecutorGroup的构造方法： protected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) { if (nThreads &lt;= 0) { throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); } if (threadFactory == null) { threadFactory = newDefaultThreadFactory(); } children = new SingleThreadEventExecutor[nThreads]; // 创建 事件执行器的选择器 if (isPowerOfTwo(children.length)) { chooser = new PowerOfTwoEventExecutorChooser(); } else { chooser = new GenericEventExecutorChooser(); } for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { // 创建 NioEventLoop children[i] = newChild(threadFactory, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { } } // 非核心代码省略 } newChild 是抽象方法由子类 NioEventLoopGroup 实现 protected EventExecutor newChild(ThreadFactory threadFactory, Object... args) throws Exception { return new NioEventLoop(this, threadFactory, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); } 从上述代码中可以看出 NioEventLoopGroup 构建过程中会按指定的线程数创建 NioEventLoop 实例并存储在 children 事件执行器数组中；同时创建了 chooser 实例，chooser 用于在新的客户端链接请求到达的时候从 children 数组中选取 eventLoop 的策略。 NioEventLoop的创建先看下 NioEventLoop 的构造 NioEventLoop(NioEventLoopGroup parent, ThreadFactory threadFactory, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) { super(parent, threadFactory, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) { throw new NullPointerException(&quot;selectorProvider&quot;); } if (strategy == null) { throw new NullPointerException(&quot;selectStrategy&quot;); } provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); // 创建 selector 选择器 selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy; } 其父类构造如下： protected SingleThreadEventExecutor( EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.parent = parent; this.addTaskWakesUp = addTaskWakesUp; // 内部线程 thread = threadFactory.newThread(new Runnable() { @Override public void run() { // 此处省略线程的具体执行 } }); threadProperties = new DefaultThreadProperties(thread); this.maxPendingTasks = Math.max(16, maxPendingTasks); // 任务队列 taskQueue = newTaskQueue(); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;); } protected Queue&lt;Runnable&gt; newTaskQueue() { return newTaskQueue(maxPendingTasks); } protected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) { return new LinkedBlockingQueue&lt;Runnable&gt;(maxPendingTasks); } 从 NioEventLoop 的构造方法可以看出, 其内部包含了一个 thread 以及 taskQueue 并且绑定了一个 selector; taskQueue 用于存储内部执行的任务, thread 该线程主要用来执行 taskQueue 中的任务及处理客户端链接的请求。 此时完成了 selector 选择器的创建,并将其绑定到 NioEventLoop 实例 在完成了两个 NioEventLoopGroup 实例的创建之后 我们可以看出 Netty 内部线程模型大概如下： NioServerSocketChannel 通道创建ServerBootstrap 在完成 group, channel, handler 的配置之后调用 bind 完成服务端启动，让我们看下其实现: public ChannelFuture bind(int inetPort) { return bind(new InetSocketAddress(inetPort)); } public ChannelFuture bind(String inetHost, int inetPort) { return bind(SocketUtils.socketAddress(inetHost, inetPort)); } public ChannelFuture bind(InetAddress inetHost, int inetPort) { return bind(new InetSocketAddress(inetHost, inetPort)); } public ChannelFuture bind(SocketAddress localAddress) { validate(); if (localAddress == null) { throw new NullPointerException(&quot;localAddress&quot;); } return doBind(localAddress); } private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } // 暂时省略 } 从上述代码中可以在 bind 过程中，先完成 channel 的注册及初始化其实现在 initAndRegister 方法中如下： final ChannelFuture initAndRegister() { Channel channel = null; try { // 创建 NioServerSocketChannel channel = channelFactory().newChannel(); // 初始化 channel init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // channel 注册 ChannelFuture regFuture = group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } return regFuture; } 从 initAndRegister 方法中可以看出，该方法主要完成以下三件事: NioServerSocketChannel 实例的创建 NioServerSocketChannel 的初始化 NioServerSocketChannel 的注册 NioServerSocketChannel的创建先让我们回过头看下 ServerBootstrap 启动时配置 channel 方法： public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } return channelFactory(new BootstrapChannelFactory&lt;C&gt;(channelClass)); } public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) { if (channelFactory == null) { throw new NullPointerException(&quot;channelFactory&quot;); } if (this.channelFactory != null) { throw new IllegalStateException(&quot;channelFactory set already&quot;); } this.channelFactory = channelFactory; return self(); } 也就是说此时 channelFactory 实例为 BootstrapChannelFactory, 接下来我们看下其实现： private static final class BootstrapChannelFactory&lt;T extends Channel&gt; implements ChannelFactory&lt;T&gt; { private final Class&lt;? extends T&gt; clazz; BootstrapChannelFactory(Class&lt;? extends T&gt; clazz) { this.clazz = clazz; } @Override public T newChannel() { try { return clazz.getConstructor().newInstance(); } catch (Throwable t) { throw new ChannelException(&quot;Unable to create Channel from class &quot; + clazz, t); } } } 故 channelFactory.newChannel() 方法也就是创建指定了 channel class 的实例也就是 NioServerSocketChannel 实例，接下来看下其构造实现： private static ServerSocketChannel newSocket(SelectorProvider provider) { try { return provider.openServerSocketChannel(); } catch (IOException e) { throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); } } private final ServerSocketChannelConfig config; public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); } public NioServerSocketChannel(SelectorProvider provider) { this(newSocket(provider)); } public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); } 其父类 AbstractNioChannel AbstractChannel 构造方法如下： protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { } } protected AbstractChannel(Channel parent) { this.parent = parent; unsafe = newUnsafe(); pipeline = newChannelPipeline(); } 从 NioServerSocketChannel 的构造方法看出其主要流程如下: 通过 newSocket 方法创建了 ServerSocketChannel 实例并设置为非阻塞模式 设置了待监听事件 OP_ACCEPT 创建 unsafe 实例为 NioMessageUnsafe 创建 pipeline 实例为 DefaultChannelPipeline 此时完成了 nio 中的 ServerSocketChannel 的创建 NioServerSocktChannel的初始化init 为抽象方法由子类实现 void init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(childOptions.size())); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(childAttrs.size())); } p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = handler(); if (handler != null) { pipeline.addLast(handler); } logger.info(&quot;ServerBootStrap init channel addLast ChannelInitializer init channel&quot;); ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); } init 主要设置 channel 的 attr 和 options;并在 pipeline 中添加 ChannelInitializer handler NioServerSocketChannel的注册在完成 channel 的创建及初始化之后即调用 NioEventLoopGroup.register(channel) 方法完成 channel 的注册。 @Override public EventLoop next() { return (EventLoop) super.next(); } @Override public ChannelFuture register(Channel channel) { return next().register(channel); } next() 方法是按照 chooser 选取策略从 NioEventLoopGroup 中获取一个 NioEventLoop 实例;跟踪 register 方法最终调用的是 unsafe.register 方法如下: public final void register(EventLoop eventLoop, final ChannelPromise promise) { // ...... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { register0(promise); } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { } } } private void register0(ChannelPromise promise) { try { // ...... boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // ...... } catch (Throwable t) { } } 调用了由子类实现的 doRegister() 方法如下： @Override protected void doRegister() throws Exception { boolean selected = false; for (;;) { try { // ServerSocketChannel 注册到 selector selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } } } 其实现就是将 ServerSocketChannel 注册到 selector 上，并以自身NioServerSocketChannel 作为附件； 注意：此时注册的时候 监听的事件 并不是 ACCEPT; 而是 0 NioServerSocketChannel 端口绑定上文中在完成了 channel 的注册之后，我们在回头看 doBind 的实现: private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { promise.setFailure(cause); } else { promise.executor = channel.eventLoop(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } } 在 channel 注册完成后会执行 doBind0 private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); } 会调用 channel.bind() 跟踪发现最终会调用 unsafe.bind() 方法如下： public final void bind(final SocketAddress localAddress, final ChannelPromise promise) { assertEventLoop(); // ...... boolean wasActive = isActive(); try { // 绑定地址端口 doBind(localAddress); } catch (Throwable t) { safeSetFailure(promise, t); closeIfClosed(); return; } if (!wasActive &amp;&amp; isActive()) { // 绑定端口成功之后 触发 pipeline handler 的 channel active 事件 invokeLater(new Runnable() { @Override public void run() { pipeline.fireChannelActive(); } }); } safeSetSuccess(promise); } protected void doBind(SocketAddress localAddress) throws Exception { if (PlatformDependent.javaVersion() &gt;= 7) { javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); } } 此时完成了 ServerSocketChannel 的服务端地址绑定 NioServerSocketChannel 注册 ACCEPT 事件上文中在完成 bind 操作之后，会触发 channelPipeline 的 channel active 事件 最终调用了 channel 的 doBeginRead 方法 protected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called if (inputShutdown) { return; } final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) { // 将 selectionKey 添加 ACCEPT 事件的监听 selectionKey.interestOps(interestOps | readInterestOp); } } 至此完成了 ServerSocketChannel 注册到 selector 并让其监听 ACCEPT 事件；服务端也启动完毕。 小结对Netty的服务端启动分析完之后，大概认识了其包含的一些组件以及各组件的作用 ServerBootstrap ：该类是服务端启动的引导类，其主要用于配置 Netty 的各个组件 NioEventLoopGroup : 该类用于管理 NioEventLoop , 并提供了 Selector 选择器创建的入口并将其绑定到 NioEventLoop 实例 NioEventLoop : 该类内部绑定了一个线程以及一个任务队列用于处理 register bind的相关任务及客户端处理（后续会详细分析） NioServerSocketChannel : 该类是对 ServerSocketChannel 的一个包装其内部包含了 unsafe channelPipeline 实例 Unsafe : 该类提供了底层的 register bind write read 等操作 DefaultChannelPipeline : 该类是个双向链表结构，其主要作用是在通道注册链接 读写的操作之后会触发相应的事件","categories":[],"tags":[{"name":"netty","slug":"netty","permalink":"https://www.hxlzpnyist.site/tags/netty/"}],"keywords":[]},{"title":"zookeeper源码阅读之watch","slug":"zookeeper源码阅读之watch","date":"2017-12-22T07:01:41.000Z","updated":"2019-06-21T06:49:05.454Z","comments":true,"path":"2017/12/22/zookeeper源码阅读之watch/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/22/zookeeper源码阅读之watch/","excerpt":"watcher 流程概述watcher 用来客户端监听某一节点的特性变化，执行对应的操作. 从下图可以看出 watcher 的流程主要包括: watcher 注册, 包括客户端注册, 服务端的注册 watcher 触发 watcher 执行","text":"watcher 流程概述watcher 用来客户端监听某一节点的特性变化，执行对应的操作. 从下图可以看出 watcher 的流程主要包括: watcher 注册, 包括客户端注册, 服务端的注册 watcher 触发 watcher 执行 watcher 注册本文我们以 zookeeper.getData 操作为例，对 watcher 的注册流程就行说明。 watcher 客户端注册getData api 如下: public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException { final String clientPath = path; PathUtils.validatePath(clientPath); // the watch contains the un-chroot path WatchRegistration wcb = null; if (watcher != null) { // 定义 watcher 注册 wcb = new DataWatchRegistration(watcher, clientPath); } final String serverPath = prependChroot(clientPath); RequestHeader h = new RequestHeader(); h.setType(ZooDefs.OpCode.getData); GetDataRequest request = new GetDataRequest(); request.setPath(serverPath); // watcher 不为空的时候 设置为 true request.setWatch(watcher != null); GetDataResponse response = new GetDataResponse(); ReplyHeader r = cnxn.submitRequest(h, request, response, wcb); if (r.getErr() != 0) { throw KeeperException.create(KeeperException.Code.get(r.getErr()), clientPath); } if (stat != null) { DataTree.copyStat(response.getStat(), stat); } return response.getData(); } 在完成本次请求，处理返回 packet 的时候, 会调用 ClinetCnxn.finishPacket(packet) 方法 private void finishPacket(Packet p) { int err = p.replyHeader.getErr(); if (p.watchRegistration != null) { // 调用 wwatcher register; 处理正常的时候 err 值为 0; 可参考类 FinalRequestProcessor p.watchRegistration.register(err); } // 省略 } 以下为 watchRegistration.register 源码: public void register(int rc) { if (shouldAddWatch(rc)) { // client 下允许对多个路径设置监听 Map&lt;String, Set&lt;Watcher&gt;&gt; watches = getWatches(rc); synchronized(watches) { Set&lt;Watcher&gt; watchers = watches.get(clientPath); if (watchers == null) { // 同一路径下允许有多个 watcher watchers = new HashSet&lt;Watcher&gt;(); watches.put(clientPath, watchers); } watchers.add(watcher); } } } protected boolean shouldAddWatch(int rc) { return rc == 0; } protected Map&lt;String, Set&lt;Watcher&gt;&gt; getWatches(int rc) { return watchManager.dataWatches; } 从以上代码中可以看出, 客户端在定义 watcher 之后会将其与 path 绑定添加到 ZKWatchManager.dataWatches; 从而完成 watcher 的注册。 watcher 服务端注册server 在接收到客户端请求执行 FinalRequestProcessor.processRequest 方法过程中，会执行对 watcher 的注册，这里同样以 getData 操作的代码进行分析: case OpCode.getData: { lastOp = &quot;GETD&quot;; GetDataRequest getDataRequest = new GetDataRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, getDataRequest); DataNode n = zks.getZKDatabase().getNode(getDataRequest.getPath()); if (n == null) { throw new KeeperException.NoNodeException(); } PrepRequestProcessor.checkACL(zks, zks.getZKDatabase().aclForNode(n), ZooDefs.Perms.READ, request.authInfo); Stat stat = new Stat(); // 若 client 请求的时候 watch 为 true, 则将 cnxn 作为参数 // cnxn 为每个客户端请求链接的时候 针对 selectorKey 绑定的 NIOServerCnxn 实例 byte b[] = zks.getZKDatabase().getData(getDataRequest.getPath(), stat, getDataRequest.getWatch() ? cnxn : null); rsp = new GetDataResponse(b, stat); break; } 从上面代码中 zks.getZKDatabase().getData(getDataRequest.getPath(), stat, getDataRequest.getWatch() ? cnxn : null); 跟踪发现其最后调用了 WatchManager.addWatch(path, watcher) 方法. // 注意 : 此时传递的参数 watcher 并不是客户端定义的 watcher 实例，而是服务端存储的与客户端绑定的 // NIOServerCnxn 实例；因为 NIOServerCnxn 实现了 watcher 接口; // watchTable 用来存储 path 与 watcher 的关系; 也可以表示为 多个客户端监听了同一节点 // watch2Paths 用来存储 watcher 与 path 的关系; 也可以表示为 每个客户端下监听了哪些节点 synchronized void addWatch(String path, Watcher watcher) { HashSet&lt;Watcher&gt; list = watchTable.get(path); if (list == null) { // don&#39;t waste memory if there are few watches on a node // rehash when the 4th entry is added, doubling size thereafter // seems like a good compromise list = new HashSet&lt;Watcher&gt;(4); watchTable.put(path, list); } list.add(watcher); HashSet&lt;String&gt; paths = watch2Paths.get(watcher); if (paths == null) { // cnxns typically have many watches, so use default cap here paths = new HashSet&lt;String&gt;(); watch2Paths.put(watcher, paths); } paths.add(path); } 从上面代码中可以看出,服务端在处理完客户端请求的时候 若客户端设置了 watcher 则会将其添加到 watchmanager 的 watchTable 中；至此服务端针对 watcher 的注册完毕. watcher 触发针对 watcher 触发的操作，这里以 setData api 为例说明。此时假设某个客户端执行了 setData 操作, 服务端在处理客户端请求的时候, 在调用 FinalRequestProcessor.processRequest 方法的时候会调用 zookeeperServer.processTxn(request); 最终会调用 DataTree.processTxn() 方法，此处摘取针对 setData 的操作如下 ： case OpCode.setData: SetDataTxn setDataTxn = (SetDataTxn) txn; rc.path = setDataTxn.getPath(); rc.stat = setData(setDataTxn.getPath(), setDataTxn .getData(), setDataTxn.getVersion(), header .getZxid(), header.getTime()); break; public Stat setData(String path, byte data[], int version, long zxid, long time) throws KeeperException.NoNodeException { Stat s = new Stat(); DataNode n = nodes.get(path); if (n == null) { throw new KeeperException.NoNodeException(); } byte lastdata[] = null; synchronized (n) { lastdata = n.data; n.data = data; n.stat.setMtime(time); n.stat.setMzxid(zxid); n.stat.setVersion(version); n.copyStat(s); } // now update if the path is in a quota subtree. String lastPrefix = getMaxPrefixWithQuota(path); if(lastPrefix != null) { // 更新节点数据 this.updateBytes(lastPrefix, (data == null ? 0 : data.length) - (lastdata == null ? 0 : lastdata.length)); } // 触发该节点下的 watcher dataWatches.triggerWatch(path, EventType.NodeDataChanged); return s; } 从上述代码中可以看出, 服务端在完成对节点数据更新之后调用了 watcher.triggerWatch(); 该方法接收两个参数一个为节点path, 一个为事件类型 Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) { WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); HashSet&lt;Watcher&gt; watchers; synchronized (this) { watchers = watchTable.remove(path); if (watchers == null || watchers.isEmpty()) { if (LOG.isTraceEnabled()) { ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, &quot;No watchers for &quot; + path); } return null; } for (Watcher w : watchers) { HashSet&lt;String&gt; paths = watch2Paths.get(w); if (paths != null) { paths.remove(path); } } } for (Watcher w : watchers) { if (supress != null &amp;&amp; supress.contains(w)) { continue; } w.process(e); } return watchers; } 从以上代码中看出在触发 watcher 的时候，会先从 watchManager 中的 watchTable 获取指定 path 的 watcher 并将其从集合中移除（从此处我们可以看出客户端定义的 watcher 若未作处理的话 将只会监听一次）。在查找到 watcher 之后将会调用 watcher.process 即执行 watcher. watcher 执行在服务端触发 watcher 之后，会调用 watcher.process 方法，此时 watcher 的实例为 NIOServerCnxn;接下来我们看下 NIOSserverCnxn 的 process 方法: public void process(WatchedEvent event) { ReplyHeader h = new ReplyHeader(-1, -1L, 0); if (LOG.isTraceEnabled()) { ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, &quot;Deliver event &quot; + event + &quot; to 0x&quot; + Long.toHexString(this.sessionId) + &quot; through &quot; + this); } // Convert WatchedEvent to a type that can be sent over the wire WatcherEvent e = event.getWrapper(); sendResponse(h, e, &quot;notification&quot;); } 从上面代码中可以看出服务端向客户端发出了 tag 为 “notification” 的响应； 接下来我们看下客户端如何处理该响应:在 ClientCnxn 下的 SendThread.readResponse 方法中我们可以看到针对 watcher 的处理如下： if (replyHdr.getXid() == -1) { // -1 means notification if (LOG.isDebugEnabled()) { LOG.debug(&quot;Got notification sessionid:0x&quot; + Long.toHexString(sessionId)); } // 从 response 中反序列化 WatcherEvent event = new WatcherEvent(); event.deserialize(bbia, &quot;response&quot;); // convert from a server path to a client path if (chrootPath != null) { String serverPath = event.getPath(); if(serverPath.compareTo(chrootPath)==0) event.setPath(&quot;/&quot;); else if (serverPath.length() &gt; chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); else { LOG.warn(&quot;Got server path &quot; + event.getPath() + &quot; which is too short for chroot path &quot; + chrootPath); } } WatchedEvent we = new WatchedEvent(event); if (LOG.isDebugEnabled()) { LOG.debug(&quot;Got &quot; + we + &quot; for sessionid 0x&quot; + Long.toHexString(sessionId)); } // 将 watchedEvent 交由 eventThread 处理 eventThread.queueEvent( we ); return; } private void queueEvent(WatchedEvent event, Set&lt;Watcher&gt; materializedWatchers) { if (event.getType() == EventType.None &amp;&amp; sessionState == event.getState()) { return; } sessionState = event.getState(); final Set&lt;Watcher&gt; watchers; if (materializedWatchers == null) { // materialize the watchers based on the event // 从 ZKWatchManager 中获取 path 的 watcher watchers = watcher.materialize(event.getState(), event.getType(), event.getPath()); } else { watchers = new HashSet&lt;Watcher&gt;(); watchers.addAll(materializedWatchers); } WatcherSetEventPair pair = new WatcherSetEventPair(watchers, event); // queue the pair (watch set &amp; event) for later processing waitingEvents.add(pair); } 从上面代码看出 客户端在处理 watcher 通知的时候会将其封装为 WatcherSetEventPair 对象并添加到 waitingEvents 队列中此时会唤醒阻塞在队列的操作，也即 eventThread 的 run 方法，如下： public void run() { try { isRunning = true; while (true) { Object event = waitingEvents.take(); if (event == eventOfDeath) { wasKilled = true; } else { processEvent(event); } if (wasKilled) synchronized (waitingEvents) { if (waitingEvents.isEmpty()) { isRunning = false; break; } } } } catch (InterruptedException e) { LOG.error(&quot;Event thread exiting due to interruption&quot;, e); } LOG.info(&quot;EventThread shut down for session: 0x{}&quot;, Long.toHexString(getSessionId())); } 截取 processEvent 方法中针对 watcher 的处理 f (event instanceof WatcherSetEventPair) { // each watcher will process the event WatcherSetEventPair pair = (WatcherSetEventPair) event; for (Watcher watcher : pair.watchers) { try { // 执行 watcher watcher.process(pair.event); } catch (Throwable t) { LOG.error(&quot;Error while calling watcher &quot;, t); } } } 从上面代码看出当 waitingEvents 队列中存在待处理的 watcher 时将会依次调用；至此完成 watcher的执行；到此完成对 zookeeper watcher 的分析.","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.hxlzpnyist.site/tags/zookeeper/"}],"keywords":[]},{"title":"NIO selector的wakeup","slug":"NIO-selector的wakeup","date":"2017-12-21T06:48:17.000Z","updated":"2017-12-21T07:37:20.000Z","comments":true,"path":"2017/12/21/NIO-selector的wakeup/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/21/NIO-selector的wakeup/","excerpt":"wakeUp 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 引用至 http://ifeve.com/selectors/","text":"wakeUp 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 引用至 http://ifeve.com/selectors/ 测试public class App { private Selector selector; public void start () throws IOException { // 开启选择器 selector selector = Selector.open(); // 开启服务端 socket 通道 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 设置为非阻塞 serverSocketChannel.configureBlocking(false); // 绑定服务端端口 serverSocketChannel.socket().bind(new InetSocketAddress(8888)); // 通道注册到选择器上 并监听 接收客户端事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); // 因 selector.select 会阻塞当前线程 故异步处理 new Thread(new Runnable() { @Override public void run() { while (true) { System.out.println(&quot;select 前执行&quot;); try { selector.select(); } catch (IOException e) { e.printStackTrace(); } System.out.println(&quot;select 后执行&quot;); } } }).start(); } public void wakeup () { System.out.println(&quot;开始唤醒&quot;); selector.wakeup(); } public static void main( String[] args ) throws IOException, InterruptedException { final App app = new App(); app.start(); Thread thread = new Thread(new Runnable() { @Override public void run() { while (true) { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } app.wakeup(); } } }); thread.start(); thread.join(); } } select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 从执行结果可以看出 在调用了 wakeup() 方法之后，即可唤醒阻塞在 select() 上的操作 也即 select() 方法会立马返回.","categories":[],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://www.hxlzpnyist.site/tags/NIO/"}],"keywords":[]},{"title":"zookeeper源码阅读之client","slug":"zookeeper源码阅读之client","date":"2017-12-15T05:46:58.000Z","updated":"2019-06-21T06:48:58.822Z","comments":true,"path":"2017/12/15/zookeeper源码阅读之client/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/15/zookeeper源码阅读之client/","excerpt":"zookeeper client 启动流程 先看下 zookeeper client 相关类图 执行 zkCli.sh 脚本时, 会运行 org.apache.zookeeper.ZookeeperMain 类主方法.public static void main(String args[]) throws KeeperException, IOException, InterruptedException { ZooKeeperMain main = new ZooKeeperMain(args); main.run(); } public ZooKeeperMain(String args[]) throws IOException, InterruptedException { // 启动参数解析 cl.parseOptions(args); System.out.println(&quot;Connecting to &quot; + cl.getOption(&quot;server&quot;)); // 链接 zookeeper server connectToZK(cl.getOption(&quot;server&quot;)); } 从代码中可以看出 client 启动时首先构造 ZookeeperMain 对象实例,构造过程中会先解析 client 的启动参数（若未指定任何参数将会默认链接本机 2181 端口 zookeeper server）","text":"zookeeper client 启动流程 先看下 zookeeper client 相关类图 执行 zkCli.sh 脚本时, 会运行 org.apache.zookeeper.ZookeeperMain 类主方法.public static void main(String args[]) throws KeeperException, IOException, InterruptedException { ZooKeeperMain main = new ZooKeeperMain(args); main.run(); } public ZooKeeperMain(String args[]) throws IOException, InterruptedException { // 启动参数解析 cl.parseOptions(args); System.out.println(&quot;Connecting to &quot; + cl.getOption(&quot;server&quot;)); // 链接 zookeeper server connectToZK(cl.getOption(&quot;server&quot;)); } 从代码中可以看出 client 启动时首先构造 ZookeeperMain 对象实例,构造过程中会先解析 client 的启动参数（若未指定任何参数将会默认链接本机 2181 端口 zookeeper server） 通过调用 connectToZK 链接 zookeeper serverprotected void connectToZK(String newHost) throws InterruptedException, IOException { if (zk != null &amp;&amp; zk.getState().isAlive()) { // 若已创建 zookeeper 对象并且状态为激活 则关闭重新创建 zk.close(); } host = newHost; boolean readOnly = cl.getOption(&quot;readonly&quot;) != null; if (cl.getOption(&quot;secure&quot;) != null) { System.setProperty(ZKClientConfig.SECURE_CLIENT, &quot;true&quot;); System.out.println(&quot;Secure connection is enabled&quot;); } // 构造 Zookeeper 对象实例 zk = new ZooKeeper(host,Integer.parseInt(cl.getOption(&quot;timeout&quot;)), new MyWatcher(), readOnly); } 创建 Zookeeper 对象实例// connectString 是形如 host:port,host:port 的字符串片段 public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly, HostProvider aHostProvider, ZKClientConfig clientConfig) throws IOException { if (clientConfig == null) { // 创建 ZKClient Config 对象 clientConfig = new ZKClientConfig(); } this.clientConfig = clientConfig; watchManager = defaultWatchManager(); watchManager.defaultWatcher = watcher; ConnectStringParser connectStringParser = new ConnectStringParser( connectString); hostProvider = aHostProvider; // 创建 ClientCnxn 对象 cnxn = new ClientCnxn(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), canBeReadOnly); cnxn.start(); } // 创建 ClientCnxnSocket对象 默认为 ClientCnxnSocketNIO 对象 private ClientCnxnSocket getClientCnxnSocket() throws IOException { String clientCnxnSocketName = getClientConfig().getProperty( ZKClientConfig.ZOOKEEPER_CLIENT_CNXN_SOCKET); if (clientCnxnSocketName == null) { clientCnxnSocketName = ClientCnxnSocketNIO.class.getName(); } try { Constructor&lt;?&gt; clientCxnConstructor = Class.forName(clientCnxnSocketName).getDeclaredConstructor(ZKClientConfig.class); ClientCnxnSocket clientCxnSocket = (ClientCnxnSocket) clientCxnConstructor.newInstance(getClientConfig()); return clientCxnSocket; } catch (Exception e) { IOException ioe = new IOException(&quot;Couldn&#39;t instantiate &quot; + clientCnxnSocketName); ioe.initCause(e); throw ioe; } } 从代码中看出 Zookeeper 关联了 ClientCnxn 对象, 在创建了 ClientCnxn 对象实例之后调用了 cnxn.start() 方法。 创建 ClientCnxn 对象实例public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) { this.zooKeeper = zooKeeper; this.watcher = watcher; this.sessionId = sessionId; this.sessionPasswd = sessionPasswd; this.sessionTimeout = sessionTimeout; this.hostProvider = hostProvider; this.chrootPath = chrootPath; // 计算连接超时时间 读数据超时时间 connectTimeout = sessionTimeout / hostProvider.size(); readTimeout = sessionTimeout * 2 / 3; readOnly = canBeReadOnly; // 创建了 SendThread EventThread 线程实例 sendThread = new SendThread(clientCnxnSocket); eventThread = new EventThread(); this.clientConfig=zooKeeper.getClientConfig(); } public void start() { sendThread.start(); eventThread.start(); } 从 start 方法中可以看出分别启动了 sendThread eventThread 两个线程。 SendThread 线程的构造及启动SendThread(ClientCnxnSocket clientCnxnSocket) { super(makeThreadName(&quot;-SendThread()&quot;)); state = States.CONNECTING; this.clientCnxnSocket = clientCnxnSocket; setDaemon(true); } SendThread 是 ClientCnxn 的内部类, 创建该线程实例时会将 ClientCnxn 的状态由默认状态(未连接)改为连接中,并赋值 clientCnxnSocket。 ClientCnxn 的主要成员变量说明 在了解 sendThread 线程的启动过程有必要先了解一下关于 SendThread 和 ClientCnxn 的相关成员变量。 变量名 描述 state 客户端连接状态 outgoingQueue 存储需要被发送出去的报文的队列 pendingQueue 存储已经发送等待响应结果的队列 SendThread 线程启动public void run() { // 将 sendThread sessionId outgoingQueue 绑定到的 clientCnxnSocketNIO clientCnxnSocket.introduce(this, sessionId, outgoingQueue); clientCnxnSocket.updateNow(); clientCnxnSocket.updateLastSendAndHeard(); int to; long lastPingRwServer = Time.currentElapsedTime(); final int MAX_SEND_PING_INTERVAL = 10000; //10 seconds while (state.isAlive()) { try { if (!clientCnxnSocket.isConnected()) { // don&#39;t re-establish connection if we are closing if (closing) { break; } // 如果 clientCnxnSocketNIO 未连接 则开始连接 startConnect(); clientCnxnSocket.updateLastSendAndHeard(); } if (state.isConnected()) { // determine whether we need to send an AuthFailed event. if (zooKeeperSaslClient != null) { // ssl client 的处理此处省略 } to = readTimeout - clientCnxnSocket.getIdleRecv(); } else { to = connectTimeout - clientCnxnSocket.getIdleRecv(); } if (to &lt;= 0) { String warnInfo; warnInfo = &quot;Client session timed out, have not heard from server in &quot; + clientCnxnSocket.getIdleRecv() + &quot;ms&quot; + &quot; for sessionid 0x&quot; + Long.toHexString(sessionId); LOG.warn(warnInfo); throw new SessionTimeoutException(warnInfo); } if (state.isConnected()) { //1000(1 second) is to prevent race condition missing to send the second ping //also make sure not to send too many pings when readTimeout is small int timeToNextPing = readTimeout / 2 - clientCnxnSocket.getIdleSend() - ((clientCnxnSocket.getIdleSend() &gt; 1000) ? 1000 : 0); //send a ping request either time is due or no packet sent out within MAX_SEND_PING_INTERVAL if (timeToNextPing &lt;= 0 || clientCnxnSocket.getIdleSend() &gt; MAX_SEND_PING_INTERVAL) { // 发送心跳 sendPing(); clientCnxnSocket.updateLastSend(); } else { if (timeToNextPing &lt; to) { to = timeToNextPing; } } } // If we are in read-only mode, seek for read/write server if (state == States.CONNECTEDREADONLY) { long now = Time.currentElapsedTime(); int idlePingRwServer = (int) (now - lastPingRwServer); if (idlePingRwServer &gt;= pingRwTimeout) { lastPingRwServer = now; idlePingRwServer = 0; pingRwTimeout = Math.min(2*pingRwTimeout, maxPingRwTimeout); pingRwServer(); } to = Math.min(to, pingRwTimeout - idlePingRwServer); } clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this); } catch (Throwable e) { // 异常处理的部分省略... } } synchronized (state) { // When it comes to this point, it guarantees that later queued // packet to outgoingQueue will be notified of death. cleanup(); } clientCnxnSocket.close(); if (state.isAlive()) { eventThread.queueEvent(new WatchedEvent(Event.EventType.None, Event.KeeperState.Disconnected, null)); } ZooTrace.logTraceMessage(LOG, ZooTrace.getTextTraceLevel(), &quot;SendThread exited loop for session: 0x&quot; + Long.toHexString(getSessionId())); } 从代码中可以看出 sendThread 主要做以下事情 创建客户端连接 发送心跳 发送消息 (终端输入的指令) 下面将针对上面三种流程分析 客户端连接创建流程 先大概看下此流程活动图 如下: sendThread 轮询过程中 先判断 clientCnxnSocket 是否已连接；若未连接则调用 sendThread.startConnect() 将 ClientCnxn.state 的状态改为 “连接中”, 接下来同步调用 clientCnxnSocket.connect 完成客户端 socket 的创建及注册到 selector 并监听连接事件 上述操作完成后会调用 clientCnxnSocket.doTransport (), 该方法主要处理 selector 选择器上就绪的通道事件. 当客户端 socket 连接就绪的时候会调用 sendThread.primeConnection() 准备连接方法，该方法 ConnectionRequet 的 Packet 并将其添加到 outgoingQueue 对列中，接下来调用 clientCnxnSocket.connectionPrimed 该方法主要告知 socket 准备好连接了 此时客户端在 selector 上注册读写事件 (此时会触发通道的写就绪事件) 当客户端 socket 写就绪的时候会调用 clientCnxnSocket.findSendablePacket 该方法从 outgoingQueue 队列中获取待发送的 Packet , 最后执行 socket.write() 发送消息(此时会触发通道的读就绪事件) 当客户端 socket 读就绪的时候判断 initialized 是否为 true，若为 false 说明执行连接初始化会调用 sendThread.onConnected 更改客户端状态为 “已连接”， 继续注册监听客户端的读写事件 客户端心跳流程 心跳流程如下： sendThread 轮询过程中 判断 state 是否为 “已连接”; 若已连接判断是否满足心跳条件, 调用 sendPing 创建心跳 packet header xid = -2; 接下来将 packet 添加到 outgoingQueue 队列中并调用 clientCnxnSocket.packetAddedd 最后唤醒阻塞在 selector.select 上的操作 当客户端 socket 写就绪的时候调用 findSendablePacket 获取待发送的 packet 最后调用 socket.write 执行发送 当客户端 socket 读就绪的时候调用 sendThread.readResponse 解析服务端的响应结果, 通过获取 response heaher xid 判断 xid == -2 ; 若为 -2 则打印心跳返回日志返回， 此时一次心跳结束 客户端终端发送指令流程 发送指令流程图如下: ZookeeperMain 构建完成后会调用 run 方法，等待用户输入 输入指令后会相应调用 executeLine, processCmd, processZKCmd 通过解析参数获取相应的 CliCommand 此处采用了命令模式 内置了各种 CliCommand 对应客户端相应的操作，包括(CreateCommand, GetCommand, SetCommand ….）; 获取对应的命令后，调用 parse, exec 方法执行命令 执行命令会调用 zookeeper 对应的操作(create, getData, setData)，在内部会调用 ClientCnxn.submitRequest 方法 在 clientCnxn.submitRequest 方法中会调用 queuePacket 创建 packet 并将其添加到队列中，接着唤醒 clientCnxnSocketNIO 的 selector.select 操作；后续操作就是读写就绪事件的处理与心跳流程类似。 至此 zookeeper client 的相关流程介绍完毕 细节的地方后续在处理.","categories":[],"tags":[],"keywords":[]},{"title":"NIO之粘包拆包处理","slug":"NIO之粘包拆包处理","date":"2017-12-14T06:48:19.000Z","updated":"2018-05-30T06:37:41.000Z","comments":true,"path":"2017/12/14/NIO之粘包拆包处理/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/14/NIO之粘包拆包处理/","excerpt":"概述 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。 粘包拆包的原因 关于 tcp 传输过程中，发生粘包拆包的原因及表现形式可参考网上的一篇博客; 这里就不在说明. 粘包拆包的解决方法 本文给出针对自定义消息报文格式，通过在消息头部添加消息载体长度来处理","text":"概述 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。 粘包拆包的原因 关于 tcp 传输过程中，发生粘包拆包的原因及表现形式可参考网上的一篇博客; 这里就不在说明. 粘包拆包的解决方法 本文给出针对自定义消息报文格式，通过在消息头部添加消息载体长度来处理 实现方式消息内容包装public class PacketWrapper { // 消息有效长度 private int length; // 消息的有效载体 private byte[] payload; public PacketWrapper(String payload) { this.payload = payload.getBytes(); this.length = this.payload.length; } public PacketWrapper(byte[] payload) { this.payload = payload; this.length = this.payload.length; } // 返回包装后的字节数组 public byte[] getBytes() { ByteBuffer byteBuffer = ByteBuffer.allocate(this.length + 4); byteBuffer.putInt(this.length); byteBuffer.put(payload); return byteBuffer.array(); } public String toString() { StringBuilder sb = new StringBuilder(); for (byte b : getBytes()) { sb.append(String.format(&quot;0x%02X &quot;, b)); } return sb.toString(); } } 消息报文的解码 public class NioDecodeHandler { private static Logger log = Logger.getLogger(NioDecodeHandler.class); private final int HEAD_LENGTH = 4; protected ByteBuffer lastReadBuffer = null; public void decode (SocketChannel socketChannel) { // 从通道中读取内容 ByteBuffer readByteBuffer = ByteBuffer.allocate(128); try { int read = socketChannel.read(readByteBuffer); if (read &lt; 0) { throw new RuntimeException(&quot;&quot;); } } catch (IOException e) { } ByteBuffer newByteBuffer = readByteBuffer; if (newByteBuffer == null) { return; } // 切换到读模式 newByteBuffer.flip(); if (lastReadBuffer != null) { // 将上次遗留的数据与本次已读的数据合并 newByteBuffer = ByteBufferUtil.composite(lastReadBuffer, newByteBuffer); } decode : while (true) { if (newByteBuffer.remaining() &lt;= HEAD_LENGTH) { // 报文字节数达不到报文长度退出 lastReadBuffer = ByteBuffer.wrap(ByteBufferUtil.readBuffer(newByteBuffer, newByteBuffer.remaining())); return; } // 获取报文头部, 即报文有效长度 int payloadLength = newByteBuffer.getInt(); if (newByteBuffer.remaining() &lt; payloadLength) { // 拆包 : 后续字节不够一个完整报文 // 因上一操作 getInt 读取了 4 字节, 故需将 position 退回移动 4 字节 newByteBuffer.position(newByteBuffer.position() - HEAD_LENGTH); lastReadBuffer = ByteBuffer.wrap(ByteBufferUtil.readBuffer(newByteBuffer, newByteBuffer.remaining())); return; } // 获取有效报文 handlerPacket(socketChannel, ByteBufferUtil.readBuffer(newByteBuffer, payloadLength)); if (newByteBuffer.remaining() &gt; 0) { // 剩下的报文 可能是有效报文, 继续解码 continue decode; } return; } } private void handlerPacket (SocketChannel socketChannel, byte[] packet) { ServiceLoader&lt;PacketHandler&gt; packetHandlers = ServiceLoader.load(PacketHandler.class); Iterator&lt;PacketHandler&gt; packetHandlerIterator = packetHandlers.iterator(); while (packetHandlerIterator.hasNext()) { packetHandlerIterator.next().handler(socketChannel, packet); } } } 依赖的工具方法如下： public class ByteBufferUtil { private ByteBufferUtil () {} /** * 将两个 bytebuffer 合并 * * @param byteBuffer1 * @param byteBuffer2 * @return */ public static ByteBuffer composite(ByteBuffer byteBuffer1, ByteBuffer byteBuffer2) { int capacity = byteBuffer1.limit() - byteBuffer1.position() + byteBuffer2.limit() - byteBuffer2.position(); ByteBuffer ret = ByteBuffer.allocate(capacity); ret.put(byteBuffer1); ret.put(byteBuffer2); ret.position(0); ret.limit(ret.capacity()); return ret; } /** * 获取 bytebuffer 中可读的内容 * * @param byteBuffer * @param size * @return */ public static byte[] readBuffer(ByteBuffer byteBuffer, int size) { byte[] bytes = new byte[size]; byteBuffer.get(bytes); return bytes; } }","categories":[],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://www.hxlzpnyist.site/tags/NIO/"}],"keywords":[]},{"title":"NIO之ByteBuffer","slug":"NIO之ByteBuffer","date":"2017-12-13T09:14:14.000Z","updated":"2019-06-21T06:48:22.153Z","comments":true,"path":"2017/12/13/NIO之ByteBuffer/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/13/NIO之ByteBuffer/","excerpt":"ByteBuffer字段说明 Capacity : Buffer 固定的容量大小 Position : 表示当前的位置， 初始值为0；当为写模式时，当写入一个字节的时候，position会向前移动到下一个可插入数据的buffer单元；当为读模式时，position会重置为0，每读取一个字节的时候，position会向前移动下一个可读取的位置。 Limit : 表示buffer最多可写或可读的数量。写模式下limit = capacity; 读模式下limit = position 初始化 采用jvm堆内存初始 /** * 定义初始容量10字节的缓冲区 capacity=10, limit=10, position=0 */ ByteBuffer byteBuffer = ByteBuffer.allocate(10);","text":"ByteBuffer字段说明 Capacity : Buffer 固定的容量大小 Position : 表示当前的位置， 初始值为0；当为写模式时，当写入一个字节的时候，position会向前移动到下一个可插入数据的buffer单元；当为读模式时，position会重置为0，每读取一个字节的时候，position会向前移动下一个可读取的位置。 Limit : 表示buffer最多可写或可读的数量。写模式下limit = capacity; 读模式下limit = position 初始化 采用jvm堆内存初始 /** * 定义初始容量10字节的缓冲区 capacity=10, limit=10, position=0 */ ByteBuffer byteBuffer = ByteBuffer.allocate(10); 采用堆外内存初始 /** * 定义初始容量10字节的缓冲区 capacity=10, limit=10, position=0 */ ByteBuffer byteBuffer = ByteBuffer.allocateDirect(10); put(byte byte) 写入数据时，每写入一个字节的时候 会检验 position &gt;= limit, 之后执行position++ 自增操作； public Bytebuffer put (byte x) { hb[ix(nextPutIndex())] = x; return this; } int nextPutIndex () { if (position &gt;= limit) { throw new BufferOverflowException(); } return position++; } flip() buffer 由写模式切换到读模式; limit 值为position， position会重置为0 public final Buffer flip() { limit = position; position = 0; mark = -1; return this; } get() buffer 读取数据的时候，检验position&gt;=limit; 之后执行position++ public byte get() { return hb[ix(nextGetIndex())]; } int nextGetIndex () { if (position &gt;= limit){ throw new BufferUnderflowException(); } return position++; }","categories":[],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://www.hxlzpnyist.site/tags/NIO/"},{"name":"bytebuffer","slug":"bytebuffer","permalink":"https://www.hxlzpnyist.site/tags/bytebuffer/"}],"keywords":[]},{"title":"zookeeper源码阅读之server","slug":"zookeeper源码阅读之server","date":"2017-12-12T11:29:37.000Z","updated":"2019-06-21T06:49:03.284Z","comments":true,"path":"2017/12/12/zookeeper源码阅读之server/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/12/zookeeper源码阅读之server/","excerpt":"zookeeper server 启动流程概述 此次只针对单机模式对 server 端的启动流程分析, 首先看下 zookeeper server 启动时序图，如下： 其启动流程如下： 执行 zkServer.sh start 脚本, 会调用 QuorumPeerMain.main(); 执行 initializeAndRun 方法 调用 QuorumPeerConfig.parse() 方法，该方法主要是对启动参数的解析并加载相应的配置文件 通过上文解析的配置, 判断当前启动模式是否为集群或单机模式 单机模式下调用 ZookeeperServerMain.main() 方法 执行 ZookeeperServerMain.initializeAndRun 方法 调用 ServerConfig.parse 再次解析启动参数加载配置文件 调用 runFromConfig , 在该方法中依次启动 JettyAdminServer.start(), NIOServerCnxnFactory.startup() 至此 zookeeper server 完成单机模式下启动，接下来将详细看下 NIOServerCnxnFactory.startup 的启动过程。","text":"zookeeper server 启动流程概述 此次只针对单机模式对 server 端的启动流程分析, 首先看下 zookeeper server 启动时序图，如下： 其启动流程如下： 执行 zkServer.sh start 脚本, 会调用 QuorumPeerMain.main(); 执行 initializeAndRun 方法 调用 QuorumPeerConfig.parse() 方法，该方法主要是对启动参数的解析并加载相应的配置文件 通过上文解析的配置, 判断当前启动模式是否为集群或单机模式 单机模式下调用 ZookeeperServerMain.main() 方法 执行 ZookeeperServerMain.initializeAndRun 方法 调用 ServerConfig.parse 再次解析启动参数加载配置文件 调用 runFromConfig , 在该方法中依次启动 JettyAdminServer.start(), NIOServerCnxnFactory.startup() 至此 zookeeper server 完成单机模式下启动，接下来将详细看下 NIOServerCnxnFactory.startup 的启动过程。 zookeeper server 线程模型 在 NIOServerCnxnFactory.startup() 启动前, 我们先看下针对 NIOServerCnxnFactory 的对象的创建及相关配置: NIOServerCnxnFactory 的创建 通过 ServerCnxnFactory.createFactory 完成 ServerCnxnFactory 的创建 static public ServerCnxnFactory createFactory() throws IOException { // 获取系统变量 zookeeper.serverCnxnFactory String serverCnxnFactoryName = System.getProperty(ZOOKEEPER_SERVER_CNXN_FACTORY); if (serverCnxnFactoryName == null) { // 若未指定该变量值 则默认返回 NIOServerCnxnFactory; 同时支持 NettyServerCnxnFactory serverCnxnFactoryName = NIOServerCnxnFactory.class.getName(); } try { return (ServerCnxnFactory) Class.forName(serverCnxnFactoryName) .newInstance(); } catch (Exception e) { IOException ioe = new IOException(&quot;Couldn&#39;t instantiate &quot; + serverCnxnFactoryName); ioe.initCause(e); throw ioe; } } NIOServerCnxnFactory 的配置 在执行 startup 前会调用 configure 方法执行相关参数的初始化并绑定 serverSocket public void configure(InetSocketAddress addr, int maxcc, boolean secure) throws IOException { if (secure) { throw new UnsupportedOperationException(&quot;SSL isn&#39;t supported in NIOServerCnxn&quot;); } configureSaslLogin(); maxClientCnxns = maxcc; sessionlessCnxnTimeout = Integer.getInteger( ZOOKEEPER_NIO_SESSIONLESS_CNXN_TIMEOUT, 10000); cnxnExpiryQueue = new ExpiryQueue&lt;NIOServerCnxn&gt;(sessionlessCnxnTimeout); expirerThread = new ConnectionExpirerThread(); // 返回虚拟机的可用处理器数量 也可认为 cpu 核数 int numCores = Runtime.getRuntime().availableProcessors(); // 32 cores sweet spot seems to be 4 selector threads // 计算 selectorThread 线程个数 numSelectorThreads = Integer.getInteger( ZOOKEEPER_NIO_NUM_SELECTOR_THREADS, Math.max((int) Math.sqrt((float) numCores/2), 1)); if (numSelectorThreads &lt; 1) { throw new IOException(&quot;numSelectorThreads must be at least 1&quot;); } // 工作线程 workerThread 数; 默认为 2*numCores numWorkerThreads = Integer.getInteger( ZOOKEEPER_NIO_NUM_WORKER_THREADS, 2 * numCores); workerShutdownTimeoutMS = Long.getLong( ZOOKEEPER_NIO_SHUTDOWN_TIMEOUT, 5000); // 创建 selectorThread 线程集合 for(int i=0; i&lt;numSelectorThreads; ++i) { selectorThreads.add(new SelectorThread(i)); } // 开启服务端链接通道并绑定端口 this.ss = ServerSocketChannel.open(); ss.socket().setReuseAddress(true); LOG.info(&quot;binding to port &quot; + addr); ss.socket().bind(addr); ss.configureBlocking(false); // 创建 AcceptThread 并绑定 ServerSocketChannel selecorThreads acceptThread = new AcceptThread(ss, addr, selectorThreads); } NIOServerCnxnFactory 的启动 启动过程包括 NIOServerCnxnFactory 的启动和 ZookeeperServer 的启动`java @Override public void startup(ZooKeeperServer zks, boolean startServer) throws IOException, InterruptedException { start(); setZooKeeperServer(zks); if (startServer) { zks.startdata(); zks.startup(); } } ```java public void start() { stopped = false; if (workerPool == null) { workerPool = new WorkerService( &quot;NIOWorker&quot;, numWorkerThreads, false); } for(SelectorThread thread : selectorThreads) { if (thread.getState() == Thread.State.NEW) { thread.start(); } } // ensure thread is started once and only once if (acceptThread.getState() == Thread.State.NEW) { acceptThread.start(); } if (expirerThread.getState() == Thread.State.NEW) { expirerThread.start(); } } 从代码中可以看出 NIOServerCnxnFactory 启动的时候开启了 AcceptThread SelectorThread ExpirerThread workerPool AcceptThreadpublic void run() { try { // 当 server 未停止 并且 serverSocket 未关闭的时候一直轮询执行select() while (!stopped &amp;&amp; !acceptSocket.socket().isClosed()) { try { select(); } catch (RuntimeException e) { LOG.warn(&quot;Ignoring unexpected runtime exception&quot;, e); } catch (Exception e) { LOG.warn(&quot;Ignoring unexpected exception&quot;, e); } } } finally { closeSelector(); // This will wake up the selector threads, and tell the // worker thread pool to begin shutdown. if (!reconfiguring) { NIOServerCnxnFactory.this.stop(); } LOG.info(&quot;accept thread exitted run method&quot;); } } private void select() { try { selector.select(); Iterator&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys().iterator(); while (!stopped &amp;&amp; selectedKeys.hasNext()) { SelectionKey key = selectedKeys.next(); selectedKeys.remove(); if (!key.isValid()) { continue; } if (key.isAcceptable()) { if (!doAccept()) { pauseAccept(10); } } else { LOG.warn(&quot;Unexpected ops in accept select &quot; + key.readyOps()); } } } catch (IOException e) { LOG.warn(&quot;Ignoring IOException while selecting&quot;, e); } } private boolean doAccept() { boolean accepted = false; SocketChannel sc = null; try { // 获取客户端链接 sc = acceptSocket.accept(); accepted = true; InetAddress ia = sc.socket().getInetAddress(); int cnxncount = getClientCnxnCount(ia); // 判断该客户端连接数是否超过最大值 if (maxClientCnxns &gt; 0 &amp;&amp; cnxncount &gt;= maxClientCnxns){ throw new IOException(&quot;Too many connections from &quot; + ia + &quot; - max is &quot; + maxClientCnxns ); } LOG.info(&quot;Accepted socket connection from &quot; + sc.socket().getRemoteSocketAddress()); sc.configureBlocking(false); // Round-robin assign this connection to a selector thread // 选取一个 selectorThread if (!selectorIterator.hasNext()) { selectorIterator = selectorThreads.iterator(); } SelectorThread selectorThread = selectorIterator.next(); // 将接收到的链接 添加到 selector thread 的接收队列中 if (!selectorThread.addAcceptedConnection(sc)) { throw new IOException( &quot;Unable to add connection to selector queue&quot; + (stopped ? &quot; (shutdown in progress)&quot; : &quot;&quot;)); } acceptErrorLogger.flush(); } catch (IOException e) { // accept, maxClientCnxns, configureBlocking acceptErrorLogger.rateLimitLog( &quot;Error accepting new connection: &quot; + e.getMessage()); fastCloseSock(sc); } return accepted; } 从代码中可以看出 AcceptThread 主要用来接收客户端的链接，并将就绪的客户端链接添加到 selectorThread线程对象的 acceptQueue 中 SelectorThreadpublic boolean addAcceptedConnection(SocketChannel accepted) { if (stopped || !acceptedQueue.offer(accepted)) { return false; } // 当接收到一个链接的时候, 唤醒阻塞在 selector.select(）操作上的线程 wakeupSelector(); return true; } 当 AcceptThread 将就绪的客户端链接添加到 selectorThread 对象的 acceptQueue 队列中的时候，同时会唤醒阻塞在 acceptQueue.poll() , selector.select() 操作的实例 public void run() { try { while (!stopped) { try { select(); // 处理 acceptedQueue 队列里面的客户端链接 processAcceptedConnections(); processInterestOpsUpdateRequests(); } catch (RuntimeException e) { LOG.warn(&quot;Ignoring unexpected runtime exception&quot;, e); } catch (Exception e) { LOG.warn(&quot;Ignoring unexpected exception&quot;, e); } } // Close connections still pending on the selector. Any others // with in-flight work, let drain out of the work queue. for (SelectionKey key : selector.keys()) { NIOServerCnxn cnxn = (NIOServerCnxn) key.attachment(); if (cnxn.isSelectable()) { cnxn.close(); } cleanupSelectionKey(key); } SocketChannel accepted; while ((accepted = acceptedQueue.poll()) != null) { fastCloseSock(accepted); } updateQueue.clear(); } finally { closeSelector(); // This will wake up the accept thread and the other selector // threads, and tell the worker thread pool to begin shutdown. NIOServerCnxnFactory.this.stop(); LOG.info(&quot;selector thread exitted run method&quot;); } } private void select() { try { selector.select(); Set&lt;SelectionKey&gt; selected = selector.selectedKeys(); ArrayList&lt;SelectionKey&gt; selectedList = new ArrayList&lt;SelectionKey&gt;(selected); Collections.shuffle(selectedList); Iterator&lt;SelectionKey&gt; selectedKeys = selectedList.iterator(); while(!stopped &amp;&amp; selectedKeys.hasNext()) { SelectionKey key = selectedKeys.next(); selected.remove(key); if (!key.isValid()) { cleanupSelectionKey(key); continue; } if (key.isReadable() || key.isWritable()) { handleIO(key); } else { LOG.warn(&quot;Unexpected ops in select &quot; + key.readyOps()); } } } catch (IOException e) { LOG.warn(&quot;Ignoring IOException while selecting&quot;, e); } } private void handleIO(SelectionKey key) { IOWorkRequest workRequest = new IOWorkRequest(this, key); NIOServerCnxn cnxn = (NIOServerCnxn) key.attachment(); // Stop selecting this key while processing on its // connection cnxn.disableSelectable(); key.interestOps(0); touchCnxn(cnxn); LOG.info(&quot;Selector THread 开始处理 io&quot;); workerPool.schedule(workRequest); } private void processAcceptedConnections() { SocketChannel accepted; while (!stopped &amp;&amp; (accepted = acceptedQueue.poll()) != null) { SelectionKey key = null; try { // 将 acceptQueue 中的 socketChannel 注册到 selector 并监听读事件 key = accepted.register(selector, SelectionKey.OP_READ); // 新建 nioServerCnxn 并以附加信息的方式绑定到 selectkey NIOServerCnxn cnxn = createConnection(accepted, key, this); key.attach(cnxn); addCnxn(cnxn); } catch (IOException e) { // register, createConnection cleanupSelectionKey(key); fastCloseSock(accepted); } } } 从以上代码可以看出 selectorThread 流程如下: 轮询 selector 选择器上是否有就绪的客户端通道 当有就绪 Read 事件的客户端通道时 将该客户端派发到 wokerPool 去执行 当 acceptQueue 队列中有新接收的到客户通道的时候 将其注册到 selector 上并监听 READ 事件；同时并创建一个 NIOServerCnxn 对象绑定到 key 上（待执行 handleIO 时用到） 接下来看下 wokerPool 如何处理 workRequest public void schedule(WorkRequest workRequest, long id) { if (stopped) { workRequest.cleanup(); return; } ScheduledWorkRequest scheduledWorkRequest = new ScheduledWorkRequest(workRequest); // If we have a worker thread pool, use that; otherwise, do the work // directly. // 如果 workers 数量大于 0, 则通过 ExecutorService 执行 scheduledWorkRequest； 反之直接调用 ScheduledWorkRequest int size = workers.size(); if (size &gt; 0) { try { // make sure to map negative ids as well to [0, size-1] int workerNum = ((int) (id % size) + size) % size; ExecutorService worker = workers.get(workerNum); worker.execute(scheduledWorkRequest); } catch (RejectedExecutionException e) { LOG.warn(&quot;ExecutorService rejected execution&quot;, e); workRequest.cleanup(); } } else { // When there is no worker thread pool, do the work directly // and wait for its completion scheduledWorkRequest.start(); try { scheduledWorkRequest.join(); } catch (InterruptedException e) { LOG.warn(&quot;Unexpected exception&quot;, e); Thread.currentThread().interrupt(); } } } private class ScheduledWorkRequest extends ZooKeeperThread { private final WorkRequest workRequest; ScheduledWorkRequest(WorkRequest workRequest) { super(&quot;ScheduledWorkRequest&quot;); this.workRequest = workRequest; } @Override public void run() { try { // Check if stopped while request was on queue if (stopped) { workRequest.cleanup(); return; } workRequest.doWork(); } catch (Exception e) { LOG.warn(&quot;Unexpected exception&quot;, e); workRequest.cleanup(); } } } private class IOWorkRequest extends WorkerService.WorkRequest { private final SelectorThread selectorThread; private final SelectionKey key; private final NIOServerCnxn cnxn; IOWorkRequest(SelectorThread selectorThread, SelectionKey key) { this.selectorThread = selectorThread; this.key = key; this.cnxn = (NIOServerCnxn) key.attachment(); } public void doWork() throws InterruptedException { if (!key.isValid()) { selectorThread.cleanupSelectionKey(key); return; } if (key.isReadable() || key.isWritable()) { LOG.info(&quot;IOWorker Request do work &quot;); cnxn.doIO(key); // Check if we shutdown or doIO() closed this connection if (stopped) { cnxn.close(); return; } if (!key.isValid()) { selectorThread.cleanupSelectionKey(key); return; } touchCnxn(cnxn); } // Mark this connection as once again ready for selection cnxn.enableSelectable(); // Push an update request on the queue to resume selecting // on the current set of interest ops, which may have changed // as a result of the I/O operations we just performed. if (!selectorThread.addInterestOpsUpdateRequest(key)) { cnxn.close(); } } @Override public void cleanup() { cnxn.close(); } } 从上面代码可以看出在执行 IOWorkRequest 时会选择由线程池执行还是单线程执行；最终会由 NIOServerCnxn 处理客户端通道的读写事件 综合 AcceptThread SelectorThread IOWorkRequest 可以看出 zookeeper server 的线程模型为单线程的 Reactor模型;如下图所示: 后续相关的 IO 处理及 PrepRequestProcessor 相关的 Processor 流程会在下文分析","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.hxlzpnyist.site/tags/zookeeper/"}],"keywords":[]},{"title":"VIM 支持 markdown 预览","slug":"vim编写markdown实时预览","date":"2017-12-12T03:28:15.000Z","updated":"2019-06-21T06:48:38.206Z","comments":true,"path":"2017/12/12/vim编写markdown实时预览/","link":"","permalink":"https://www.hxlzpnyist.site/2017/12/12/vim编写markdown实时预览/","excerpt":"安装 vim 插件管理器 vundle下载 vundle git clone https://github.com/VundleVim/Vundle.vim ~/.vim/bundle/Vundle.vim 编辑 vim 配置文件 vimrc 通过 apt-get install vim 安装的 vim 配置文件路径为 /etc/vim/vimrc vim /etc/vim/vimrc","text":"安装 vim 插件管理器 vundle下载 vundle git clone https://github.com/VundleVim/Vundle.vim ~/.vim/bundle/Vundle.vim 编辑 vim 配置文件 vimrc 通过 apt-get install vim 安装的 vim 配置文件路径为 /etc/vim/vimrc vim /etc/vim/vimrc 将以下内容添加到 vimrc 文件中 set nocompatible &quot; be iMproved, required filetype off &quot; required &quot; 启用vundle来管理vim插件 set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() &quot; 安装插件写在这之后 &quot; let Vundle manage Vundle, required Plugin &#39;VundleVim/Vundle.vim&#39; &quot; 安装插件写在这之前 call vundle#end() &quot; required filetype plugin on &quot; required&quot; 常用命令 &quot; :PluginList - 查看已经安装的插件 &quot; :PluginInstall - 安装插件 &quot; :PluginUpdate - 更新插件 &quot; :PluginSearch - 搜索插件，例如 :PluginSearch xml就能搜到xml相关的插件 &quot; :PluginClean - 删除插件，把安装插件对应行删除，然后执行这个命令即可 &quot; h: vundle - 获取帮助 进入 vim 执行 PluginInstall sudo vim :PluginInstall 插件安装完成后, 左下角会出现 Done！ 至此 vundle 插件管理器安装完成. 安装 vim-instant-markdown 插件 在 vim 配置文件 vimrc 文件中添加以下内容: Plugin &#39;suan/vim-instant-markdown&#39; 再次进入 vim 执行 PluginInstall; 当出现 Done！即表示插件安装完成. 此时 vim xx.md 即可实时预览 markdown 文件;效果如下图所示.","categories":[],"tags":[{"name":"vim","slug":"vim","permalink":"https://www.hxlzpnyist.site/tags/vim/"}],"keywords":[]}]}