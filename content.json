{"meta":{"title":"断风雨","subtitle":"耐得住寂寞,才能守得住繁华","description":null,"author":"hxlzpnyist","url":"https://hxlzpnyist.github.io"},"pages":[{"title":"about","date":"2019-02-22T06:12:19.000Z","updated":"2019-02-22T06:12:49.522Z","comments":true,"path":"about/index.html","permalink":"https://hxlzpnyist.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Hello World","slug":"hello-world (2)","date":"2019-02-22T06:51:48.243Z","updated":"2017-12-12T03:15:21.000Z","comments":true,"path":"2019/02/22/hello-world (2)/","link":"","permalink":"https://hxlzpnyist.github.io/2019/02/22/hello-world (2)/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[],"keywords":[]},{"title":"测试文章","slug":"测试文章","date":"2019-02-22T02:47:09.000Z","updated":"2019-02-22T02:55:05.707Z","comments":true,"path":"2019/02/22/测试文章/","link":"","permalink":"https://hxlzpnyist.github.io/2019/02/22/测试文章/","excerpt":"","text":"测试标题 这是测试内容","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://hxlzpnyist.github.io/tags/java/"},{"name":"后端","slug":"后端","permalink":"https://hxlzpnyist.github.io/tags/后端/"}],"keywords":[]},{"title":"Hello World","slug":"hello-world","date":"2019-02-21T15:00:40.113Z","updated":"2019-02-21T15:00:40.114Z","comments":true,"path":"2019/02/21/hello-world/","link":"","permalink":"https://hxlzpnyist.github.io/2019/02/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[],"keywords":[]},{"title":"TCP：三次握手、四次握手、backlog及其他","slug":"TCP：三次握手、四次握手、backlog及其他","date":"2018-03-13T11:58:41.000Z","updated":"2018-03-13T12:01:40.000Z","comments":true,"path":"2018/03/13/TCP：三次握手、四次握手、backlog及其他/","link":"","permalink":"https://hxlzpnyist.github.io/2018/03/13/TCP：三次握手、四次握手、backlog及其他/","excerpt":"","text":"参考博客 TCP：三次握手、四次握手、backlog及其他","categories":[],"tags":[],"keywords":[]},{"title":"Java内存模型","slug":"Java内存模型","date":"2018-03-11T11:42:20.000Z","updated":"2018-03-11T12:17:02.000Z","comments":true,"path":"2018/03/11/Java内存模型/","link":"","permalink":"https://hxlzpnyist.github.io/2018/03/11/Java内存模型/","excerpt":"","text":"定义Java 虚拟机规范中通过定义一种 Java 内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现 Java 程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存主内存 : 在 Java 内存模型中规定了所有的变量都存储在主内存中。工作内存 : 每个线程都有自己的工作内存，在工作内存中保存了该线程使用到的变量的主内存副本拷贝；线程对变量的所有操作必须在工作内存中完成，而不能直接读写主内存的变量；不同线程之间无法直接访问对方的工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 此处我们描述的主内存，工作内存与 Java 运行时数据中的堆,栈，方法区并不是同一层次的内存划分；二者基本上是没有关系的，不过也可以理解为主内存对应于 Java 堆中的对象实例，而工作内存对应于虚拟机中的栈。 内存间如何交互在 Java 内存模型中定义了８中操作用来实现内存间的交互，也即是变量如何从主内存拷贝到工作内存，以及工作内存中的变量如何同步回主内存。 ８中操作如下： lock : 锁定，作用于主内存的变量，将变量标志为一条线程独占的状态 unlock : 解锁，作用于主内存的变量，将处于锁定状态的变量释放，方便其他线程锁定 read : 读取，作用于主内存的变量，将一个变量的值从主内存传输到工作内存中 load : 载入，作用于工作内存，将read操作从主内存得到的变量放入工作内存的变量副本中 use : 使用，作用于工作内存的变量 assign : 赋值 store : 存储 write : 在 Java 模型中还规定了在完成上述操作时必须满足以下规则： 变量在工作内存中改变之后必须把该变化同步到主内存 一个变量在同一时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次；多次 lock 之后，只有执行相同次数的 unlock 操作，变量才会被解锁；也就是可重入锁。 对一个变量执行 lock 操作，将会清空工作内存中此变量的值也就是从主内存重新获取该变量的值更新到工作内存中 对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中","categories":[],"tags":[],"keywords":[]},{"title":"Jdk之LinkedHashMap","slug":"Jdk之LinkedHashMap","date":"2018-03-05T13:29:13.000Z","updated":"2018-03-05T14:47:38.000Z","comments":true,"path":"2018/03/05/Jdk之LinkedHashMap/","link":"","permalink":"https://hxlzpnyist.github.io/2018/03/05/Jdk之LinkedHashMap/","excerpt":"概述LinkedHashMap 与 HashMap 的不同之处在于前者遍历有序，后者遍历无序 从上图中可以看出 LinkedHashMap 继承至 HashMap , 并重写了 init, createEntry, addEntry, iterator 等方法。 同时新增了全局变量 header, 并自定义了 LinkedHashMap.Entry 内部类","text":"概述LinkedHashMap 与 HashMap 的不同之处在于前者遍历有序，后者遍历无序 从上图中可以看出 LinkedHashMap 继承至 HashMap , 并重写了 init, createEntry, addEntry, iterator 等方法。 同时新增了全局变量 header, 并自定义了 LinkedHashMap.Entry 内部类 private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; { // These fields comprise the doubly linked list used for iteration. Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) { super(hash, key, value, next); } /** * Removes this entry from the linked list. */ private void remove() { before.after = after; after.before = before; } /** * Inserts this entry before the specified existing entry in the list. */ private void addBefore(Entry&lt;K,V&gt; existingEntry) { after = existingEntry; before = existingEntry.before; before.after = this; after.before = this; } } 从代码中可以看出 LinkedHashMap.Entry 继承至 HashMap.Entry , 新增了变量 before, after; 以及内部方法 addBefore; 那么 LinkedHashMap 如何保证遍历有序的呢？下文将详细说明，首先我们先看下 LinkedHashMap 的初始化操作有何不同。 init void init() { header = new Entry&lt;&gt;(-1, null, null, null); header.before = header.after = header; } 在初始化过程中 构建了 header 节点 createEntry /** * This override differs from addEntry in that it doesn&#39;t resize the * table or remove the eldest entry. */ void createEntry(int hash, K key, V value, int bucketIndex) { HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); table[bucketIndex] = e; e.addBefore(header); size++; } 从代码中可以看出与 HashMap 不同之处在于 构建 Entry 实例之后执行了 e.addBefore 方法 private void addBefore(Entry&lt;K,V&gt; existingEntry) { // 当前节点的后驱节点指向 existingEntry after = existingEntry; // 当前节点的前驱节点指向 existingEntry 的后驱节点 before = existingEntry.before; // 当前节点的前驱节点的后驱节点指向当前节点 before.after = this; // 当前节点的后驱节点的前驱节点指向当前节点 after.before = this; } 从init, Entry.addBefore 方法可以看出 LinkedHashMap 内部维护了一个”双向链表”，每次添加元素的时候会将该节点添加到链表中；如下图所示： iteratorprivate abstract class LinkedHashIterator&lt;T&gt; implements Iterator&lt;T&gt; { Entry&lt;K,V&gt; nextEntry = header.after; Entry&lt;K,V&gt; lastReturned = null; /** * The modCount value that the iterator believes that the backing * List should have. If this expectation is violated, the iterator * has detected concurrent modification. */ int expectedModCount = modCount; public boolean hasNext() { // 当 nextEntry 不等于 header 的表示还未遍历到链表末尾 return nextEntry != header; } public void remove() { if (lastReturned == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); LinkedHashMap.this.remove(lastReturned.key); lastReturned = null; expectedModCount = modCount; } Entry&lt;K,V&gt; nextEntry() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (nextEntry == header) throw new NoSuchElementException(); Entry&lt;K,V&gt; e = lastReturned = nextEntry; // 指向节点的后驱节点 nextEntry = e.after; return e; } } 从内部类 LinkedHashIterator 中可以看出 LinkedHashMap 是遍历双向链表，从而保证遍历的时候有序. 同样 LinkedHashSet 内部是调用 LinkedHashMap 实现，同样也保证了遍历有序。","categories":[],"tags":[],"keywords":[]},{"title":"Jdk之HashMap","slug":"Jdk之HashMap","date":"2018-03-05T11:10:27.000Z","updated":"2018-03-05T13:28:33.000Z","comments":true,"path":"2018/03/05/Jdk之HashMap/","link":"","permalink":"https://hxlzpnyist.github.io/2018/03/05/Jdk之HashMap/","excerpt":"","text":"概述HashMap 是散列表的一种基于拉链法的实现方式。 本文先看下 HashMap 的迭代实现方式 private abstract class HashIterator&lt;E&gt; implements Iterator&lt;E&gt; { Entry&lt;K,V&gt; next; // next entry to return int expectedModCount; // For fast-fail int index; // current slot Entry&lt;K,V&gt; current; // current entry HashIterator() { expectedModCount = modCount; if (size &gt; 0) { // advance to first entry Entry[] t = table; // 遍历数组 直到发现一个不为空的 Entry while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; } } public final boolean hasNext() { return next != null; } final Entry&lt;K,V&gt; nextEntry() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); // 获取当前 Entry 链表的下一个节点，如果下个节点为空说明当前链表已经遍历结束 // 此时继续遍历数组 直到发现一个不为空的 Entry if ((next = e.next) == null) { Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; } current = e; return e; } public void remove() { if (current == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); Object k = current.key; current = null; HashMap.this.removeEntryForKey(k); expectedModCount = modCount; } } 遍历过程如下图所示：","categories":[],"tags":[],"keywords":[]},{"title":"jdk之TreeMap","slug":"jdk之TreeMap","date":"2018-03-01T14:35:24.000Z","updated":"2018-03-01T14:36:08.000Z","comments":true,"path":"2018/03/01/jdk之TreeMap/","link":"","permalink":"https://hxlzpnyist.github.io/2018/03/01/jdk之TreeMap/","excerpt":"","text":"定义TreeMap 基于红黑树实现","categories":[],"tags":[],"keywords":[]},{"title":"jdk之LinkedList","slug":"jdk之LinkedList","date":"2018-02-28T11:54:31.000Z","updated":"2018-03-01T06:47:22.000Z","comments":true,"path":"2018/02/28/jdk之LinkedList/","link":"","permalink":"https://hxlzpnyist.github.io/2018/02/28/jdk之LinkedList/","excerpt":"定义public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 从定义可以看出 LinkedList 实现了接口 List, Deque, 表明其支持列表,栈，队列，双端队列的操作。","text":"定义public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 从定义可以看出 LinkedList 实现了接口 List, Deque, 表明其支持列表,栈，队列，双端队列的操作。 变量 transient int size = 0; /** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; size : 链表元素个数 first : 指向链表的头节点 last : 指向链表的尾节点 内部类 private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; } } Node 是 LinkedList 的内部类，定义了链表的节点结构: item : 节点存储的元素 prev : 当前节点的前驱节点 next : 当前节点的后驱节点 Apiadd(E)向链表中添加元素 public boolean add(E e) { linkLast(e); return true; } void linkLast(E e) { final Node&lt;E&gt; l = last; // 定义插入节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) // 链表为空 头尾节点均指向新插入的节点 first = newNode; else // 链表的尾节点后驱节点指向新插入的节点 l.next = newNode; // 元素个数加一 size++; modCount++; } 首先构建待插入的节点 将尾节点指向待插入的节点 若原尾节点为空，说明队列为空，将头节点也指向待插入的节点 若原尾节点非空，则将原尾节点的后驱节点指向待插入节点 元素个数加一 add(index, e)向链表中指定的位置插入元素 public void add(int index, E element) { // 检查位置index 是否在链表范围内 checkPositionIndex(index); if (index == size) // 表明在链表的末尾插入节点 linkLast(element); else linkBefore(element, node(index)); } node(index) 方法用于获取链表指定位置的节点 Node&lt;E&gt; node(int index) { // assert isElementIndex(index); // 判断index 是否比链表长度的一半小；size &gt;&gt; 1 相当于 size/2 // 如果小于链表的一半，则从头节点开始遍历 // 如果大于链表的一半，则从尾节点开始遍历 if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; } } linkBefor(E e, Node succ) 方法用于在指定节点前插入元素 void linkBefore(E e, Node&lt;E&gt; succ) { // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; } set(index, e)更新链表指定位置节点的元素，并返回老的元素 public E set(int index, E element) { checkElementIndex(index); // 获取指定位置的节点 Node&lt;E&gt; x = node(index); E oldVal = x.item; // 更新节点元素 x.item = element; return oldVal; } get(index)获取链表指定位置的元素 public E get(int index) { checkElementIndex(index); // 获取指定位置的节点 然后返回其存储的元素 return node(index).item; } remove(index)删除链表指定位置的节点并返回该节点存储的元素 public E remove(int index) { checkElementIndex(index); return unlink(node(index)); } unlink(node) 该方法从字面上理解即解除节点与链表的链接 E unlink(Node&lt;E&gt; x) { // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) { // 前驱节点为空，说明删除的节点为头节点 // 那么将头节点指向删除节点的后驱节点 first = next; } else { // 前驱节点不为空 // 将前驱节点的后驱节点指向删除节点的后驱节点 prev.next = next; // 删除节点的前驱节点指向空 x.prev = null; } if (next == null) { // 删除节点的后驱节点为空，说明删除节点为尾节点 // 那么将尾节点指向删除节点的前驱节点 last = prev; } else { // 后驱节点不为空 // 将后驱节点的前驱节点指向删除节点的前驱节点 next.prev = prev; // 删除节点的后驱节点指向空 x.next = null; } // 存储元素改为空,元素个数减一 x.item = null; size--; modCount++; return element; } iterator()链表的迭代, 内部调用的是 listIterator(0) 方法 public ListIterator&lt;E&gt; listIterator(int index) { checkPositionIndex(index); return new ListItr(index); } private class ListItr implements ListIterator&lt;E&gt; { private Node&lt;E&gt; lastReturned = null; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) { // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; } public boolean hasNext() { // nextIndex 小于 size 表明还未遍历到链表结尾 return nextIndex &lt; size; } public E next() { checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; // next 指向下一个节点 next = next.next; // nextIndex 加一 nextIndex++; return lastReturned.item; } }","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"数据结构-平衡二叉树","slug":"数据结构-平衡二叉树","date":"2018-02-26T10:50:42.000Z","updated":"2018-02-28T11:14:12.000Z","comments":true,"path":"2018/02/26/数据结构-平衡二叉树/","link":"","permalink":"https://hxlzpnyist.github.io/2018/02/26/数据结构-平衡二叉树/","excerpt":"概念平衡二叉树平衡二叉树(Self-Balancing Binary Search Tree) 是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于１。","text":"概念平衡二叉树平衡二叉树(Self-Balancing Binary Search Tree) 是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于１。 平衡因子平衡因子 BF (Balance Factor) : 我们将二叉树上节点的左子树的深度减去右子树的深度值称为平衡因子；那么平衡二叉树上所有节点的平衡因子只可能是 -1, 0, 1。 只要二叉树上有一个节点的平衡因子的绝对值大于１, 那么该二叉树就是不平衡的 最小不平衡子树最小不平衡子树: 当我们在执行平衡二叉树插入节点时，距离插入节点最近的，且平衡因子的绝对值大于１的节点为根的子树，我们将其称之为最小不平衡子树。 示例现通过下图一些样例说明何为平衡二叉树 图１为平衡二叉树：因为除了根节点的平衡因子为０，其他节点的平衡因子的绝对值均为１，符合平衡二叉树的条件 图２不是平衡二叉树：因为节点５８的左节点为５９，５９ &gt; 58 不符合二叉树的性质左节点小于根节点，所以也不符合平衡二叉树 图３不是平衡二叉树：因为节点５８的左子树的深度为２，而右子树为空；平衡因子为２，所以不符合平衡二叉树的条件 图４为平衡二叉树，满足平衡二叉树的条件 同样如上图所示，插入节点３７时，距离它最近的且平衡因子超过１的节点为５８，所以５８节点开始以下的子树为最小不平衡子树。 实现原理平衡二叉树构建的基本思想就是在构建二叉排序树的过程中，每当插入一个节点时先检查是否因插入而破坏了树的平衡性；若是则找出最小不平衡子树，在保持二叉排序树特性的前提下调整最小不平衡子树中各节点之间的链接关系进行相应的旋转，使其成为新的平衡子树。 下面以一个数组 a[10] = {3, 2, 1, 4, 5, 6, 7, 10, 9, 8} 构建平衡二叉树的过程来说明其实现原理。 以上两张图说明了平衡二叉树在构建过程的原理。针对构建过程发现不平衡的处理有如下几个步骤： 当最小不平衡子树根节点的平衡因子BF大于１时，右旋；当平衡因子小于-1时左旋 当最小不平衡子树的BF与其子节点BF符号相反时，需要先对子节点进行一次旋转使得符号相同后再进行一次旋转已达到平衡 右旋 : 将旋转节点的左节点指向其左节点的右节点，然后将旋转节点的左节点的右节点指向旋转节点（旋转节点下降，其左节点上浮） 左旋 : 将旋转节点的右节点指向其右节点的左节点，然后将旋转节点的右节点的左节点指向旋转节点（旋转节点下降，其右节点上浮）","categories":[],"tags":[],"keywords":[]},{"title":"java-泛型","slug":"java-泛型","date":"2018-01-29T09:17:34.000Z","updated":"2018-01-30T09:04:59.000Z","comments":true,"path":"2018/01/29/java-泛型/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/29/java-泛型/","excerpt":"","text":"类型擦除泛型和方法重载","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://hxlzpnyist.github.io/tags/java/"}],"keywords":[]},{"title":"jdk之LinkedBlockingQueue","slug":"jdk之LinkedBlockingQueue","date":"2018-01-26T06:18:59.000Z","updated":"2018-01-26T11:00:49.000Z","comments":true,"path":"2018/01/26/jdk之LinkedBlockingQueue/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/26/jdk之LinkedBlockingQueue/","excerpt":"概述在上一篇文章中我们分析了 ArrayBlockingQueue , 今天在看下采用链表结构实现的阻塞队列。 分析前我们同样有以下疑问： 如何通过链表实现队列的 FIFO ? 如何保证队列操作的同步 ? 与 ArrayBlockingQueue 相比有如何优势 ?","text":"概述在上一篇文章中我们分析了 ArrayBlockingQueue , 今天在看下采用链表结构实现的阻塞队列。 分析前我们同样有以下疑问： 如何通过链表实现队列的 FIFO ? 如何保证队列操作的同步 ? 与 ArrayBlockingQueue 相比有如何优势 ? 定义同样首先我们先来看下 LinkedBlockingQueue 的相关属性定义如下： /** * 定义链表节点 * * item : 节点存储的元素 * next : 当前节点的后继节点 */ static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node(E x) { item = x; } } /** 定义队列的容量 默认为 Integer.MAX_VALUE */ private final int capacity; /** 定义当前队列的存储元素个数 */ private final AtomicInteger count = new AtomicInteger(0); /** * 队列头节点 * Invariant: head.item == null */ private transient Node&lt;E&gt; head; /** * 队列尾节点 * Invariant: last.next == null */ private transient Node&lt;E&gt; last; /** Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition(); 从定义中有以下几个疑问： 当前队列元素个数为什么采用原子操作类 AtomicInteger ? int 类型的变量为什么不可以？ 队列的头尾节点定义注释中为什么说 head last 都有一个不变性 item 永远为空 ? 构造 public LinkedBlockingQueue() { // 队列默认容量为 int 最大值 this(Integer.MAX_VALUE); } public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); // 设置队列容量 this.capacity = capacity; // 初始队列头尾节点 last = head = new Node&lt;E&gt;(null); } APIoffer(E e) public boolean offer(E e) { if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) // 若队列满了 返回 false; 说明插入失败 return false; int c = -1; // 定义节点 Node&lt;E&gt; node = new Node(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try { if (count.get() &lt; capacity) { // 插入队列 enqueue(node); // 队列元素个数加一，并返回原来的个数 c = count.getAndIncrement(); if (c + 1 &lt; capacity) // 队列未满唤醒因为队列满而阻塞的 put 操作 notFull.signal(); } } finally { putLock.unlock(); } // c == 0 说明队列曾经为空，那么需要唤醒阻塞在 take poll 操作上的线程 if (c == 0) signalNotEmpty(); return c &gt;= 0; } private void enqueue(Node&lt;E&gt; node) { // 将原尾节点的后继节点 指向 node // 将尾节点指针指向 node last = last.next = node; } offer 之后 last 永远指向链表的最近插入的节点，所以 last 节点的 next 永远为空。 poll() public E poll() { final AtomicInteger count = this.count; if (count.get() == 0) // 队列为空 返回 null return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { if (count.get() &gt; 0) { // 出队 获取队列头部元素 x = dequeue(); // 队列元素个数减一 并返回原个数 c = count.getAndDecrement(); if (c &gt; 1) // 唤醒因队列为空而阻塞的 take poll 操作 notEmpty.signal(); } } finally { takeLock.unlock(); } // c== capacity 说明队列曾经满了有 offer put 线程阻塞，故需唤醒 if (c == capacity) signalNotFull(); return x; } private E dequeue() { Node&lt;E&gt; h = head; // 取 head 的后继节点 Node&lt;E&gt; first = h.next; // 将 head 节点的 next 指向自己 h.next = h; // help GC // 将 head 重新指向头节点 head = first; E x = first.item; // 将 item 置为空 first.item = null; return x; } 此时我们可以看出 LinkedBlockingQueue 中通过移动节点 head last 指针来实现队列的 FIFO; 效果如下图所示： 因为插入和获取头部操作里采用的是两个不同的锁，所以为了保持不同线程不同操作内队列元素个数的一致性所以采用 AtomicInteger 计算而非 int 类型。 put(E e)public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { while (count.get() == capacity) { notFull.await(); } enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } if (c == 0) signalNotEmpty(); } take()","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"jdk之ArrayBlockingQueue","slug":"jdk之ArrayBlockingQueue","date":"2018-01-24T06:28:27.000Z","updated":"2018-01-25T06:37:21.000Z","comments":true,"path":"2018/01/24/jdk之ArrayBlockingQueue/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/24/jdk之ArrayBlockingQueue/","excerpt":"概述ArrayBlockingQueue 又称为数组阻塞队列；其基于数组实现的有界阻塞队列，能容纳的元素数量固定，一旦创建就不能再增加其容量。 那么接下来我们会带着以下两个疑问进行分析： 如何通过数组实现队列的特性 FIFO ? 如何保证队列插入获取操作的同步 ?","text":"概述ArrayBlockingQueue 又称为数组阻塞队列；其基于数组实现的有界阻塞队列，能容纳的元素数量固定，一旦创建就不能再增加其容量。 那么接下来我们会带着以下两个疑问进行分析： 如何通过数组实现队列的特性 FIFO ? 如何保证队列插入获取操作的同步 ? 定义首先看下 ArrayBlockingQueue 的属性定义 如下： /** 固定大小数组用于存储队列元素 */ final Object[] items; /** 指向下次获取元素的下标 可以理解为指向队列头部 */ int takeIndex; /** 指向下次插入元素的下标 可以理解为指向队列尾部 */ int putIndex; /** 当前队列存储元素的个数 */ int count; /** 定义可重入锁 */ final ReentrantLock lock; /** 用于控制 take 操作的 condition */ private final Condition notEmpty; /** 用于控制 put 操作的 condition */ private final Condition notFull; 构造函数 public ArrayBlockingQueue(int capacity) { this(capacity, false); } /** * 创建固定容量的阻塞队列并设置访问策略 * @param capacity 队列的最大容量 * @param fair 队列的访问策略，true为公平锁策略, false为非公平锁；默认为 false */ public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); } 从构造函数可以看出，在创建 ArrayBlockinQueue 实例时，需指定队列最大存储元素的容量并设置内部重入锁的访问策略默认为非公平锁。 APIadd(E e) public boolean add(E e) { return super.add(e); } 从代码可以看出 ArrayBlockingQueue 的 add 方法的实现是基于父类 AbstractQueu 的实现如下： public boolean add(E e) { if (offer(e)) return true; else throw new IllegalStateException(&quot;Queue full&quot;); } 从代码中我们知道 add 方法的主要实现在 offer 方法内（将会在下文分析），如果能够插入成功则返回 true, 否则抛出 IllegalStateException 异常 remove()remove 方法移除队列的头部元素并返回, 其实现是在父类 AbstractQueue 中如下: public E remove() { E x = poll(); if (x != null) return x; else throw new NoSuchElementException(); } 如上代码知道 remov的主要实现在 poll 方法内；如果获取的头部元素不为空将返回，若为空则抛出 NoSUchElementException 异常。 offer(E e) public boolean offer(E e) { // 检查元素是否为空 checkNotNull(e); final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try { // 元素个数达到最大容量时返回 fae if (count == items.length) return false; // 执行插入返回 true else { insert(e); return true; } } finally { // 释放锁 lock.unlock(); } } private void insert(E x) { // 将元素插入数组指定的位置 items[putIndex] = x; // 将 putIndex 移动到下一个位置 putIndex = inc(putIndex); // 元素个数加一 ++count; // 当前队列非空，唤醒阻塞在获取元素操作上的线程 notEmpty.signal(); } 从代码可以看出 offer 方法将元素插入队列的逻辑如下： 判断元素是否为空 获取锁 判断队列是否已满，若已满则返回 false 通过指针 putIndex 将元素放入数组 移动指针 putIndex 指向下一个位置 队列当前元素个数加一 唤醒阻塞在获取元素操作上的线程 释放锁 poll() public E poll() { final ReentrantLock lock = this.lock; lock.lock(); try { // 队列空的时候 返回 null; 非空的时候调用 extract return (count == 0) ? null : extract(); } finally { lock.unlock(); } } private E extract() { final Object[] items = this.items; // 获取头部的元素 E x = this.&lt;E&gt;cast(items[takeIndex]); // 将队列头部置为空 items[takeIndex] = null; // 移动头部指针 takeIndex = inc(takeIndex); // 队列元素个数减一 --count; // 唤醒因队列满而阻塞的插入操作 notFull.signal(); return x; } poll 方法获取头部元素逻辑如下： 获取锁 判断队列是否为空，若空则返回 null 通过 takeIndex 头部指针获取队列头元素 将队列头部置为空 移动头部指针指向下个位置 队列元素个数减一 唤醒因队列满而阻塞的插入操作 返回头部元素并释放锁 此时我们可以看出 ArrayBlockingQueue 中通过两个指针 takeIndex putIndex 的移动来保证队列的 FIFO,如下图所示： 我们知道数组有界 在队列中又是如何保证循环利用的呢？ final int inc(int i) { return (++i == items.length) ? 0 : i; } 从 inc 方法可以看出在移动 takeindex putindex 指针的时候，当他们到达末尾的时候重新指向头部。 offer(E e,long timeout,TimeUnit u)该方法表示在指定的时间内将元素插入队列中，若失败返回 false 。 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 当前元素个数达到队列最大容量时 等待 while (count == items.length) { if (nanos &lt;= 0) // 说明已超时 队列满了插入失败 返回 false return false; nanos = notFull.awaitNanos(nanos); } // 执行插入 insert(e); return true; } finally { // 释放锁 lock.unlock(); } } 该方法与 offer(e) 实现基本相同，只是在当队列满的情况下会在设置的 timeout 时间内等待。 poll(long timeout, TimeUnit unit) public E poll(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 当队列空的时候等待队列有元素；若等待超时之后还未有元素则返回 false while (count == 0) { if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); } // 队列非空时 获取头部元素 return extract(); } finally { // 释放锁 lock.unlock(); } } 与 poll() 方法类似，不同之处在于当队列为空的时候等待。 put(E e) public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 队列满的时候 while (count == items.length) // 释放锁当前线程阻塞；等待 take 操作唤醒 notFull.await(); // 队列未满执行插入 insert(e); } finally { // 释放锁 lock.unlock(); } } 该方法与 offer 不同之处在于当队列满的时候，当前线程会阻塞直至等待 take 操作唤醒。 take() public E take() throws InterruptedException { final ReentrantLock lock = this.lock; // 获取锁 lock.lockInterruptibly(); try { // 队列为空的时候 while (count == 0) // 释放锁当前线程阻塞；等待 put 操作唤醒 notEmpty.await(); // 队列非空 获取头部元素 return extract(); } finally { // 释放锁 lock.unlock(); } } 该方法与 poll 不同之处在于当队列为空的时候，当前线程会一直阻塞直至等待 put 操作唤醒。 小结 ArrayBlockingQueue 采用数组作为元素存储，故其为有界队列 ArrayBlockingQueue 通过指针 takeIndex putIndex 的移动来实现 FIFO ArrayBlockingQueue 通过定义 ReentrantLock 重入锁来保证插入获取操作的同步。也就是当前若有线程在执行插入操作，则获取操作同样会被阻塞。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"jdk之BlockingQueue","slug":"jdk之BlockingQueue","date":"2018-01-24T03:20:13.000Z","updated":"2018-01-24T06:08:37.000Z","comments":true,"path":"2018/01/24/jdk之BlockingQueue/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/24/jdk之BlockingQueue/","excerpt":"概述BlockingQueue 被称为阻塞队列，除了具备 Queue 的特点外，还支持另外两项重要特性： 对于有界队列，当队列满的时候，插入操作会阻塞等待队列可用； 当队列空的时候，获取元素的操作会阻塞等待队列为非空 阻塞队列常用于“生产者－消费者”模式的业务场景，生产者就是往阻塞队列中插入元素的线程，消费者就是从阻塞队列中获取元素的线程；当生产者的速度大于消费者的速度，就可能出现有界队列满的情况，此时生产者就会出现阻塞等待状态直到队列中出现空闲；当生产者的速度小于消费者的速度就可能出现空队列的情况，消费者就会出现阻塞等待状态，直到队列中有元素。","text":"概述BlockingQueue 被称为阻塞队列，除了具备 Queue 的特点外，还支持另外两项重要特性： 对于有界队列，当队列满的时候，插入操作会阻塞等待队列可用； 当队列空的时候，获取元素的操作会阻塞等待队列为非空 阻塞队列常用于“生产者－消费者”模式的业务场景，生产者就是往阻塞队列中插入元素的线程，消费者就是从阻塞队列中获取元素的线程；当生产者的速度大于消费者的速度，就可能出现有界队列满的情况，此时生产者就会出现阻塞等待状态直到队列中出现空闲；当生产者的速度小于消费者的速度就可能出现空队列的情况，消费者就会出现阻塞等待状态，直到队列中有元素。 APIadd(Object o)该方法是将指定元素插入到队列中，如果队列可插入则返回 true, 否则抛出异常 offer(Object o)该方法将指定元素插入到队列中，如果队列可插入则返回 true, 否则返回 false offer (Object, timeout, timeunit)该方法在设定的等待时间内如果能将指定元素插入到队列中返回 true, 否则返回 false poll(long timeout,TimeUnit unit)该方法从队列中取出一个队首的元素，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。超时后，依然没有取得数据则返回NULL put(Object o)把对象o加入到BlockingQueue里，如果BlockingQueue没有足够空间，则调用此方法的线程会被阻塞等待，直到BlockingQueue里面有空闲空间时再继续执行 take( )取走BlockingQueue里排在首位的对象，如果BlockingQueue为空，则调用此方法的线程会被阻塞等待，直到BlockingQueue里面有新元素被加入后再继续执行 后续将会对 BlockingQueue 的几种实现进行分析.","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"Netty客户端链接派发分析","slug":"Netty客户端链接派发分析","date":"2018-01-20T02:39:43.000Z","updated":"2018-01-20T08:14:14.000Z","comments":true,"path":"2018/01/20/Netty客户端链接派发分析/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/20/Netty客户端链接派发分析/","excerpt":"在上篇针对 Netty 的服务端启动过程进行了分析，我们知道服务端包含了两个 NioEventLoopGroup, 一个是 boss 用于接收客户端的请求，一个是 worker 用于处理客户端的读写操作；那么 boss group 是如何将客户端链接通道派发到 worker 呢？本文主要针对这个问题进行分析。","text":"在上篇针对 Netty 的服务端启动过程进行了分析，我们知道服务端包含了两个 NioEventLoopGroup, 一个是 boss 用于接收客户端的请求，一个是 worker 用于处理客户端的读写操作；那么 boss group 是如何将客户端链接通道派发到 worker 呢？本文主要针对这个问题进行分析。 NioEventLoop上文中我们知道 netty 主要通过 NioEventLoop 内部的线程处理客户端请求，那么我们接下来详细看下该线程的实现： protected SingleThreadEventExecutor( EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.parent = parent; this.addTaskWakesUp = addTaskWakesUp; thread = threadFactory.newThread(new Runnable() { @Override public void run() { boolean success = false; updateLastExecutionTime(); try { SingleThreadEventExecutor.this.run(); success = true; } catch (Throwable t) { logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); } finally { } } }); threadProperties = new DefaultThreadProperties(thread); this.maxPendingTasks = Math.max(16, maxPendingTasks); taskQueue = newTaskQueue(); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;); } NioEventLoop 内部的线程运行时会调用抽象方法 run, 其实现如下： protected void run() { for (;;) { try { switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) { case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); if (wakenUp.get()) { selector.wakeup(); } // fall through default: } cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) { try { processSelectedKeys(); } finally { // Ensure we always run tasks. runAllTasks(); } } else { final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); } finally { // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); } } } catch (Throwable t) { handleLoopException(t); } // Always handle shutdown even if the loop processing threw an exception. try { if (isShuttingDown()) { closeAll(); if (confirmShutdown()) { return; } } } catch (Throwable t) { handleLoopException(t); } } } 该线程内部以“死循环”的方式 执行 select 后处理 selectedKeys : private void processSelectedKeys() { if (selectedKeys != null) { processSelectedKeysOptimized(); } else { processSelectedKeysPlain(selector.selectedKeys()); } } selectedKeys 是在NioEventLoop构建时创建的SelectedSelectionKeySet实例，故会调用 processSelectedKeysOptimized 方法如下： private void processSelectedKeysOptimized() { for (int i = 0; i &lt; selectedKeys.size; ++i) { final SelectionKey k = selectedKeys.keys[i]; // null out entry in the array to allow to have it GC&#39;ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.keys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) { processSelectedKey(k, (AbstractNioChannel) a); } else { @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); } if (needsToSelectAgain) { // null out entries in the array to allow to have it GC&#39;ed once the Channel close // See https://github.com/netty/netty/issues/2363 selectedKeys.reset(i + 1); selectAgain(); i = -1; } } } 其实现是循环遍历 selectedKeys 集合中的 selectedKey 进行处理，那么此时我们会有一个疑惑： selector 选择器中就绪的通道的 selectedKey 是如何添加到 selectedKeys 集合中呢？ 让我们回过头在看下 NioEventLoop 开启 selector 的过程： private SelectorTuple openSelector() { final Selector unwrappedSelector; try { // 开启 selector 返回 EpollSelectorImpl 实例 unwrappedSelector = provider.openSelector(); } catch (IOException e) { throw new ChannelException(&quot;failed to open a new selector&quot;, e); } if (DISABLE_KEYSET_OPTIMIZATION) { return new SelectorTuple(unwrappedSelector); } final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet(); // ...... final Class&lt;?&gt; selectorImplClass = (Class&lt;?&gt;) maybeSelectorImplClass; Object maybeException = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { @Override public Object run() { try { Field selectedKeysField = selectorImplClass.getDeclaredField(&quot;selectedKeys&quot;); Field publicSelectedKeysField = selectorImplClass.getDeclaredField(&quot;publicSelectedKeys&quot;); Throwable cause = ReflectionUtil.trySetAccessible(selectedKeysField); if (cause != null) { return cause; } cause = ReflectionUtil.trySetAccessible(publicSelectedKeysField); if (cause != null) { return cause; } // 将 Selector 实现类的属性 selectedKeys 替换为 netty 自定义的 SelectedSelectionKeySet // 这样当选择器 有就绪的通道时 就会把 selectKey 添加到 SelectedSelectionKeySet 中 selectedKeysField.set(unwrappedSelector, selectedKeySet); publicSelectedKeysField.set(unwrappedSelector, selectedKeySet); return null; } catch (NoSuchFieldException e) { return e; } catch (IllegalAccessException e) { return e; } } }); if (maybeException instanceof Exception) { selectedKeys = null; Exception e = (Exception) maybeException; logger.trace(&quot;failed to instrument a special java.util.Set into: {}&quot;, unwrappedSelector, e); return new SelectorTuple(unwrappedSelector); } selectedKeys = selectedKeySet; logger.trace(&quot;instrumented a special java.util.Set into: {}&quot;, unwrappedSelector); return new SelectorTuple(unwrappedSelector, new SelectedSelectionKeySetSelector(unwrappedSelector, selectedKeySet)); } 从代码中可以看出 NioEventLoop 内部对于 selector 进行了包装，通过反射对 EpollSelectorImpl 实例内字段 selectedKeys publicSelectedKeys 替换为 SelectedSelectionKeySet 实例；这样就保证了当选择器有就绪的通道时就会把 selectKey 添加到 selectedSelectionKeySet 中 我们在回到 processSelectedKeysOptimized 方法中，当集合中有就绪的 selectedKey 时，会获取绑定在该 key 上的附件 attachment 针对服务端来说 也就是 NioServerSocketChannel （注册的时候绑定的)；接下来会调用 processSelectedKey 如下： private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final NioUnsafe unsafe = ch.unsafe(); try { int readyOps = k.readyOps(); // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise // the NIO JDK channel implementation may throw a NotYetConnectedException. if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) { // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); } // Process OP_WRITE first as we may be able to write some queued buffers and so free memory. if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) { // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); } // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { unsafe.read(); } } catch (CancelledKeyException ignored) { unsafe.close(unsafe.voidPromise()); } } 因服务端监听的是 ACCEPT 事件，故当有客户端链接请求就绪的时候会调用 unsafe.read() ,此时 unsafe 实例为 NioMessageSafe: public void read() { assert eventLoop().inEventLoop(); final ChannelConfig config = config(); if (!config.isAutoRead() &amp;&amp; !isReadPending()) { // ChannelConfig.setAutoRead(false) was called in the meantime removeReadOp(); return; } final int maxMessagesPerRead = config.getMaxMessagesPerRead(); final ChannelPipeline pipeline = pipeline(); boolean closed = false; Throwable exception = null; try { try { for (;;) { int localRead = doReadMessages(readBuf); // 当没有客户端通道时退出 if (localRead == 0) { break; } if (localRead &lt; 0) { closed = true; break; } // stop reading and remove op if (!config.isAutoRead()) { break; } if (readBuf.size() &gt;= maxMessagesPerRead) { break; } } } catch (Throwable t) { exception = t; } setReadPending(false); int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) { // 触发 pipeline 的 channelRead 事件 pipeline.fireChannelRead(readBuf.get(i)); } readBuf.clear(); // 触发 pipeline 的 channelReadComplete 事件 pipeline.fireChannelReadComplete(); if (exception != null) { closed = closeOnReadError(exception); pipeline.fireExceptionCaught(exception); } if (closed) { if (isOpen()) { close(voidPromise()); } } } finally { } } protected int doReadMessages(List&lt;Object&gt; buf) throws Exception { // 获取客户端通道 SocketChannel ch = SocketUtils.accept(javaChannel()); try { if (ch != null) { // 将 nio socketChannel 封装为 NioSocketChannell 添加到 buf 集合中 buf.add(new NioSocketChannel(this, ch)); return 1; } } catch (Throwable t) { logger.warn(&quot;Failed to create a new channel from an accepted socket.&quot;, t); try { ch.close(); } catch (Throwable t2) { logger.warn(&quot;Failed to close a socket.&quot;, t2); } } return 0; } 其流程为： 获取客户端通道 socketChannel 并将其封装为 NioSocketChannel 添加到缓冲中 触发 pipeline 的 channelRead 事件 触发 pipeline 的 channelReadComplete 事件 最终会触发 ServerBootstrapAcceptor handler 的 channelRead 事件如下： public void channelRead(ChannelHandlerContext ctx, Object msg) { // msg 为 NioSocketChannel 实例 final Channel child = (Channel) msg; // 将 ServerBootstrap 设置的 childHandler 添加到 NioSocketChannel 的 pipeline 中 child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) { child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); } try { // childGroup 也就是我们所理解的 wrker group // 执行注册 nioSocketChannel 即将 NioSocektChannel 注册到 worker group 中的 NioEventLoop 的 selector childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); } } channelReadComplete 事件在执行过程中最终会调用 NioSocktChannel 的 doBegingRead 方法如下： protected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called if (inputShutdown) { return; } final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) { // NioSocetChannel 创建的时候 readInterestop 值为 O_READ selectionKey.interestOps(interestOps | readInterestOp); } } protected AbstractNioByteChannel(Channel parent, SelectableChannel ch) { super(parent, ch, SelectionKey.OP_READ); } 至此将 SocketChannel 客户端通道注册到 worker group 中的 NioEventLoop 内的 selector 并监听 OP_READ 事件。 此时 netty 内部线程模型如下：","categories":[],"tags":[{"name":"netty","slug":"netty","permalink":"https://hxlzpnyist.github.io/tags/netty/"}],"keywords":[]},{"title":"Netty服务端启动源码分析","slug":"Netty服务端启动源码分析","date":"2018-01-17T08:28:57.000Z","updated":"2018-01-18T09:17:04.000Z","comments":true,"path":"2018/01/17/Netty服务端启动源码分析/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/17/Netty服务端启动源码分析/","excerpt":"Netty 是一个高性能异步事件驱动的 NIO 框架, 因其底层采用的 NIO, 故其启动过程一样可以分为以下几个步骤: selector 多路复用选择器开启 ServerSocketChannel 通道建立并绑定端口 ServerSocketChannel 通道注册到 selector 并监听 accept 事件 在进行服务端启动分析前，我们先看下 netty 的服务端使用示例。","text":"Netty 是一个高性能异步事件驱动的 NIO 框架, 因其底层采用的 NIO, 故其启动过程一样可以分为以下几个步骤: selector 多路复用选择器开启 ServerSocketChannel 通道建立并绑定端口 ServerSocketChannel 通道注册到 selector 并监听 accept 事件 在进行服务端启动分析前，我们先看下 netty 的服务端使用示例。 示例// Configure the server. EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline p = ch.pipeline(); if (sslCtx != null) { p.addLast(sslCtx.newHandler(ch.alloc())); } p.addLast(new EchoServerHandler()); } }); // Start the server. ChannelFuture f = b.bind(PORT).sync(); // Wait until the server socket is closed. f.channel().closeFuture().sync(); } finally { // Shut down all event loops to terminate all threads. bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } 从示例可以看出 netty 服务端通过创建 ServerBootstrap 实例，并对其配置 EventLoopGroup, channel, handler 之后即完成服务端的启动。 NioEventLoopGroup - selector的创建从示例中可以看出 ServerBootstrap 启动的过程中需要两个 EventLoopGroup 实例，从职责上可以将其分为两种 boss 和 worker;前者主要负责客户端链接的接收以及派发到 worker, 后者主要负责客户端链接的读写请求操作。 NioEventLoopGroup 的创建 public NioEventLoopGroup(int nThreads) { this(nThreads, null); } public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory) { this(nThreads, threadFactory, SelectorProvider.provider()); } public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, final SelectorProvider selectorProvider) { this(nThreads, threadFactory, selectorProvider, DefaultSelectStrategyFactory.INSTANCE); } public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, final SelectorProvider selectorProvider, final SelectStrategyFactory selectStrategyFactory) { super(nThreads, threadFactory, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject()); } static { DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt( &quot;io.netty.eventLoopThreads&quot;, NettyRuntime.availableProcessors() * 2)); if (logger.isDebugEnabled()) { logger.debug(&quot;-Dio.netty.eventLoopThreads: {}&quot;, DEFAULT_EVENT_LOOP_THREADS); } } protected MultithreadEventLoopGroup(int nThreads, ThreadFactory threadFactory, Object... args) { super(nThreads == 0? DEFAULT_EVENT_LOOP_THREADS : nThreads, threadFactory, args); } 加载 MultithreadEventLoopGroup 类时，会先计算默认线程数其值为处理器个数的两倍。 在看下父类MultithreadEventExecutorGroup的构造方法： protected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) { if (nThreads &lt;= 0) { throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); } if (threadFactory == null) { threadFactory = newDefaultThreadFactory(); } children = new SingleThreadEventExecutor[nThreads]; // 创建 事件执行器的选择器 if (isPowerOfTwo(children.length)) { chooser = new PowerOfTwoEventExecutorChooser(); } else { chooser = new GenericEventExecutorChooser(); } for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { // 创建 NioEventLoop children[i] = newChild(threadFactory, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { } } // 非核心代码省略 } newChild 是抽象方法由子类 NioEventLoopGroup 实现 protected EventExecutor newChild(ThreadFactory threadFactory, Object... args) throws Exception { return new NioEventLoop(this, threadFactory, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]); } 从上述代码中可以看出 NioEventLoopGroup 构建过程中会按指定的线程数创建 NioEventLoop 实例并存储在 children 事件执行器数组中；同时创建了 chooser 实例，chooser 用于在新的客户端链接请求到达的时候从 children 数组中选取 eventLoop 的策略。 NioEventLoop的创建先看下 NioEventLoop 的构造 NioEventLoop(NioEventLoopGroup parent, ThreadFactory threadFactory, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) { super(parent, threadFactory, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); if (selectorProvider == null) { throw new NullPointerException(&quot;selectorProvider&quot;); } if (strategy == null) { throw new NullPointerException(&quot;selectStrategy&quot;); } provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); // 创建 selector 选择器 selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy; } 其父类构造如下： protected SingleThreadEventExecutor( EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) { if (threadFactory == null) { throw new NullPointerException(&quot;threadFactory&quot;); } this.parent = parent; this.addTaskWakesUp = addTaskWakesUp; // 内部线程 thread = threadFactory.newThread(new Runnable() { @Override public void run() { // 此处省略线程的具体执行 } }); threadProperties = new DefaultThreadProperties(thread); this.maxPendingTasks = Math.max(16, maxPendingTasks); // 任务队列 taskQueue = newTaskQueue(); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;); } protected Queue&lt;Runnable&gt; newTaskQueue() { return newTaskQueue(maxPendingTasks); } protected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) { return new LinkedBlockingQueue&lt;Runnable&gt;(maxPendingTasks); } 从 NioEventLoop 的构造方法可以看出, 其内部包含了一个 thread 以及 taskQueue 并且绑定了一个 selector; taskQueue 用于存储内部执行的任务, thread 该线程主要用来执行 taskQueue 中的任务及处理客户端链接的请求。 此时完成了 selector 选择器的创建,并将其绑定到 NioEventLoop 实例 在完成了两个 NioEventLoopGroup 实例的创建之后 我们可以看出 Netty 内部线程模型大概如下： NioServerSocketChannel 通道创建ServerBootstrap 在完成 group, channel, handler 的配置之后调用 bind 完成服务端启动，让我们看下其实现: public ChannelFuture bind(int inetPort) { return bind(new InetSocketAddress(inetPort)); } public ChannelFuture bind(String inetHost, int inetPort) { return bind(SocketUtils.socketAddress(inetHost, inetPort)); } public ChannelFuture bind(InetAddress inetHost, int inetPort) { return bind(new InetSocketAddress(inetHost, inetPort)); } public ChannelFuture bind(SocketAddress localAddress) { validate(); if (localAddress == null) { throw new NullPointerException(&quot;localAddress&quot;); } return doBind(localAddress); } private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } // 暂时省略 } 从上述代码中可以在 bind 过程中，先完成 channel 的注册及初始化其实现在 initAndRegister 方法中如下： final ChannelFuture initAndRegister() { Channel channel = null; try { // 创建 NioServerSocketChannel channel = channelFactory().newChannel(); // 初始化 channel init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // channel 注册 ChannelFuture regFuture = group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } return regFuture; } 从 initAndRegister 方法中可以看出，该方法主要完成以下三件事: NioServerSocketChannel 实例的创建 NioServerSocketChannel 的初始化 NioServerSocketChannel 的注册 NioServerSocketChannel的创建先让我们回过头看下 ServerBootstrap 启动时配置 channel 方法： public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } return channelFactory(new BootstrapChannelFactory&lt;C&gt;(channelClass)); } public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) { if (channelFactory == null) { throw new NullPointerException(&quot;channelFactory&quot;); } if (this.channelFactory != null) { throw new IllegalStateException(&quot;channelFactory set already&quot;); } this.channelFactory = channelFactory; return self(); } 也就是说此时 channelFactory 实例为 BootstrapChannelFactory, 接下来我们看下其实现： private static final class BootstrapChannelFactory&lt;T extends Channel&gt; implements ChannelFactory&lt;T&gt; { private final Class&lt;? extends T&gt; clazz; BootstrapChannelFactory(Class&lt;? extends T&gt; clazz) { this.clazz = clazz; } @Override public T newChannel() { try { return clazz.getConstructor().newInstance(); } catch (Throwable t) { throw new ChannelException(&quot;Unable to create Channel from class &quot; + clazz, t); } } } 故 channelFactory.newChannel() 方法也就是创建指定了 channel class 的实例也就是 NioServerSocketChannel 实例，接下来看下其构造实现： private static ServerSocketChannel newSocket(SelectorProvider provider) { try { return provider.openServerSocketChannel(); } catch (IOException e) { throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); } } private final ServerSocketChannelConfig config; public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER)); } public NioServerSocketChannel(SelectorProvider provider) { this(newSocket(provider)); } public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); } 其父类 AbstractNioChannel AbstractChannel 构造方法如下： protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { } } protected AbstractChannel(Channel parent) { this.parent = parent; unsafe = newUnsafe(); pipeline = newChannelPipeline(); } 从 NioServerSocketChannel 的构造方法看出其主要流程如下: 通过 newSocket 方法创建了 ServerSocketChannel 实例并设置为非阻塞模式 设置了待监听事件 OP_ACCEPT 创建 unsafe 实例为 NioMessageUnsafe 创建 pipeline 实例为 DefaultChannelPipeline 此时完成了 nio 中的 ServerSocketChannel 的创建 NioServerSocktChannel的初始化init 为抽象方法由子类实现 void init(Channel channel) throws Exception { final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options(); synchronized (options) { setChannelOptions(channel, options, logger); } final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs(); synchronized (attrs) { for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) { @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); } } ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) { currentChildOptions = childOptions.entrySet().toArray(newOptionArray(childOptions.size())); } synchronized (childAttrs) { currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(childAttrs.size())); } p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) throws Exception { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = handler(); if (handler != null) { pipeline.addLast(handler); } logger.info(&quot;ServerBootStrap init channel addLast ChannelInitializer init channel&quot;); ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } }); } init 主要设置 channel 的 attr 和 options;并在 pipeline 中添加 ChannelInitializer handler NioServerSocketChannel的注册在完成 channel 的创建及初始化之后即调用 NioEventLoopGroup.register(channel) 方法完成 channel 的注册。 @Override public EventLoop next() { return (EventLoop) super.next(); } @Override public ChannelFuture register(Channel channel) { return next().register(channel); } next() 方法是按照 chooser 选取策略从 NioEventLoopGroup 中获取一个 NioEventLoop 实例;跟踪 register 方法最终调用的是 unsafe.register 方法如下: public final void register(EventLoop eventLoop, final ChannelPromise promise) { // ...... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { register0(promise); } else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } catch (Throwable t) { } } } private void register0(ChannelPromise promise) { try { // ...... boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // ...... } catch (Throwable t) { } } 调用了由子类实现的 doRegister() 方法如下： @Override protected void doRegister() throws Exception { boolean selected = false; for (;;) { try { // ServerSocketChannel 注册到 selector selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } catch (CancelledKeyException e) { if (!selected) { // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; } else { // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; } } } } 其实现就是将 ServerSocketChannel 注册到 selector 上，并以自身NioServerSocketChannel 作为附件； 注意：此时注册的时候 监听的事件 并不是 ACCEPT; 而是 0 NioServerSocketChannel 端口绑定上文中在完成了 channel 的注册之后，我们在回头看 doBind 的实现: private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { promise.setFailure(cause); } else { promise.executor = channel.eventLoop(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } } 在 channel 注册完成后会执行 doBind0 private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); } 会调用 channel.bind() 跟踪发现最终会调用 unsafe.bind() 方法如下： public final void bind(final SocketAddress localAddress, final ChannelPromise promise) { assertEventLoop(); // ...... boolean wasActive = isActive(); try { // 绑定地址端口 doBind(localAddress); } catch (Throwable t) { safeSetFailure(promise, t); closeIfClosed(); return; } if (!wasActive &amp;&amp; isActive()) { // 绑定端口成功之后 触发 pipeline handler 的 channel active 事件 invokeLater(new Runnable() { @Override public void run() { pipeline.fireChannelActive(); } }); } safeSetSuccess(promise); } protected void doBind(SocketAddress localAddress) throws Exception { if (PlatformDependent.javaVersion() &gt;= 7) { javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); } } 此时完成了 ServerSocketChannel 的服务端地址绑定 NioServerSocketChannel 注册 ACCEPT 事件上文中在完成 bind 操作之后，会触发 channelPipeline 的 channel active 事件 最终调用了 channel 的 doBeginRead 方法 protected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called if (inputShutdown) { return; } final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) { // 将 selectionKey 添加 ACCEPT 事件的监听 selectionKey.interestOps(interestOps | readInterestOp); } } 至此完成了 ServerSocketChannel 注册到 selector 并让其监听 ACCEPT 事件；服务端也启动完毕。 小结对Netty的服务端启动分析完之后，大概认识了其包含的一些组件以及各组件的作用 ServerBootstrap ：该类是服务端启动的引导类，其主要用于配置 Netty 的各个组件 NioEventLoopGroup : 该类用于管理 NioEventLoop , 并提供了 Selector 选择器创建的入口并将其绑定到 NioEventLoop 实例 NioEventLoop : 该类内部绑定了一个线程以及一个任务队列用于处理 register bind的相关任务及客户端处理（后续会详细分析） NioServerSocketChannel : 该类是对 ServerSocketChannel 的一个包装其内部包含了 unsafe channelPipeline 实例 Unsafe : 该类提供了底层的 register bind write read 等操作 DefaultChannelPipeline : 该类是个双向链表结构，其主要作用是在通道注册链接 读写的操作之后会触发相应的事件","categories":[],"tags":[{"name":"netty","slug":"netty","permalink":"https://hxlzpnyist.github.io/tags/netty/"}],"keywords":[]},{"title":"Jdk之CountDownLatch源码分析","slug":"Jdk之CountDownLatch源码分析","date":"2018-01-11T07:16:00.000Z","updated":"2018-01-11T08:05:03.000Z","comments":true,"path":"2018/01/11/Jdk之CountDownLatch源码分析/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/11/Jdk之CountDownLatch源码分析/","excerpt":"概述 CountdownLatch 是 JDK 并发包中提供的并发工具类，其允许一个或多个线程等待其他线程完成操作。常用作将一个任务拆分成多个子任务同时执行，只有子任务都执行完毕主线程才往下执行。","text":"概述 CountdownLatch 是 JDK 并发包中提供的并发工具类，其允许一个或多个线程等待其他线程完成操作。常用作将一个任务拆分成多个子任务同时执行，只有子任务都执行完毕主线程才往下执行。 用例public class CountDownLatchTest { static class Task implements Runnable { private CountDownLatch countDownLatch; public Task (CountDownLatch countDownLatch) { this.countDownLatch = countDownLatch; } @Override public void run() { System.out.println(Thread.currentThread() + &quot; done.&quot;); countDownLatch.countDown(); } } public static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(3); for (int i = 0; i &lt; 3; i++) { new Thread(new Task(countDownLatch)).start(); } countDownLatch.await(); System.out.println(&quot;main done.&quot;); } } 输出结果如下： Thread[Thread-0,5,main] done. Thread[Thread-1,5,main] done. Thread[Thread-2,5,main] done. main done. 实现Sync private static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; Sync(int count) { // 设置计数值 setState(count); } int getCount() { return getState(); } protected int tryAcquireShared(int acquires) { // 只有同步状态值为0的情况下获取共享锁成功 return (getState() == 0) ? 1 : -1; } protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; // 每次释放锁的时候计数值减一 只有值为0的时候才表示释放成功 int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; } } } await public void await() throws InterruptedException { // 主线程调用 await 发生阻塞，是因为获取锁失败被添加到同步队列线程被挂起 sync.acquireSharedInterruptibly(1); } countDown public void countDown() { // 计数减一 等同于释放一次锁,只有计数为0时才会唤醒阻塞的主线程 sync.releaseShared(1); } QA CountDownLatch 内部为什么采用共享锁机制? 个人认为是从其提供的使用场景考虑，将任务拆分为多个子任务也就是让多个线程并发执行；所以采用共享锁实现。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"Jdk之ThreadPoolExecutor源码分析","slug":"Jdk之ThreadPoolExecutor源码分析","date":"2018-01-09T11:00:02.000Z","updated":"2018-01-10T11:00:00.000Z","comments":true,"path":"2018/01/09/Jdk之ThreadPoolExecutor源码分析/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/09/Jdk之ThreadPoolExecutor源码分析/","excerpt":"概述线程池在 JAVA 中是运用场景最多的并发框架，合理的运用线程池能够带来以下好处： 降低资源消耗。 提高响应速度。 提高线程的可管理性。","text":"概述线程池在 JAVA 中是运用场景最多的并发框架，合理的运用线程池能够带来以下好处： 降低资源消耗。 提高响应速度。 提高线程的可管理性。 参数定义线程池在定义时需指定以下参数： corePoolSize : 线程池的核心线程数。 maximumPoolSize : 线程池允许创建的最大线程数 keepAliveTIme : 线程池的工作线程空闲后，保持存活的时间 TimeUnit : 线程活动保持时间的单位 threadFactory : 用于创建工作线程的工厂 workQueue : 用于存储等待执行的任务的阻塞队列; 可以选择以下几个阻塞队列： ArrayBlockingQueue : 基于数组的有界队列 LinkedBlockingQueue : 基于链表的无界队列，若采用此类型队列则 maximumPoolSize 没有意义 SynchronousQueue : 不存储元素的阻塞队列 RejectedExecutionHandler : 饱和策略，当线程池达到最大线程数以及阻塞队列满了的情况下，说明线程池处于饱和状态，此时必须采取一种策略处理提交的新任务。有以下几种策略： AbortPolicy : 直接抛出异常 CallerRunsPolicy : 采用调用者所在线程处理任务 DiscardOldestPolicy : 丢弃队列最近的一个任务,并执行当前任务 DiscardPolicy : 不处理丢弃 原理现以一张示意图说明线程池的运行原理(引用至网上的) 其运行流程如下： 提交任务时，线程池判断当前运行的工作线程数小于 corePoolSize 时，将任务封装为 worker 对象来执行任务。 当运行的工作线程数大于 corePoolSize 时，则将任务添加到 workerQueue 阻塞队列中；此时若添加队列失败（说明采用的是有界队列，队列已满)，线程池会创建 worker 对象来执行任务 当运行的工作线程数大于 maximumPoolSize 时，任务将拒绝执行 工作线程会已轮询的方式从阻塞队列中获取待执行的任务；若指定了 keepAliveTime 参数会以 poll() 的方式获取在指定的时间内若无可执行的任务，工作线程将会销毁 实现接下来看下具体如何实现的，首先让我们先看下线程池中如何计算当前运行线程数的以及线程池的运行状态 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 计算线程池的状态 private static int runStateOf(int c) { return c &amp; ~CAPACITY; } // 计算线程池中的工作线程数 private static int workerCountOf(int c) { return c &amp; CAPACITY; } private static int ctlOf(int rs, int wc) { return rs | wc; } 线程池通过 ctl 采用 int 的高３位表示线程池的运行状态，低29位表示当前线程池中的线程数； 线程池的状态包括: RUNNING 运行中，该状态会接收新的任务并处理阻塞等待队列中的任务 SHUTDOWN 关闭，通常时执行 shutdown 方法，该状态下线程池不再接收新的任务；等待线程池中和队列中的任务完成 STOP 已停止，通常是执行过 shutdownNow 方法，此时线程池不接收新的任务队列中的任务也不再执行并尝试终止线程池中的线程 TIDYING TERMINATED 执行任务(execute) public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&#39;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { // 工作线程数小于 corePoolSize 创建线程执行任务 if (addWorker(command, true)) return; c = ctl.get(); } // 检查线程池状态是否为运行中；如果为运行中则插入队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); // double check 再次检查线程池的状态; 此时若为非运行状态则将任务从队列中移除 if (! isRunning(recheck) &amp;&amp; remove(command)) // 拒绝执行任务 reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 队列若满了 则创建新的线程执行任务 else if (!addWorker(command, false)) reject(command); } 从源码方法的注释中可以看出 execute 方法主要包括３步： 如果少于 corePoolSize 的线程正在运行，则尝试创建新的线程并将接收的任务作为其第一个任务启动 如果任务成功插入队列中，仍然需要检查线程池状态因为这个时候有可能关闭了这个线程池 如果任务不能入队，则创建新的线程执行，如果创建失败则拒绝处理 private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // 检查线程池状态 队列是否为空 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) // 检查是否超过核心线程数或最大线程数 return false; // 新增工作线程数 成功则退出循环 if (compareAndIncrementWorkerCount(c)) break retry; // 若 workerCount 被其他线程修改 则继续循环 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { final ReentrantLock mainLock = this.mainLock; // 创建 worker w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { mainLock.lock(); try { // 再次检查线程池状态,操作前先获取锁防止线程池关闭 int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 添加到 workers 集合 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; // workr 添加成功 workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { // worker 启动执行任务 t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; } 接下来看下关于 Worker 的定义 private final class Worker extends AbstractQueuedSynchronizer implements Runnable { /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } /** Delegates main run loop to outer runWorker */ public void run() { runWorker(this); } } 从代码中可以看出 Worker 实现了 Runnable,构建的时候通过线程工厂启动了一个线程并将自身作为任务传递到该线程，所以在 addWorker 方法中执行 t.start() 后会执行 runWorker(this) 方法。 final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { // task 不为空或阻塞队列中还有任务的情况下循环执行 while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); Throwable thrown = null; try { // 执行任务 task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); } } finally { // 任务处理完后置为空 已处理完的任务数加１ task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 线程池已关闭或队列为空 则工作线程数减一 返回null 此时 worker 将会销毁 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } boolean timed; // Are workers subject to culling? for (;;) { int wc = workerCountOf(c); // worker 线程是否销毁 // allowCoreThreadTimeOut 表示是否允许核心线程在空闲状态下自行销毁 默认为false // 此处判断默认情况下 若超过了核心线程数则允许自行销毁 timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if (wc &lt;= maximumPoolSize &amp;&amp; ! (timedOut &amp;&amp; timed)) break; if (compareAndDecrementWorkerCount(c)) return null; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } try { // workQueue.take 若队列为空当前线程将会被挂起等待任务加入被唤醒 // workQueue.poll 若在 keepALiveTime 时间内阻塞队列还是没有任务则返回null Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } worker 在执行的过程中以自旋的方式从队列中获取任务并执行，在指定存活时间内若队列为空则获取任务为空说明无等待任务 此时跳出循环 执行 worker 的退出销毁 提交任务(submit)采用 submit() 方法提交的任务，可以通过其返回结果 Future 判断任务是否已完成以及获取任务的返回值。 submit 方法参数支持 Callable, Runnable 两种类型，当参数类型为 Runnable 时会包装成 RunnableAdapter 类，该类同样实现了 Callable 接口；所以下面我们主要分析下 submit(Callable task) 方法。 public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; } submit 方法通过将 Callable 封装成一个 FutureTask 对象后，调用了 execute 方法；也就是其处理逻辑与 execute 方法的不同之处在于 FutureTask 的 run 方法； 接下来我们看下 FutureTask 的定义与 run 方法处理逻辑: FutureTask 的属性字段以及状态说明： * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */ private volatile int state; // 初始状态 private static final int NEW = 0; // 已完成 private static final int COMPLETING = 1; // 完成后的状态 private static final int NORMAL = 2; // 异常 private static final int EXCEPTIONAL = 3; // 取消 private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; // 待执行的任务 private Callable&lt;V&gt; callable; // 任务返回值 private Object outcome; // non-volatile, protected by state reads/writes // 当前执行线程 private volatile Thread runner; // 因执行 get 操作获取返回值时被挂起的调用方线程链表 private volatile WaitNode waiters; FutureTask 的构造： public FutureTask(Callable&lt;V&gt; callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; // 初始状态 this.state = NEW; // ensure visibility of callable } FutureTask run 方法： public void run() { if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) { V result; boolean ran; try { // 执行任务 获取返回值 result = c.call(); ran = true; } catch (Throwable ex) { result = null; ran = false; setException(ex); } if (ran) // 任务执行成功 未出现异常设置返回结果 set(result); } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } protected void set(V v) { // 将状态更新为 COMPLETING if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { // 将返回结果赋值 outcome outcome = v; // 将状态更新为 NORMAL UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state // 将 waiters 链表上的阻塞线程唤醒 finishCompletion(); } } private void finishCompletion() { // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) { if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) { for (;;) { // 获取 waiters 链表上节点的线程并唤醒 Thread t = q.thread; if (t != null) { q.thread = null; LockSupport.unpark(t); } WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; } break; } } done(); callable = null; // to reduce footprint } 从代码中可以看出 run 方法处理流程如下： 执行任务存储返回结果 更新状态为已完成 唤醒被挂起的调用方 FutureTask get 方法 public V get() throws InterruptedException, ExecutionException { int s = state; if (s &lt;= COMPLETING) // 若任务还未执行完 s = awaitDone(false, 0L); return report(s); } private int awaitDone(boolean timed, long nanos) throws InterruptedException { final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) { if (Thread.interrupted()) { removeWaiter(q); throw new InterruptedException(); } int s = state; if (s &gt; COMPLETING) { if (q != null) q.thread = null; // 任务已完成则返回 return s; } else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) // 创建 waitNode q = new WaitNode(); else if (!queued) // 加入等待队列中 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) { nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) { removeWaiter(q); return state; } LockSupport.parkNanos(this, nanos); } else // 挂起当前线程 LockSupport.park(this); } } 当调用方执行 future.get() 方法时，会先判断任务是否执行完毕，若在处理中的时候，先创建 waitNode 并将其加入到等待队列中，最后将当前调用方线程挂起，等待处理完后唤醒。 线程池关闭 public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 将线程池状态修改为 SHUTDOWN advanceRunState(SHUTDOWN); // 将空闲的工作线程终止 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } tryTerminate(); } private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) { Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) { try { // 空闲的线程执行中断 t.interrupt(); } catch (SecurityException ignore) { } finally { w.unlock(); } } if (onlyOne) break; } } finally { mainLock.unlock(); } } 参考资料 JAVA 并发编程的艺术 占小狼-深入分析java线程池的实现原理 线程池ThreadPoolExecutor、Executors参数详解与源代码分析(本文中对corePoolSize 线程在线程池中的比喻解释很形象详细可以看看)","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"Jdk之ReentrantLock源码分析","slug":"Jdk之ReentrantLock源码分析","date":"2018-01-08T03:10:32.000Z","updated":"2018-01-09T03:53:52.000Z","comments":true,"path":"2018/01/08/Jdk之ReentrantLock源码分析/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/08/Jdk之ReentrantLock源码分析/","excerpt":"概述ReentrantLock 是重入锁，也就是说支持重新进入的锁，也表示同一线程在获取锁之后可以再次获取锁。 synchronizer 关键字是隐式的支持重进入的，比如说采用 synchronizer 修饰的递归方法，在方法执行时，执行线程在获取锁之后依然可以连续多次获得锁。 ReentrantLock 支持获取锁时的公平和非公平性的选择，默认为非公平性锁。","text":"概述ReentrantLock 是重入锁，也就是说支持重新进入的锁，也表示同一线程在获取锁之后可以再次获取锁。 synchronizer 关键字是隐式的支持重进入的，比如说采用 synchronizer 修饰的递归方法，在方法执行时，执行线程在获取锁之后依然可以连续多次获得锁。 ReentrantLock 支持获取锁时的公平和非公平性的选择，默认为非公平性锁。 非公平锁非公平锁是指在获取锁的过程中，新进入的线程有机率比同步队列中线程优先获取锁。 锁的获取static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; final void lock() { if (compareAndSetState(0, 1)) // 获取锁成功并绑定当前线程 setExclusiveOwnerThread(Thread.currentThread()); else // 再次获取锁 acquire(1); } protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } } final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { // 获取锁成功 绑定当前线程 setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { // 当前线程为获取锁的线程 则累加同步状态值 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } 从代码中可以看出，重入锁新增了多次获取锁的处理逻辑：通过判断当前线程是否为获取锁的线程，如果时获取锁的线程则将同步状态值累加。 锁的释放 protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { // 只有同步状态值为0 才完成真正的释放 free = true; setExclusiveOwnerThread(null); } setState(c); return free; } 从 tryRelease 方法中可以看出，只有在同步状态值为0 才完成真正的释放返回 true;也就是说 若线程获取锁了 n 次，那么前 n-1 次均是释放失败也就是返回 false. 公平锁公平锁可以理解为在绝对时间上，先对锁进行获取的线程一定先被满足，也可以理解为等待时间最长的线程最优先获取锁。 锁的获取 static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } } 从代码中可以看出公平锁在获取锁的过程多了一个判断条件 hasQueuedPredecessors(), 实现如下： public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); } hasQueuedPredecessors 主要判断是否有其他线程等待获取锁的时间要比当前线程长，也即是当前同步队列的头节点的后驱节点所绑定的线程是否为当前线程；也可以理解为新进入的线程只有在同步队列上的等待线程均处理完毕才可以获取锁，否则会加入到同步队列中。 锁的释放与公平锁的释放一样。 公平锁与非公平锁对性能的影响 公平锁保证了锁的获取按照 FIFO 原则，但会造成大量线程的切换 非公平锁可能会造成线程”饥饿”的现象（也就是线程长时间获取不到锁 一直处于阻塞状态），但极少的线程切换会保证更大的吞吐量。","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"Jdk之AbstractQueuedSynchronizer源码分析","slug":"Jdk之AbstractQueuedSynchronizer源码分析","date":"2018-01-05T10:56:27.000Z","updated":"2018-01-09T03:28:23.000Z","comments":true,"path":"2018/01/05/Jdk之AbstractQueuedSynchronizer源码分析/","link":"","permalink":"https://hxlzpnyist.github.io/2018/01/05/Jdk之AbstractQueuedSynchronizer源码分析/","excerpt":"概述 队列同步器 (AbstractQueuedSynchronizer) 是用来构建锁或其他同步组件的基础框架，使用了一个 int 成员变量表示同步状态, 通过内置的 FIFO 队列来完成资源获取线程的排队工作。 定义public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { protected AbstractQueuedSynchronizer() { } /** * 同步队列头结点 */ private transient volatile Node head; /** * 同步队列尾节点 */ private transient volatile Node tail; /** * 同步状态 */ private volatile int state; }","text":"概述 队列同步器 (AbstractQueuedSynchronizer) 是用来构建锁或其他同步组件的基础框架，使用了一个 int 成员变量表示同步状态, 通过内置的 FIFO 队列来完成资源获取线程的排队工作。 定义public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { protected AbstractQueuedSynchronizer() { } /** * 同步队列头结点 */ private transient volatile Node head; /** * 同步队列尾节点 */ private transient volatile Node tail; /** * 同步状态 */ private volatile int state; } 内置队列节点定义如下: static final class Node { /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor&#39;s thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; /** * 节点等待状态 */ volatile int waitStatus; /** * 节点的前置节点 */ volatile Node prev; /** * 节点的后置节点 */ volatile Node next; /** * 绑定节点对应的线程 */ volatile Thread thread; /** * */ Node nextWaiter; /** * Returns true if node is waiting in shared mode */ final boolean isShared() { return nextWaiter == SHARED; } /** */ final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } } 从 Node 的定义可以看出 AQS 内置的是一个双向队列，当线程获取锁失败的时候同步器会将当前线程及等待状态构造成一个节点加入到同步队列中。 等待状态 waitStatus 取值范围如下： CANCELLED = 1; 说明由于同步队列中等待的线程等待超时或被中断，需要取消等待 SIGNAL = -1; 等待触发状态，同时该节点的后继节点的线程处于等待状态，当前节点的线程如果释放了锁,将会唤醒后继节点 INITIAL = 0; 初始状态 独占模式独占模式下允许当前只有一个线程获取锁。 获取锁 通过调用同步器的 acquire(int args) 方法获取锁, 该方法对中断不敏感，也就是当线程获取锁失败后加入同步队列中，后续对线程进行中断操作时，线程不会从队列中移除。 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 获取锁的主要逻辑如下： 调用自定义实现 tryAcquire(arg) 方法, 尝试获取锁；如果获取锁失败则往下执行 addWaiter 以独占模式构造同步节点并将其添加到同步队列尾部 acquireQueued 让该节点以“死循环”的方式尝试再次获取锁，如果获取失败则将该节点对应的线程挂起，等待前置节点的唤醒 private Node addWaiter(Node mode) { // 将当前线程以独占模式创建同步节点 Node node = new Node(Thread.currentThread(), mode); // 当前队列的尾节点为新增节点的前置节点 Node pred = tail; if (pred != null) { // 前置节点不为空 说明同步队列已经初始化 // 将新增节点的前置节点指向 pred node.prev = pred; // 将同步队列的尾节点移动指向新增的节点 if (compareAndSetTail(pred, node)) { // 将 pred 的后置节点指向新增的节点 并返回 pred.next = node; return node; } } // enq 完成同步队列的初始化 并将新增节点加入队列中 enq(node); return node; } private Node enq(final Node node) { for (;;) { Node t = tail; // 判断尾节点是否为空 if (t == null) { // 执行同步队列的初始化 // 创建头节点 // 将 head tail 分别指向队列头节点 if (compareAndSetHead(new Node())) tail = head; } else { // 将 node 的前置节点指向尾节点 node.prev = t; // 将 tail 移动指向 node, 并将 t 的后置节点指向 node if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 从 enq 方法可以看出, 同步器通过”死循环”来保证节点的正确添加，只有通过CAS将节点设置为尾节点，当前线程才能返回；否则不断尝试设置。 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 获取节点的前置节点 final Node p = node.predecessor(); // 如果前置节点为 head 节点，并且再次尝试获取锁成功 if (p == head &amp;&amp; tryAcquire(arg)) { // 将 node 设为头节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 获取锁失败后 将当前线程挂起 // shouldParkAfterFailedAcquire 判断当前线程是否支持挂起 // parkAndCHeckInterrupt 将当前线程挂起, 并检测是否中断 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) // 只有当前置节点的等待状态为触发状态(-1)时返回 允许后置节点挂起 return true; if (ws &gt; 0) { do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 将前置节点的等待状态改为 -1 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } private final boolean parkAndCheckInterrupt() { // 将线程挂起 LockSupport.park(this); return Thread.interrupted(); } 从 acquireQueued 方法中可以看出，节点进入同步队列之后以“自轮询”的方式再满足条件的情况下（前置节点为头节点）再次尝试获取锁，如果获取成功则将自己设置为头节点并退出“自轮询”的过程；如果获取失败则将自己当前线程挂起阻塞等待被唤醒以此类推执行“自轮询”的过程。 释放锁public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } private void unparkSuccessor(Node node) { int ws = node.waitStatus; if (ws &lt; 0) // 将头节点的等待状态改为 0 compareAndSetWaitStatus(node, ws, 0); // 获取后置节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) // 唤醒后置节点对应的线程 LockSupport.unpark(s.thread); } 关于节点自轮询及节点释放锁后队列的变化如下图所示： 共享模式共享模式表示同一时刻允许多个线程获取锁 获取锁 public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } tryAcquireShared(arg) 尝试获取共享锁，返回结果 &gt;= 0 表示获取锁成功；反之获取锁失败, 调用 doAcquireShared(arg) private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 从 doAcquireShared 方法中可以看出共享模式下节点加入同步队列以及”自轮询”的过程与独占模式下基本类似，不同之处在于当节点尝试获取锁成功后的处理逻辑 setHeadAndPropagate private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); } } 从代码中可以看出在节点获取锁成功后会判断后置节点是否为共享模式，如果为共享模式则对其进行唤醒操作，也就是同时激发多个线程并发的运行 释放锁","categories":[],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://hxlzpnyist.github.io/tags/jdk/"}],"keywords":[]},{"title":"zookeeper源码阅读之watch","slug":"zookeeper源码阅读之watch","date":"2017-12-22T07:01:41.000Z","updated":"2017-12-22T11:52:27.000Z","comments":true,"path":"2017/12/22/zookeeper源码阅读之watch/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/22/zookeeper源码阅读之watch/","excerpt":"watcher 流程概述watcher 用来客户端监听某一节点的特性变化，执行对应的操作. 从下图可以看出 watcher 的流程主要包括: watcher 注册, 包括客户端注册, 服务端的注册 watcher 触发 watcher 执行","text":"watcher 流程概述watcher 用来客户端监听某一节点的特性变化，执行对应的操作. 从下图可以看出 watcher 的流程主要包括: watcher 注册, 包括客户端注册, 服务端的注册 watcher 触发 watcher 执行 watcher 注册本文我们以 zookeeper.getData 操作为例，对 watcher 的注册流程就行说明。 watcher 客户端注册getData api 如下: public byte[] getData(final String path, Watcher watcher, Stat stat) throws KeeperException, InterruptedException { final String clientPath = path; PathUtils.validatePath(clientPath); // the watch contains the un-chroot path WatchRegistration wcb = null; if (watcher != null) { // 定义 watcher 注册 wcb = new DataWatchRegistration(watcher, clientPath); } final String serverPath = prependChroot(clientPath); RequestHeader h = new RequestHeader(); h.setType(ZooDefs.OpCode.getData); GetDataRequest request = new GetDataRequest(); request.setPath(serverPath); // watcher 不为空的时候 设置为 true request.setWatch(watcher != null); GetDataResponse response = new GetDataResponse(); ReplyHeader r = cnxn.submitRequest(h, request, response, wcb); if (r.getErr() != 0) { throw KeeperException.create(KeeperException.Code.get(r.getErr()), clientPath); } if (stat != null) { DataTree.copyStat(response.getStat(), stat); } return response.getData(); } 在完成本次请求，处理返回 packet 的时候, 会调用 ClinetCnxn.finishPacket(packet) 方法 private void finishPacket(Packet p) { int err = p.replyHeader.getErr(); if (p.watchRegistration != null) { // 调用 wwatcher register; 处理正常的时候 err 值为 0; 可参考类 FinalRequestProcessor p.watchRegistration.register(err); } // 省略 } 以下为 watchRegistration.register 源码: public void register(int rc) { if (shouldAddWatch(rc)) { // client 下允许对多个路径设置监听 Map&lt;String, Set&lt;Watcher&gt;&gt; watches = getWatches(rc); synchronized(watches) { Set&lt;Watcher&gt; watchers = watches.get(clientPath); if (watchers == null) { // 同一路径下允许有多个 watcher watchers = new HashSet&lt;Watcher&gt;(); watches.put(clientPath, watchers); } watchers.add(watcher); } } } protected boolean shouldAddWatch(int rc) { return rc == 0; } protected Map&lt;String, Set&lt;Watcher&gt;&gt; getWatches(int rc) { return watchManager.dataWatches; } 从以上代码中可以看出, 客户端在定义 watcher 之后会将其与 path 绑定添加到 ZKWatchManager.dataWatches; 从而完成 watcher 的注册。 watcher 服务端注册server 在接收到客户端请求执行 FinalRequestProcessor.processRequest 方法过程中，会执行对 watcher 的注册，这里同样以 getData 操作的代码进行分析: case OpCode.getData: { lastOp = &quot;GETD&quot;; GetDataRequest getDataRequest = new GetDataRequest(); ByteBufferInputStream.byteBuffer2Record(request.request, getDataRequest); DataNode n = zks.getZKDatabase().getNode(getDataRequest.getPath()); if (n == null) { throw new KeeperException.NoNodeException(); } PrepRequestProcessor.checkACL(zks, zks.getZKDatabase().aclForNode(n), ZooDefs.Perms.READ, request.authInfo); Stat stat = new Stat(); // 若 client 请求的时候 watch 为 true, 则将 cnxn 作为参数 // cnxn 为每个客户端请求链接的时候 针对 selectorKey 绑定的 NIOServerCnxn 实例 byte b[] = zks.getZKDatabase().getData(getDataRequest.getPath(), stat, getDataRequest.getWatch() ? cnxn : null); rsp = new GetDataResponse(b, stat); break; } 从上面代码中 zks.getZKDatabase().getData(getDataRequest.getPath(), stat, getDataRequest.getWatch() ? cnxn : null); 跟踪发现其最后调用了 WatchManager.addWatch(path, watcher) 方法. // 注意 : 此时传递的参数 watcher 并不是客户端定义的 watcher 实例，而是服务端存储的与客户端绑定的 // NIOServerCnxn 实例；因为 NIOServerCnxn 实现了 watcher 接口; // watchTable 用来存储 path 与 watcher 的关系; 也可以表示为 多个客户端监听了同一节点 // watch2Paths 用来存储 watcher 与 path 的关系; 也可以表示为 每个客户端下监听了哪些节点 synchronized void addWatch(String path, Watcher watcher) { HashSet&lt;Watcher&gt; list = watchTable.get(path); if (list == null) { // don&#39;t waste memory if there are few watches on a node // rehash when the 4th entry is added, doubling size thereafter // seems like a good compromise list = new HashSet&lt;Watcher&gt;(4); watchTable.put(path, list); } list.add(watcher); HashSet&lt;String&gt; paths = watch2Paths.get(watcher); if (paths == null) { // cnxns typically have many watches, so use default cap here paths = new HashSet&lt;String&gt;(); watch2Paths.put(watcher, paths); } paths.add(path); } 从上面代码中可以看出,服务端在处理完客户端请求的时候 若客户端设置了 watcher 则会将其添加到 watchmanager 的 watchTable 中；至此服务端针对 watcher 的注册完毕. watcher 触发针对 watcher 触发的操作，这里以 setData api 为例说明。此时假设某个客户端执行了 setData 操作, 服务端在处理客户端请求的时候, 在调用 FinalRequestProcessor.processRequest 方法的时候会调用 zookeeperServer.processTxn(request); 最终会调用 DataTree.processTxn() 方法，此处摘取针对 setData 的操作如下 ： case OpCode.setData: SetDataTxn setDataTxn = (SetDataTxn) txn; rc.path = setDataTxn.getPath(); rc.stat = setData(setDataTxn.getPath(), setDataTxn .getData(), setDataTxn.getVersion(), header .getZxid(), header.getTime()); break; public Stat setData(String path, byte data[], int version, long zxid, long time) throws KeeperException.NoNodeException { Stat s = new Stat(); DataNode n = nodes.get(path); if (n == null) { throw new KeeperException.NoNodeException(); } byte lastdata[] = null; synchronized (n) { lastdata = n.data; n.data = data; n.stat.setMtime(time); n.stat.setMzxid(zxid); n.stat.setVersion(version); n.copyStat(s); } // now update if the path is in a quota subtree. String lastPrefix = getMaxPrefixWithQuota(path); if(lastPrefix != null) { // 更新节点数据 this.updateBytes(lastPrefix, (data == null ? 0 : data.length) - (lastdata == null ? 0 : lastdata.length)); } // 触发该节点下的 watcher dataWatches.triggerWatch(path, EventType.NodeDataChanged); return s; } 从上述代码中可以看出, 服务端在完成对节点数据更新之后调用了 watcher.triggerWatch(); 该方法接收两个参数一个为节点path, 一个为事件类型 Set&lt;Watcher&gt; triggerWatch(String path, EventType type, Set&lt;Watcher&gt; supress) { WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); HashSet&lt;Watcher&gt; watchers; synchronized (this) { watchers = watchTable.remove(path); if (watchers == null || watchers.isEmpty()) { if (LOG.isTraceEnabled()) { ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, &quot;No watchers for &quot; + path); } return null; } for (Watcher w : watchers) { HashSet&lt;String&gt; paths = watch2Paths.get(w); if (paths != null) { paths.remove(path); } } } for (Watcher w : watchers) { if (supress != null &amp;&amp; supress.contains(w)) { continue; } w.process(e); } return watchers; } 从以上代码中看出在触发 watcher 的时候，会先从 watchManager 中的 watchTable 获取指定 path 的 watcher 并将其从集合中移除（从此处我们可以看出客户端定义的 watcher 若未作处理的话 将只会监听一次）。在查找到 watcher 之后将会调用 watcher.process 即执行 watcher. watcher 执行在服务端触发 watcher 之后，会调用 watcher.process 方法，此时 watcher 的实例为 NIOServerCnxn;接下来我们看下 NIOSserverCnxn 的 process 方法: public void process(WatchedEvent event) { ReplyHeader h = new ReplyHeader(-1, -1L, 0); if (LOG.isTraceEnabled()) { ZooTrace.logTraceMessage(LOG, ZooTrace.EVENT_DELIVERY_TRACE_MASK, &quot;Deliver event &quot; + event + &quot; to 0x&quot; + Long.toHexString(this.sessionId) + &quot; through &quot; + this); } // Convert WatchedEvent to a type that can be sent over the wire WatcherEvent e = event.getWrapper(); sendResponse(h, e, &quot;notification&quot;); } 从上面代码中可以看出服务端向客户端发出了 tag 为 “notification” 的响应； 接下来我们看下客户端如何处理该响应:在 ClientCnxn 下的 SendThread.readResponse 方法中我们可以看到针对 watcher 的处理如下： if (replyHdr.getXid() == -1) { // -1 means notification if (LOG.isDebugEnabled()) { LOG.debug(&quot;Got notification sessionid:0x&quot; + Long.toHexString(sessionId)); } // 从 response 中反序列化 WatcherEvent event = new WatcherEvent(); event.deserialize(bbia, &quot;response&quot;); // convert from a server path to a client path if (chrootPath != null) { String serverPath = event.getPath(); if(serverPath.compareTo(chrootPath)==0) event.setPath(&quot;/&quot;); else if (serverPath.length() &gt; chrootPath.length()) event.setPath(serverPath.substring(chrootPath.length())); else { LOG.warn(&quot;Got server path &quot; + event.getPath() + &quot; which is too short for chroot path &quot; + chrootPath); } } WatchedEvent we = new WatchedEvent(event); if (LOG.isDebugEnabled()) { LOG.debug(&quot;Got &quot; + we + &quot; for sessionid 0x&quot; + Long.toHexString(sessionId)); } // 将 watchedEvent 交由 eventThread 处理 eventThread.queueEvent( we ); return; } private void queueEvent(WatchedEvent event, Set&lt;Watcher&gt; materializedWatchers) { if (event.getType() == EventType.None &amp;&amp; sessionState == event.getState()) { return; } sessionState = event.getState(); final Set&lt;Watcher&gt; watchers; if (materializedWatchers == null) { // materialize the watchers based on the event // 从 ZKWatchManager 中获取 path 的 watcher watchers = watcher.materialize(event.getState(), event.getType(), event.getPath()); } else { watchers = new HashSet&lt;Watcher&gt;(); watchers.addAll(materializedWatchers); } WatcherSetEventPair pair = new WatcherSetEventPair(watchers, event); // queue the pair (watch set &amp; event) for later processing waitingEvents.add(pair); } 从上面代码看出 客户端在处理 watcher 通知的时候会将其封装为 WatcherSetEventPair 对象并添加到 waitingEvents 队列中此时会唤醒阻塞在队列的操作，也即 eventThread 的 run 方法，如下： public void run() { try { isRunning = true; while (true) { Object event = waitingEvents.take(); if (event == eventOfDeath) { wasKilled = true; } else { processEvent(event); } if (wasKilled) synchronized (waitingEvents) { if (waitingEvents.isEmpty()) { isRunning = false; break; } } } } catch (InterruptedException e) { LOG.error(&quot;Event thread exiting due to interruption&quot;, e); } LOG.info(&quot;EventThread shut down for session: 0x{}&quot;, Long.toHexString(getSessionId())); } 截取 processEvent 方法中针对 watcher 的处理 f (event instanceof WatcherSetEventPair) { // each watcher will process the event WatcherSetEventPair pair = (WatcherSetEventPair) event; for (Watcher watcher : pair.watchers) { try { // 执行 watcher watcher.process(pair.event); } catch (Throwable t) { LOG.error(&quot;Error while calling watcher &quot;, t); } } } 从上面代码看出当 waitingEvents 队列中存在待处理的 watcher 时将会依次调用；至此完成 watcher的执行；到此完成对 zookeeper watcher 的分析.","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://hxlzpnyist.github.io/tags/zookeeper/"}],"keywords":[]},{"title":"NIO selector的wakeup","slug":"NIO-selector的wakeup","date":"2017-12-21T06:48:17.000Z","updated":"2017-12-21T07:37:20.000Z","comments":true,"path":"2017/12/21/NIO-selector的wakeup/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/21/NIO-selector的wakeup/","excerpt":"wakeUp 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 引用至 http://ifeve.com/selectors/","text":"wakeUp 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 引用至 http://ifeve.com/selectors/ 测试public class App { private Selector selector; public void start () throws IOException { // 开启选择器 selector selector = Selector.open(); // 开启服务端 socket 通道 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 设置为非阻塞 serverSocketChannel.configureBlocking(false); // 绑定服务端端口 serverSocketChannel.socket().bind(new InetSocketAddress(8888)); // 通道注册到选择器上 并监听 接收客户端事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); // 因 selector.select 会阻塞当前线程 故异步处理 new Thread(new Runnable() { @Override public void run() { while (true) { System.out.println(&quot;select 前执行&quot;); try { selector.select(); } catch (IOException e) { e.printStackTrace(); } System.out.println(&quot;select 后执行&quot;); } } }).start(); } public void wakeup () { System.out.println(&quot;开始唤醒&quot;); selector.wakeup(); } public static void main( String[] args ) throws IOException, InterruptedException { final App app = new App(); app.start(); Thread thread = new Thread(new Runnable() { @Override public void run() { while (true) { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } app.wakeup(); } } }); thread.start(); thread.join(); } } select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 select 前执行 开始唤醒 select 后执行 从执行结果可以看出 在调用了 wakeup() 方法之后，即可唤醒阻塞在 select() 上的操作 也即 select() 方法会立马返回.","categories":[],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://hxlzpnyist.github.io/tags/NIO/"}],"keywords":[]},{"title":"zookeeper源码阅读之client","slug":"zookeeper源码阅读之client","date":"2017-12-15T05:46:58.000Z","updated":"2017-12-19T07:52:37.000Z","comments":true,"path":"2017/12/15/zookeeper源码阅读之client/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/15/zookeeper源码阅读之client/","excerpt":"zookeeper client 启动流程 先看下 zookeeper client 相关类图 执行 zkCli.sh 脚本时, 会运行 org.apache.zookeeper.ZookeeperMain 类主方法.public static void main(String args[]) throws KeeperException, IOException, InterruptedException { ZooKeeperMain main = new ZooKeeperMain(args); main.run(); } public ZooKeeperMain(String args[]) throws IOException, InterruptedException { // 启动参数解析 cl.parseOptions(args); System.out.println(&quot;Connecting to &quot; + cl.getOption(&quot;server&quot;)); // 链接 zookeeper server connectToZK(cl.getOption(&quot;server&quot;)); } 从代码中可以看出 client 启动时首先构造 ZookeeperMain 对象实例,构造过程中会先解析 client 的启动参数（若未指定任何参数将会默认链接本机 2181 端口 zookeeper server）","text":"zookeeper client 启动流程 先看下 zookeeper client 相关类图 执行 zkCli.sh 脚本时, 会运行 org.apache.zookeeper.ZookeeperMain 类主方法.public static void main(String args[]) throws KeeperException, IOException, InterruptedException { ZooKeeperMain main = new ZooKeeperMain(args); main.run(); } public ZooKeeperMain(String args[]) throws IOException, InterruptedException { // 启动参数解析 cl.parseOptions(args); System.out.println(&quot;Connecting to &quot; + cl.getOption(&quot;server&quot;)); // 链接 zookeeper server connectToZK(cl.getOption(&quot;server&quot;)); } 从代码中可以看出 client 启动时首先构造 ZookeeperMain 对象实例,构造过程中会先解析 client 的启动参数（若未指定任何参数将会默认链接本机 2181 端口 zookeeper server） 通过调用 connectToZK 链接 zookeeper serverprotected void connectToZK(String newHost) throws InterruptedException, IOException { if (zk != null &amp;&amp; zk.getState().isAlive()) { // 若已创建 zookeeper 对象并且状态为激活 则关闭重新创建 zk.close(); } host = newHost; boolean readOnly = cl.getOption(&quot;readonly&quot;) != null; if (cl.getOption(&quot;secure&quot;) != null) { System.setProperty(ZKClientConfig.SECURE_CLIENT, &quot;true&quot;); System.out.println(&quot;Secure connection is enabled&quot;); } // 构造 Zookeeper 对象实例 zk = new ZooKeeper(host,Integer.parseInt(cl.getOption(&quot;timeout&quot;)), new MyWatcher(), readOnly); } 创建 Zookeeper 对象实例// connectString 是形如 host:port,host:port 的字符串片段 public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher, boolean canBeReadOnly, HostProvider aHostProvider, ZKClientConfig clientConfig) throws IOException { if (clientConfig == null) { // 创建 ZKClient Config 对象 clientConfig = new ZKClientConfig(); } this.clientConfig = clientConfig; watchManager = defaultWatchManager(); watchManager.defaultWatcher = watcher; ConnectStringParser connectStringParser = new ConnectStringParser( connectString); hostProvider = aHostProvider; // 创建 ClientCnxn 对象 cnxn = new ClientCnxn(connectStringParser.getChrootPath(), hostProvider, sessionTimeout, this, watchManager, getClientCnxnSocket(), canBeReadOnly); cnxn.start(); } // 创建 ClientCnxnSocket对象 默认为 ClientCnxnSocketNIO 对象 private ClientCnxnSocket getClientCnxnSocket() throws IOException { String clientCnxnSocketName = getClientConfig().getProperty( ZKClientConfig.ZOOKEEPER_CLIENT_CNXN_SOCKET); if (clientCnxnSocketName == null) { clientCnxnSocketName = ClientCnxnSocketNIO.class.getName(); } try { Constructor&lt;?&gt; clientCxnConstructor = Class.forName(clientCnxnSocketName).getDeclaredConstructor(ZKClientConfig.class); ClientCnxnSocket clientCxnSocket = (ClientCnxnSocket) clientCxnConstructor.newInstance(getClientConfig()); return clientCxnSocket; } catch (Exception e) { IOException ioe = new IOException(&quot;Couldn&#39;t instantiate &quot; + clientCnxnSocketName); ioe.initCause(e); throw ioe; } } 从代码中看出 Zookeeper 关联了 ClientCnxn 对象, 在创建了 ClientCnxn 对象实例之后调用了 cnxn.start() 方法。 创建 ClientCnxn 对象实例public ClientCnxn(String chrootPath, HostProvider hostProvider, int sessionTimeout, ZooKeeper zooKeeper, ClientWatchManager watcher, ClientCnxnSocket clientCnxnSocket, long sessionId, byte[] sessionPasswd, boolean canBeReadOnly) { this.zooKeeper = zooKeeper; this.watcher = watcher; this.sessionId = sessionId; this.sessionPasswd = sessionPasswd; this.sessionTimeout = sessionTimeout; this.hostProvider = hostProvider; this.chrootPath = chrootPath; // 计算连接超时时间 读数据超时时间 connectTimeout = sessionTimeout / hostProvider.size(); readTimeout = sessionTimeout * 2 / 3; readOnly = canBeReadOnly; // 创建了 SendThread EventThread 线程实例 sendThread = new SendThread(clientCnxnSocket); eventThread = new EventThread(); this.clientConfig=zooKeeper.getClientConfig(); } public void start() { sendThread.start(); eventThread.start(); } 从 start 方法中可以看出分别启动了 sendThread eventThread 两个线程。 SendThread 线程的构造及启动SendThread(ClientCnxnSocket clientCnxnSocket) { super(makeThreadName(&quot;-SendThread()&quot;)); state = States.CONNECTING; this.clientCnxnSocket = clientCnxnSocket; setDaemon(true); } SendThread 是 ClientCnxn 的内部类, 创建该线程实例时会将 ClientCnxn 的状态由默认状态(未连接)改为连接中,并赋值 clientCnxnSocket。 ClientCnxn 的主要成员变量说明 在了解 sendThread 线程的启动过程有必要先了解一下关于 SendThread 和 ClientCnxn 的相关成员变量。 变量名 描述 state 客户端连接状态 outgoingQueue 存储需要被发送出去的报文的队列 pendingQueue 存储已经发送等待响应结果的队列 SendThread 线程启动public void run() { // 将 sendThread sessionId outgoingQueue 绑定到的 clientCnxnSocketNIO clientCnxnSocket.introduce(this, sessionId, outgoingQueue); clientCnxnSocket.updateNow(); clientCnxnSocket.updateLastSendAndHeard(); int to; long lastPingRwServer = Time.currentElapsedTime(); final int MAX_SEND_PING_INTERVAL = 10000; //10 seconds while (state.isAlive()) { try { if (!clientCnxnSocket.isConnected()) { // don&#39;t re-establish connection if we are closing if (closing) { break; } // 如果 clientCnxnSocketNIO 未连接 则开始连接 startConnect(); clientCnxnSocket.updateLastSendAndHeard(); } if (state.isConnected()) { // determine whether we need to send an AuthFailed event. if (zooKeeperSaslClient != null) { // ssl client 的处理此处省略 } to = readTimeout - clientCnxnSocket.getIdleRecv(); } else { to = connectTimeout - clientCnxnSocket.getIdleRecv(); } if (to &lt;= 0) { String warnInfo; warnInfo = &quot;Client session timed out, have not heard from server in &quot; + clientCnxnSocket.getIdleRecv() + &quot;ms&quot; + &quot; for sessionid 0x&quot; + Long.toHexString(sessionId); LOG.warn(warnInfo); throw new SessionTimeoutException(warnInfo); } if (state.isConnected()) { //1000(1 second) is to prevent race condition missing to send the second ping //also make sure not to send too many pings when readTimeout is small int timeToNextPing = readTimeout / 2 - clientCnxnSocket.getIdleSend() - ((clientCnxnSocket.getIdleSend() &gt; 1000) ? 1000 : 0); //send a ping request either time is due or no packet sent out within MAX_SEND_PING_INTERVAL if (timeToNextPing &lt;= 0 || clientCnxnSocket.getIdleSend() &gt; MAX_SEND_PING_INTERVAL) { // 发送心跳 sendPing(); clientCnxnSocket.updateLastSend(); } else { if (timeToNextPing &lt; to) { to = timeToNextPing; } } } // If we are in read-only mode, seek for read/write server if (state == States.CONNECTEDREADONLY) { long now = Time.currentElapsedTime(); int idlePingRwServer = (int) (now - lastPingRwServer); if (idlePingRwServer &gt;= pingRwTimeout) { lastPingRwServer = now; idlePingRwServer = 0; pingRwTimeout = Math.min(2*pingRwTimeout, maxPingRwTimeout); pingRwServer(); } to = Math.min(to, pingRwTimeout - idlePingRwServer); } clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this); } catch (Throwable e) { // 异常处理的部分省略... } } synchronized (state) { // When it comes to this point, it guarantees that later queued // packet to outgoingQueue will be notified of death. cleanup(); } clientCnxnSocket.close(); if (state.isAlive()) { eventThread.queueEvent(new WatchedEvent(Event.EventType.None, Event.KeeperState.Disconnected, null)); } ZooTrace.logTraceMessage(LOG, ZooTrace.getTextTraceLevel(), &quot;SendThread exited loop for session: 0x&quot; + Long.toHexString(getSessionId())); } 从代码中可以看出 sendThread 主要做以下事情 创建客户端连接 发送心跳 发送消息 (终端输入的指令) 下面将针对上面三种流程分析 客户端连接创建流程 先大概看下此流程活动图 如下: sendThread 轮询过程中 先判断 clientCnxnSocket 是否已连接；若未连接则调用 sendThread.startConnect() 将 ClientCnxn.state 的状态改为 “连接中”, 接下来同步调用 clientCnxnSocket.connect 完成客户端 socket 的创建及注册到 selector 并监听连接事件 上述操作完成后会调用 clientCnxnSocket.doTransport (), 该方法主要处理 selector 选择器上就绪的通道事件. 当客户端 socket 连接就绪的时候会调用 sendThread.primeConnection() 准备连接方法，该方法 ConnectionRequet 的 Packet 并将其添加到 outgoingQueue 对列中，接下来调用 clientCnxnSocket.connectionPrimed 该方法主要告知 socket 准备好连接了 此时客户端在 selector 上注册读写事件 (此时会触发通道的写就绪事件) 当客户端 socket 写就绪的时候会调用 clientCnxnSocket.findSendablePacket 该方法从 outgoingQueue 队列中获取待发送的 Packet , 最后执行 socket.write() 发送消息(此时会触发通道的读就绪事件) 当客户端 socket 读就绪的时候判断 initialized 是否为 true，若为 false 说明执行连接初始化会调用 sendThread.onConnected 更改客户端状态为 “已连接”， 继续注册监听客户端的读写事件 客户端心跳流程 心跳流程如下： sendThread 轮询过程中 判断 state 是否为 “已连接”; 若已连接判断是否满足心跳条件, 调用 sendPing 创建心跳 packet header xid = -2; 接下来将 packet 添加到 outgoingQueue 队列中并调用 clientCnxnSocket.packetAddedd 最后唤醒阻塞在 selector.select 上的操作 当客户端 socket 写就绪的时候调用 findSendablePacket 获取待发送的 packet 最后调用 socket.write 执行发送 当客户端 socket 读就绪的时候调用 sendThread.readResponse 解析服务端的响应结果, 通过获取 response heaher xid 判断 xid == -2 ; 若为 -2 则打印心跳返回日志返回， 此时一次心跳结束 客户端终端发送指令流程 发送指令流程图如下: ZookeeperMain 构建完成后会调用 run 方法，等待用户输入 输入指令后会相应调用 executeLine, processCmd, processZKCmd 通过解析参数获取相应的 CliCommand 此处采用了命令模式 内置了各种 CliCommand 对应客户端相应的操作，包括(CreateCommand, GetCommand, SetCommand ….）; 获取对应的命令后，调用 parse, exec 方法执行命令 执行命令会调用 zookeeper 对应的操作(create, getData, setData)，在内部会调用 ClientCnxn.submitRequest 方法 在 clientCnxn.submitRequest 方法中会调用 queuePacket 创建 packet 并将其添加到队列中，接着唤醒 clientCnxnSocketNIO 的 selector.select 操作；后续操作就是读写就绪事件的处理与心跳流程类似。 至此 zookeeper client 的相关流程介绍完毕 细节的地方后续在处理.","categories":[],"tags":[],"keywords":[]},{"title":"NIO之粘包拆包处理","slug":"NIO之粘包拆包处理","date":"2017-12-14T06:48:19.000Z","updated":"2018-05-30T06:37:41.000Z","comments":true,"path":"2017/12/14/NIO之粘包拆包处理/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/14/NIO之粘包拆包处理/","excerpt":"概述 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。 粘包拆包的原因 关于 tcp 传输过程中，发生粘包拆包的原因及表现形式可参考网上的一篇博客; 这里就不在说明. 粘包拆包的解决方法 本文给出针对自定义消息报文格式，通过在消息头部添加消息载体长度来处理","text":"概述 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。 粘包拆包的原因 关于 tcp 传输过程中，发生粘包拆包的原因及表现形式可参考网上的一篇博客; 这里就不在说明. 粘包拆包的解决方法 本文给出针对自定义消息报文格式，通过在消息头部添加消息载体长度来处理 实现方式消息内容包装public class PacketWrapper { // 消息有效长度 private int length; // 消息的有效载体 private byte[] payload; public PacketWrapper(String payload) { this.payload = payload.getBytes(); this.length = this.payload.length; } public PacketWrapper(byte[] payload) { this.payload = payload; this.length = this.payload.length; } // 返回包装后的字节数组 public byte[] getBytes() { ByteBuffer byteBuffer = ByteBuffer.allocate(this.length + 4); byteBuffer.putInt(this.length); byteBuffer.put(payload); return byteBuffer.array(); } public String toString() { StringBuilder sb = new StringBuilder(); for (byte b : getBytes()) { sb.append(String.format(&quot;0x%02X &quot;, b)); } return sb.toString(); } } 消息报文的解码 public class NioDecodeHandler { private static Logger log = Logger.getLogger(NioDecodeHandler.class); private final int HEAD_LENGTH = 4; protected ByteBuffer lastReadBuffer = null; public void decode (SocketChannel socketChannel) { // 从通道中读取内容 ByteBuffer readByteBuffer = ByteBuffer.allocate(128); try { int read = socketChannel.read(readByteBuffer); if (read &lt; 0) { throw new RuntimeException(&quot;&quot;); } } catch (IOException e) { } ByteBuffer newByteBuffer = readByteBuffer; if (newByteBuffer == null) { return; } // 切换到读模式 newByteBuffer.flip(); if (lastReadBuffer != null) { // 将上次遗留的数据与本次已读的数据合并 newByteBuffer = ByteBufferUtil.composite(lastReadBuffer, newByteBuffer); } decode : while (true) { if (newByteBuffer.remaining() &lt;= HEAD_LENGTH) { // 报文字节数达不到报文长度退出 lastReadBuffer = ByteBuffer.wrap(ByteBufferUtil.readBuffer(newByteBuffer, newByteBuffer.remaining())); return; } // 获取报文头部, 即报文有效长度 int payloadLength = newByteBuffer.getInt(); if (newByteBuffer.remaining() &lt; payloadLength) { // 拆包 : 后续字节不够一个完整报文 // 因上一操作 getInt 读取了 4 字节, 故需将 position 退回移动 4 字节 newByteBuffer.position(newByteBuffer.position() - HEAD_LENGTH); lastReadBuffer = ByteBuffer.wrap(ByteBufferUtil.readBuffer(newByteBuffer, newByteBuffer.remaining())); return; } // 获取有效报文 handlerPacket(socketChannel, ByteBufferUtil.readBuffer(newByteBuffer, payloadLength)); if (newByteBuffer.remaining() &gt; 0) { // 剩下的报文 可能是有效报文, 继续解码 continue decode; } return; } } private void handlerPacket (SocketChannel socketChannel, byte[] packet) { ServiceLoader&lt;PacketHandler&gt; packetHandlers = ServiceLoader.load(PacketHandler.class); Iterator&lt;PacketHandler&gt; packetHandlerIterator = packetHandlers.iterator(); while (packetHandlerIterator.hasNext()) { packetHandlerIterator.next().handler(socketChannel, packet); } } } 依赖的工具方法如下： public class ByteBufferUtil { private ByteBufferUtil () {} /** * 将两个 bytebuffer 合并 * * @param byteBuffer1 * @param byteBuffer2 * @return */ public static ByteBuffer composite(ByteBuffer byteBuffer1, ByteBuffer byteBuffer2) { int capacity = byteBuffer1.limit() - byteBuffer1.position() + byteBuffer2.limit() - byteBuffer2.position(); ByteBuffer ret = ByteBuffer.allocate(capacity); ret.put(byteBuffer1); ret.put(byteBuffer2); ret.position(0); ret.limit(ret.capacity()); return ret; } /** * 获取 bytebuffer 中可读的内容 * * @param byteBuffer * @param size * @return */ public static byte[] readBuffer(ByteBuffer byteBuffer, int size) { byte[] bytes = new byte[size]; byteBuffer.get(bytes); return bytes; } }","categories":[],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://hxlzpnyist.github.io/tags/NIO/"}],"keywords":[]},{"title":"NIO之ByteBuffer","slug":"NIO之ByteBuffer","date":"2017-12-13T09:14:14.000Z","updated":"2017-12-15T02:48:32.000Z","comments":true,"path":"2017/12/13/NIO之ByteBuffer/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/13/NIO之ByteBuffer/","excerpt":"ByteBuffer字段说明 Capacity : Buffer 固定的容量大小 Position : 表示当前的位置， 初始值为0；当为写模式时，当写入一个字节的时候，position会向前移动到下一个可插入数据的buffer单元；当为读模式时，position会重置为0，每读取一个字节的时候，position会向前移动下一个可读取的位置。 Limit : 表示buffer最多可写或可读的数量。写模式下limit = capacity; 读模式下limit = position 初始化 采用jvm堆内存初始 /** * 定义初始容量10字节的缓冲区 capacity=10, limit=10, position=0 */ ByteBuffer byteBuffer = ByteBuffer.allocate(10);","text":"ByteBuffer字段说明 Capacity : Buffer 固定的容量大小 Position : 表示当前的位置， 初始值为0；当为写模式时，当写入一个字节的时候，position会向前移动到下一个可插入数据的buffer单元；当为读模式时，position会重置为0，每读取一个字节的时候，position会向前移动下一个可读取的位置。 Limit : 表示buffer最多可写或可读的数量。写模式下limit = capacity; 读模式下limit = position 初始化 采用jvm堆内存初始 /** * 定义初始容量10字节的缓冲区 capacity=10, limit=10, position=0 */ ByteBuffer byteBuffer = ByteBuffer.allocate(10); 采用堆外内存初始 /** * 定义初始容量10字节的缓冲区 capacity=10, limit=10, position=0 */ ByteBuffer byteBuffer = ByteBuffer.allocateDirect(10); put(byte byte) 写入数据时，每写入一个字节的时候 会检验 position &gt;= limit, 之后执行position++ 自增操作； public Bytebuffer put (byte x) { hb[ix(nextPutIndex())] = x; return this; } int nextPutIndex () { if (position &gt;= limit) { throw new BufferOverflowException(); } return position++; } flip() buffer 由写模式切换到读模式; limit 值为position， position会重置为0 public final Buffer flip() { limit = position; position = 0; mark = -1; return this; } get() buffer 读取数据的时候，检验position&gt;=limit; 之后执行position++ public byte get() { return hb[ix(nextGetIndex())]; } int nextGetIndex () { if (position &gt;= limit){ throw new BufferUnderflowException(); } return position++; }","categories":[],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://hxlzpnyist.github.io/tags/NIO/"},{"name":"bytebuffer","slug":"bytebuffer","permalink":"https://hxlzpnyist.github.io/tags/bytebuffer/"}],"keywords":[]},{"title":"zookeeper源码阅读之server","slug":"zookeeper源码阅读之server","date":"2017-12-12T11:29:37.000Z","updated":"2017-12-19T07:38:37.000Z","comments":true,"path":"2017/12/12/zookeeper源码阅读之server/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/12/zookeeper源码阅读之server/","excerpt":"zookeeper server 启动流程概述 此次只针对单机模式对 server 端的启动流程分析, 首先看下 zookeeper server 启动时序图，如下： 其启动流程如下： 执行 zkServer.sh start 脚本, 会调用 QuorumPeerMain.main(); 执行 initializeAndRun 方法 调用 QuorumPeerConfig.parse() 方法，该方法主要是对启动参数的解析并加载相应的配置文件 通过上文解析的配置, 判断当前启动模式是否为集群或单机模式 单机模式下调用 ZookeeperServerMain.main() 方法 执行 ZookeeperServerMain.initializeAndRun 方法 调用 ServerConfig.parse 再次解析启动参数加载配置文件 调用 runFromConfig , 在该方法中依次启动 JettyAdminServer.start(), NIOServerCnxnFactory.startup() 至此 zookeeper server 完成单机模式下启动，接下来将详细看下 NIOServerCnxnFactory.startup 的启动过程。","text":"zookeeper server 启动流程概述 此次只针对单机模式对 server 端的启动流程分析, 首先看下 zookeeper server 启动时序图，如下： 其启动流程如下： 执行 zkServer.sh start 脚本, 会调用 QuorumPeerMain.main(); 执行 initializeAndRun 方法 调用 QuorumPeerConfig.parse() 方法，该方法主要是对启动参数的解析并加载相应的配置文件 通过上文解析的配置, 判断当前启动模式是否为集群或单机模式 单机模式下调用 ZookeeperServerMain.main() 方法 执行 ZookeeperServerMain.initializeAndRun 方法 调用 ServerConfig.parse 再次解析启动参数加载配置文件 调用 runFromConfig , 在该方法中依次启动 JettyAdminServer.start(), NIOServerCnxnFactory.startup() 至此 zookeeper server 完成单机模式下启动，接下来将详细看下 NIOServerCnxnFactory.startup 的启动过程。 zookeeper server 线程模型 在 NIOServerCnxnFactory.startup() 启动前, 我们先看下针对 NIOServerCnxnFactory 的对象的创建及相关配置: NIOServerCnxnFactory 的创建 通过 ServerCnxnFactory.createFactory 完成 ServerCnxnFactory 的创建 static public ServerCnxnFactory createFactory() throws IOException { // 获取系统变量 zookeeper.serverCnxnFactory String serverCnxnFactoryName = System.getProperty(ZOOKEEPER_SERVER_CNXN_FACTORY); if (serverCnxnFactoryName == null) { // 若未指定该变量值 则默认返回 NIOServerCnxnFactory; 同时支持 NettyServerCnxnFactory serverCnxnFactoryName = NIOServerCnxnFactory.class.getName(); } try { return (ServerCnxnFactory) Class.forName(serverCnxnFactoryName) .newInstance(); } catch (Exception e) { IOException ioe = new IOException(&quot;Couldn&#39;t instantiate &quot; + serverCnxnFactoryName); ioe.initCause(e); throw ioe; } } NIOServerCnxnFactory 的配置 在执行 startup 前会调用 configure 方法执行相关参数的初始化并绑定 serverSocket public void configure(InetSocketAddress addr, int maxcc, boolean secure) throws IOException { if (secure) { throw new UnsupportedOperationException(&quot;SSL isn&#39;t supported in NIOServerCnxn&quot;); } configureSaslLogin(); maxClientCnxns = maxcc; sessionlessCnxnTimeout = Integer.getInteger( ZOOKEEPER_NIO_SESSIONLESS_CNXN_TIMEOUT, 10000); cnxnExpiryQueue = new ExpiryQueue&lt;NIOServerCnxn&gt;(sessionlessCnxnTimeout); expirerThread = new ConnectionExpirerThread(); // 返回虚拟机的可用处理器数量 也可认为 cpu 核数 int numCores = Runtime.getRuntime().availableProcessors(); // 32 cores sweet spot seems to be 4 selector threads // 计算 selectorThread 线程个数 numSelectorThreads = Integer.getInteger( ZOOKEEPER_NIO_NUM_SELECTOR_THREADS, Math.max((int) Math.sqrt((float) numCores/2), 1)); if (numSelectorThreads &lt; 1) { throw new IOException(&quot;numSelectorThreads must be at least 1&quot;); } // 工作线程 workerThread 数; 默认为 2*numCores numWorkerThreads = Integer.getInteger( ZOOKEEPER_NIO_NUM_WORKER_THREADS, 2 * numCores); workerShutdownTimeoutMS = Long.getLong( ZOOKEEPER_NIO_SHUTDOWN_TIMEOUT, 5000); // 创建 selectorThread 线程集合 for(int i=0; i&lt;numSelectorThreads; ++i) { selectorThreads.add(new SelectorThread(i)); } // 开启服务端链接通道并绑定端口 this.ss = ServerSocketChannel.open(); ss.socket().setReuseAddress(true); LOG.info(&quot;binding to port &quot; + addr); ss.socket().bind(addr); ss.configureBlocking(false); // 创建 AcceptThread 并绑定 ServerSocketChannel selecorThreads acceptThread = new AcceptThread(ss, addr, selectorThreads); } NIOServerCnxnFactory 的启动 启动过程包括 NIOServerCnxnFactory 的启动和 ZookeeperServer 的启动`java @Override public void startup(ZooKeeperServer zks, boolean startServer) throws IOException, InterruptedException { start(); setZooKeeperServer(zks); if (startServer) { zks.startdata(); zks.startup(); } } ```java public void start() { stopped = false; if (workerPool == null) { workerPool = new WorkerService( &quot;NIOWorker&quot;, numWorkerThreads, false); } for(SelectorThread thread : selectorThreads) { if (thread.getState() == Thread.State.NEW) { thread.start(); } } // ensure thread is started once and only once if (acceptThread.getState() == Thread.State.NEW) { acceptThread.start(); } if (expirerThread.getState() == Thread.State.NEW) { expirerThread.start(); } } 从代码中可以看出 NIOServerCnxnFactory 启动的时候开启了 AcceptThread SelectorThread ExpirerThread workerPool AcceptThreadpublic void run() { try { // 当 server 未停止 并且 serverSocket 未关闭的时候一直轮询执行select() while (!stopped &amp;&amp; !acceptSocket.socket().isClosed()) { try { select(); } catch (RuntimeException e) { LOG.warn(&quot;Ignoring unexpected runtime exception&quot;, e); } catch (Exception e) { LOG.warn(&quot;Ignoring unexpected exception&quot;, e); } } } finally { closeSelector(); // This will wake up the selector threads, and tell the // worker thread pool to begin shutdown. if (!reconfiguring) { NIOServerCnxnFactory.this.stop(); } LOG.info(&quot;accept thread exitted run method&quot;); } } private void select() { try { selector.select(); Iterator&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys().iterator(); while (!stopped &amp;&amp; selectedKeys.hasNext()) { SelectionKey key = selectedKeys.next(); selectedKeys.remove(); if (!key.isValid()) { continue; } if (key.isAcceptable()) { if (!doAccept()) { pauseAccept(10); } } else { LOG.warn(&quot;Unexpected ops in accept select &quot; + key.readyOps()); } } } catch (IOException e) { LOG.warn(&quot;Ignoring IOException while selecting&quot;, e); } } private boolean doAccept() { boolean accepted = false; SocketChannel sc = null; try { // 获取客户端链接 sc = acceptSocket.accept(); accepted = true; InetAddress ia = sc.socket().getInetAddress(); int cnxncount = getClientCnxnCount(ia); // 判断该客户端连接数是否超过最大值 if (maxClientCnxns &gt; 0 &amp;&amp; cnxncount &gt;= maxClientCnxns){ throw new IOException(&quot;Too many connections from &quot; + ia + &quot; - max is &quot; + maxClientCnxns ); } LOG.info(&quot;Accepted socket connection from &quot; + sc.socket().getRemoteSocketAddress()); sc.configureBlocking(false); // Round-robin assign this connection to a selector thread // 选取一个 selectorThread if (!selectorIterator.hasNext()) { selectorIterator = selectorThreads.iterator(); } SelectorThread selectorThread = selectorIterator.next(); // 将接收到的链接 添加到 selector thread 的接收队列中 if (!selectorThread.addAcceptedConnection(sc)) { throw new IOException( &quot;Unable to add connection to selector queue&quot; + (stopped ? &quot; (shutdown in progress)&quot; : &quot;&quot;)); } acceptErrorLogger.flush(); } catch (IOException e) { // accept, maxClientCnxns, configureBlocking acceptErrorLogger.rateLimitLog( &quot;Error accepting new connection: &quot; + e.getMessage()); fastCloseSock(sc); } return accepted; } 从代码中可以看出 AcceptThread 主要用来接收客户端的链接，并将就绪的客户端链接添加到 selectorThread线程对象的 acceptQueue 中 SelectorThreadpublic boolean addAcceptedConnection(SocketChannel accepted) { if (stopped || !acceptedQueue.offer(accepted)) { return false; } // 当接收到一个链接的时候, 唤醒阻塞在 selector.select(）操作上的线程 wakeupSelector(); return true; } 当 AcceptThread 将就绪的客户端链接添加到 selectorThread 对象的 acceptQueue 队列中的时候，同时会唤醒阻塞在 acceptQueue.poll() , selector.select() 操作的实例 public void run() { try { while (!stopped) { try { select(); // 处理 acceptedQueue 队列里面的客户端链接 processAcceptedConnections(); processInterestOpsUpdateRequests(); } catch (RuntimeException e) { LOG.warn(&quot;Ignoring unexpected runtime exception&quot;, e); } catch (Exception e) { LOG.warn(&quot;Ignoring unexpected exception&quot;, e); } } // Close connections still pending on the selector. Any others // with in-flight work, let drain out of the work queue. for (SelectionKey key : selector.keys()) { NIOServerCnxn cnxn = (NIOServerCnxn) key.attachment(); if (cnxn.isSelectable()) { cnxn.close(); } cleanupSelectionKey(key); } SocketChannel accepted; while ((accepted = acceptedQueue.poll()) != null) { fastCloseSock(accepted); } updateQueue.clear(); } finally { closeSelector(); // This will wake up the accept thread and the other selector // threads, and tell the worker thread pool to begin shutdown. NIOServerCnxnFactory.this.stop(); LOG.info(&quot;selector thread exitted run method&quot;); } } private void select() { try { selector.select(); Set&lt;SelectionKey&gt; selected = selector.selectedKeys(); ArrayList&lt;SelectionKey&gt; selectedList = new ArrayList&lt;SelectionKey&gt;(selected); Collections.shuffle(selectedList); Iterator&lt;SelectionKey&gt; selectedKeys = selectedList.iterator(); while(!stopped &amp;&amp; selectedKeys.hasNext()) { SelectionKey key = selectedKeys.next(); selected.remove(key); if (!key.isValid()) { cleanupSelectionKey(key); continue; } if (key.isReadable() || key.isWritable()) { handleIO(key); } else { LOG.warn(&quot;Unexpected ops in select &quot; + key.readyOps()); } } } catch (IOException e) { LOG.warn(&quot;Ignoring IOException while selecting&quot;, e); } } private void handleIO(SelectionKey key) { IOWorkRequest workRequest = new IOWorkRequest(this, key); NIOServerCnxn cnxn = (NIOServerCnxn) key.attachment(); // Stop selecting this key while processing on its // connection cnxn.disableSelectable(); key.interestOps(0); touchCnxn(cnxn); LOG.info(&quot;Selector THread 开始处理 io&quot;); workerPool.schedule(workRequest); } private void processAcceptedConnections() { SocketChannel accepted; while (!stopped &amp;&amp; (accepted = acceptedQueue.poll()) != null) { SelectionKey key = null; try { // 将 acceptQueue 中的 socketChannel 注册到 selector 并监听读事件 key = accepted.register(selector, SelectionKey.OP_READ); // 新建 nioServerCnxn 并以附加信息的方式绑定到 selectkey NIOServerCnxn cnxn = createConnection(accepted, key, this); key.attach(cnxn); addCnxn(cnxn); } catch (IOException e) { // register, createConnection cleanupSelectionKey(key); fastCloseSock(accepted); } } } 从以上代码可以看出 selectorThread 流程如下: 轮询 selector 选择器上是否有就绪的客户端通道 当有就绪 Read 事件的客户端通道时 将该客户端派发到 wokerPool 去执行 当 acceptQueue 队列中有新接收的到客户通道的时候 将其注册到 selector 上并监听 READ 事件；同时并创建一个 NIOServerCnxn 对象绑定到 key 上（待执行 handleIO 时用到） 接下来看下 wokerPool 如何处理 workRequest public void schedule(WorkRequest workRequest, long id) { if (stopped) { workRequest.cleanup(); return; } ScheduledWorkRequest scheduledWorkRequest = new ScheduledWorkRequest(workRequest); // If we have a worker thread pool, use that; otherwise, do the work // directly. // 如果 workers 数量大于 0, 则通过 ExecutorService 执行 scheduledWorkRequest； 反之直接调用 ScheduledWorkRequest int size = workers.size(); if (size &gt; 0) { try { // make sure to map negative ids as well to [0, size-1] int workerNum = ((int) (id % size) + size) % size; ExecutorService worker = workers.get(workerNum); worker.execute(scheduledWorkRequest); } catch (RejectedExecutionException e) { LOG.warn(&quot;ExecutorService rejected execution&quot;, e); workRequest.cleanup(); } } else { // When there is no worker thread pool, do the work directly // and wait for its completion scheduledWorkRequest.start(); try { scheduledWorkRequest.join(); } catch (InterruptedException e) { LOG.warn(&quot;Unexpected exception&quot;, e); Thread.currentThread().interrupt(); } } } private class ScheduledWorkRequest extends ZooKeeperThread { private final WorkRequest workRequest; ScheduledWorkRequest(WorkRequest workRequest) { super(&quot;ScheduledWorkRequest&quot;); this.workRequest = workRequest; } @Override public void run() { try { // Check if stopped while request was on queue if (stopped) { workRequest.cleanup(); return; } workRequest.doWork(); } catch (Exception e) { LOG.warn(&quot;Unexpected exception&quot;, e); workRequest.cleanup(); } } } private class IOWorkRequest extends WorkerService.WorkRequest { private final SelectorThread selectorThread; private final SelectionKey key; private final NIOServerCnxn cnxn; IOWorkRequest(SelectorThread selectorThread, SelectionKey key) { this.selectorThread = selectorThread; this.key = key; this.cnxn = (NIOServerCnxn) key.attachment(); } public void doWork() throws InterruptedException { if (!key.isValid()) { selectorThread.cleanupSelectionKey(key); return; } if (key.isReadable() || key.isWritable()) { LOG.info(&quot;IOWorker Request do work &quot;); cnxn.doIO(key); // Check if we shutdown or doIO() closed this connection if (stopped) { cnxn.close(); return; } if (!key.isValid()) { selectorThread.cleanupSelectionKey(key); return; } touchCnxn(cnxn); } // Mark this connection as once again ready for selection cnxn.enableSelectable(); // Push an update request on the queue to resume selecting // on the current set of interest ops, which may have changed // as a result of the I/O operations we just performed. if (!selectorThread.addInterestOpsUpdateRequest(key)) { cnxn.close(); } } @Override public void cleanup() { cnxn.close(); } } 从上面代码可以看出在执行 IOWorkRequest 时会选择由线程池执行还是单线程执行；最终会由 NIOServerCnxn 处理客户端通道的读写事件 综合 AcceptThread SelectorThread IOWorkRequest 可以看出 zookeeper server 的线程模型为单线程的 Reactor模型;如下图所示: 后续相关的 IO 处理及 PrepRequestProcessor 相关的 Processor 流程会在下文分析","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://hxlzpnyist.github.io/tags/zookeeper/"}],"keywords":[]},{"title":"VIM 支持 markdown 预览","slug":"vim编写markdown实时预览","date":"2017-12-12T03:28:15.000Z","updated":"2017-12-19T07:56:41.000Z","comments":true,"path":"2017/12/12/vim编写markdown实时预览/","link":"","permalink":"https://hxlzpnyist.github.io/2017/12/12/vim编写markdown实时预览/","excerpt":"安装 vim 插件管理器 vundle下载 vundle git clone https://github.com/VundleVim/Vundle.vim ~/.vim/bundle/Vundle.vim 编辑 vim 配置文件 vimrc 通过 apt-get install vim 安装的 vim 配置文件路径为 /etc/vim/vimrc vim /etc/vim/vimrc","text":"安装 vim 插件管理器 vundle下载 vundle git clone https://github.com/VundleVim/Vundle.vim ~/.vim/bundle/Vundle.vim 编辑 vim 配置文件 vimrc 通过 apt-get install vim 安装的 vim 配置文件路径为 /etc/vim/vimrc vim /etc/vim/vimrc 将以下内容添加到 vimrc 文件中 set nocompatible &quot; be iMproved, required filetype off &quot; required &quot; 启用vundle来管理vim插件 set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() &quot; 安装插件写在这之后 &quot; let Vundle manage Vundle, required Plugin &#39;VundleVim/Vundle.vim&#39; &quot; 安装插件写在这之前 call vundle#end() &quot; required filetype plugin on &quot; required&quot; 常用命令 &quot; :PluginList - 查看已经安装的插件 &quot; :PluginInstall - 安装插件 &quot; :PluginUpdate - 更新插件 &quot; :PluginSearch - 搜索插件，例如 :PluginSearch xml就能搜到xml相关的插件 &quot; :PluginClean - 删除插件，把安装插件对应行删除，然后执行这个命令即可 &quot; h: vundle - 获取帮助 进入 vim 执行 PluginInstall sudo vim :PluginInstall 插件安装完成后, 左下角会出现 Done！ 至此 vundle 插件管理器安装完成. 安装 vim-instant-markdown 插件 在 vim 配置文件 vimrc 文件中添加以下内容: Plugin &#39;suan/vim-instant-markdown&#39; 再次进入 vim 执行 PluginInstall; 当出现 Done！即表示插件安装完成. 此时 vim xx.md 即可实时预览 markdown 文件;效果如下图所示.","categories":[],"tags":[{"name":"vim","slug":"vim","permalink":"https://hxlzpnyist.github.io/tags/vim/"}],"keywords":[]}]}